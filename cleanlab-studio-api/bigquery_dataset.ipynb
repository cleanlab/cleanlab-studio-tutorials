{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Data from BigQuery to Cleanlab Studio\n",
    "\n",
    "In this tutorial, you\u2019ll learn how to upload data from BigQuery to Cleanlab Studio. You\u2019ll start by creating a table in BigQuery, then configure access by enabling the Cleanlab Studio GCP service account. Finally, you\u2019ll use the Python client to upload your table. This guide will help you integrate your BigQuery data into Cleanlab Studio efficiently.\n",
    "\n",
    "This notebook uses the BigQuery client library, along with the `cleanlab-studio` Python Package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install and import dependencies\n",
    "\n",
    "You'll need to install the `cleanlab-studio` package, along with the `google-cloud-bigquery` package. Additionally, you will need the `requests` library to download the example dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Install the required packages\n",
    "\n",
    "Required packages are installed using `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install cleanlab-studio --upgrade\n",
    "%pip install google-cloud-bigquery requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab_studio import Studio\n",
    "from google.cloud import bigquery\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Create BigQuery, Cleanlab Studio clients\n",
    "To make API calls to BigQuery and Cleanlab Studio, you need to create clients for both services.\n",
    "\n",
    "This tutorial assumes you have already authenticated your Google Cloud account. If you haven't, you can follow the instructions in the [Google Cloud documentation](https://cloud.google.com/docs/authentication/client-libraries).\n",
    "\n",
    "Ensure that you set the `GCP_PROJECT` variable along with the Cleanlab Studio API key in the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a BigQuery client\n",
    "GCP_PROJECT = \"<your-gcp-project>\"\n",
    "bigquery_client = bigquery.Client(project=GCP_PROJECT)\n",
    "\n",
    "# create a Studio client\n",
    "# you can find your Cleanlab Studio API key by going to app.cleanlab.ai/account\n",
    "API_KEY = \"<YOUR_API_KEY>\"\n",
    "studio = Studio(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload an example dataset to BigQuery (optional)\n",
    "\n",
    "You can use the following code to upload an example dataset to BigQuery. This dataset is an example customer support dataset that contains two columns.\n",
    "\n",
    "If you already have a dataset in BigQuery, you can skip this step -- just ensure that you set the `BIGQUERY_DATASET` and `BIGQUERY_TABLE` variables to the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set BigQuery dataset, and table\n",
    "BIGQUERY_DATASET = \"cleanlab_studio_demo\"\n",
    "BIGQUERY_TABLE = \"cleanlab_studio_banking\"\n",
    "\n",
    "LOCAL_DATASET_PATH = \"/tmp/studio_bigquery_dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": 0,
   "metadata": {},
   "source": [
    "**Optional: download example dataset**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(LOCAL_DATASET_PATH, \"wb\") as outf:\n",
    "    resp = requests.get(\"https://cleanlab-public.s3.amazonaws.com/Datasets/banking-text-quickstart-v1.csv\")\n",
    "    outf.write(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": 1,
   "metadata": {},
   "source": [
    "**Optional: upload example dataset to BigQuery**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigquery_dataset_id = f\"{GCP_PROJECT}.{BIGQUERY_DATASET}\"\n",
    "bigquery_table_id = f\"{bigquery_dataset_id}.{BIGQUERY_TABLE}\"\n",
    "bigquery_client.create_dataset(bigquery_dataset_id, exists_ok=True)\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    "    skip_leading_rows=1,\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"text\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"label\", \"STRING\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "with open(LOCAL_DATASET_PATH, \"rb\") as source_file:\n",
    "    job = bigquery_client.load_table_from_file(source_file, bigquery_table_id, job_config=job_config)\n",
    "\n",
    "result = job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure access to BigQuery\n",
    "\n",
    "To upload data from BigQuery to Cleanlab Studio, you need to enable the Cleanlab Studio GCP service account to access your BigQuery table. You can do this by adding the service account email to the IAM roles in your project.\n",
    "\n",
    "This allows Cleanlab Studio to read data from your BigQuery table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_read_access_to_bigquery_table(\n",
    "    bigquery_client: bigquery.Client,\n",
    "    bigquery_table_id: str,\n",
    "    entity_id: str,\n",
    "):\n",
    "    \"\"\"Adds read access to the given entity for the given BigQuery table.\"\"\"\n",
    "    # load IAM policy for table\n",
    "    policy = bigquery_client.get_iam_policy(bigquery_table_id)\n",
    "\n",
    "    # add dataViewer binding to policy\n",
    "    policy.bindings.append(\n",
    "        {\n",
    "            \"role\": \"roles/bigquery.dataViewer\",\n",
    "            \"members\": [f\"serviceAccount:{entity_id}\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # update IAM policy for table\n",
    "    bigquery_client.set_iam_policy(bigquery_table_id, policy)\n",
    "\n",
    "\n",
    "cleanlab_studio_entity_id = \"cleanlab-studio-bq-integration@cleanlab-studio-433118.iam.gserviceaccount.com\"\n",
    "\n",
    "# add read access to the BigQuery table \n",
    "add_read_access_to_bigquery_table(\n",
    "    bigquery_client=bigquery_client,\n",
    "    bigquery_table_id=bigquery_table_id,\n",
    "    entity_id=cleanlab_studio_entity_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upload data from BigQuery to Cleanlab Studio\n",
    "\n",
    "Now that you have created a table in BigQuery and configured access, you can upload the data to Cleanlab Studio. You can use the `cleanlab-studio` Python package to upload the data.\n",
    "\n",
    "After uploading the data, you can access it in Cleanlab Studio by opening the application and finding the dataset on the Dashboard (or clicking the link below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the dataset to Cleanlab Studio\n",
    "dataset_id = studio.upload_from_bigquery(\n",
    "    bigquery_project=GCP_PROJECT,\n",
    "    bigquery_dataset_id=BIGQUERY_DATASET,\n",
    "    bigquery_table_id=BIGQUERY_TABLE,\n",
    ")\n",
    "\n",
    "# view the dataset in Cleanlab Studio\n",
    "print(f\"https://app.cleanlab.ai/datasets/{dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "In this tutorial, you learned how to upload data from BigQuery to Cleanlab Studio. You created a table in BigQuery, configured access, and uploaded the data using the `cleanlab-studio` Python package. You can now access your BigQuery data in Cleanlab Studio and use it to create projects. For next steps, check out our [Projects guide](/guide/concepts/projects)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}