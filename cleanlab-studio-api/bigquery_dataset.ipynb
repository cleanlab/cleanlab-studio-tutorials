{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesting Data from Google BigQuery (BigFrames)\n",
    "\n",
    "In this tutorial, you\u2019ll learn how to ingest data from Google BigQuery DataFrames (`bigframes`) to Cleanlab Studio. You\u2019ll start by creating a `bigframes` DataFrame and then use the Python client to ingest your table. This guide will help you integrate your `bigframes`/BigQuery data into Cleanlab Studio efficiently.\n",
    "\n",
    "This notebook uses the `bigframes` package, along with the `cleanlab-studio` Python Package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install and import dependencies\n",
    "\n",
    "You'll need to install the `cleanlab-studio` package, along with the `bigframes` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Install the required packages\n",
    "\n",
    "Required packages are installed using `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U cleanlab-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install bigframes \"numpy>=1.26.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bigframes.pandas as bpd\n",
    "from google.cloud import bigquery\n",
    "from cleanlab_studio import Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Setup BigQuery options and Cleanlab Studio\n",
    "To make API calls to BigQuery and Cleanlab Studio, you need to setup BigQuery DataFrame options and create a Cleanlab Studio client. \n",
    "\n",
    "This tutorial assumes you have already authenticated your Google Cloud account. If you haven't, you can follow the instructions in the [Google Cloud documentation](https://cloud.google.com/docs/authentication/client-libraries).\n",
    "\n",
    "Ensure that you set the `GCP_PROJECT` variable along with the Cleanlab Studio API key in the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set BigQuery DataFrames options\n",
    "GCP_PROJECT = \"<your-gcp-project-id>\"\n",
    "GCP_REGION = \"US\"\n",
    "bpd.options.bigquery.project = GCP_PROJECT\n",
    "bpd.options.bigquery.location = GCP_REGION\n",
    "\n",
    "# Create a Studio client\n",
    "# You can find your Cleanlab Studio API key by going to app.cleanlab.ai/account\n",
    "API_KEY = \"<YOUR_API_KEY>\"\n",
    "studio = Studio(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a DataFrame (from a BigQuery table)\n",
    "\n",
    "The following code block creates a DataFrame from a (public) BigQuery table. You can use this DataFrame to ingest data to Cleanlab Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset and read into a DataFrame\n",
    "query_or_table = \"bigquery-public-data.ml_datasets.penguins\"\n",
    "df = bpd.read_gbq(query_or_table)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ingest `bigframes` DataFrame to Cleanlab Studio\n",
    "\n",
    "You can use the `cleanlab-studio` Python package to ingest the `bigframes` DataFrame to Cleanlab Studio.\n",
    "\n",
    "After ingesting the data, you can access it in Cleanlab Studio by opening the application and finding the dataset on the Dashboard (or clicking the link below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest the dataset to Cleanlab Studio\n",
    "dataset_id = studio.upload_from_bigframe(df)\n",
    "\n",
    "# View the dataset in Cleanlab Studio\n",
    "print(f\"https://app.cleanlab.ai/datasets/{dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Cleanlab Studio Project on `bigframes` ingested data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\u2019s now create a project using this dataset. A Cleanlab Studio project will automatically train ML models to provide AI-based analysis of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run a Cleanlab Studio multi-class classification project using the `sex` column as the label and the rest of the columns as the features\n",
    "project_id = studio.create_project(\n",
    "    dataset_id=dataset_id,\n",
    "    project_name=\"bigquery-public-data.ml_datasets.penguins project\",\n",
    "    modality=\"tabular\",\n",
    "    task_type=\"multi-class\",\n",
    "    model_type=\"regular\",\n",
    "    label_column=\"sex\"\n",
    ")\n",
    "\n",
    "print(f\"Project successfully created and training has begun! project_id: {project_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on status of the project and if cleanset has been created (after project finishes running)\n",
    "cleanset_id = studio.get_latest_cleanset_id(project_id)\n",
    "print(f\"cleanset_id: {cleanset_id}\")\n",
    "project_status = studio.poll_cleanset_status(cleanset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Store results in BigFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fetch the Cleanlab columns that contain the metadata of this cleanset using its `cleanset_id`. These columns have the same length as your original dataset and provide metadata about each individual data point, like what types of issues it exhibits and severe these issues are. \n",
    "\n",
    "Then we'll convert the metadata results directly into a BigQuery DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas DataFrame to a BigQuery DataFrame\n",
    "cleanlab_bq_df = bpd.DataFrame(studio.download_cleanlab_columns(cleanset_id))\n",
    "cleanlab_bq_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save the results in a BigQuery table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now initialize a BigQuery client and create a dataset in BigQuery (if it doesn't already exist) to define a table to write our Cleanlab Project results to. This shows how easy it is to integrate Cleanlab Studio with BigQuery (both before and after running a Cleanlab Studio project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a BigQuery client\n",
    "client = bigquery.Client(project=GCP_PROJECT)\n",
    "\n",
    "# Create a new dataset (if it doesn't exist)\n",
    "dataset_id = f\"{GCP_PROJECT}.penguins_cleanlab_results\"\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = GCP_REGION\n",
    "\n",
    "try:\n",
    "    dataset = client.create_dataset(dataset, exists_ok=True)\n",
    "    print(f\"Dataset {dataset_id} is ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with dataset {dataset_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the table\n",
    "table_id = f\"{dataset_id}.penguins_with_cleanlab\"\n",
    "\n",
    "# Save the dataset to the new BigQuery table\n",
    "cleanlab_bq_df.to_gbq(table_id, if_exists='replace')\n",
    "\n",
    "print(f\"Data successfully saved to {table_id}\")\n",
    "\n",
    "# Verify the data was saved by reading it back\n",
    "verified_df = bpd.read_gbq(table_id)\n",
    "\n",
    "print(f\"Shape of data written to BigQuery: {cleanlab_bq_df.shape}\")\n",
    "print(f\"Shape of data read back from BigQuery: {verified_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "In this tutorial, you learned how to ingest data from BigQuery to Cleanlab Studio, run a Cleanlab Studio project on this data, and then download the Cleanset results and load them back into a BigQuery `bigframes` DataFrame before saving the results in a BigQuery table. You created a table in BigQuery, configured access, and ingested the data using the `cleanlab-studio` Python package. For more details on configuring and running Cleanlab Studio projects, check out our [Projects guide](/guide/concepts/projects)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}