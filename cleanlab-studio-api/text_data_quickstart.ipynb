{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Issues in Text Datasets\n",
    "\n",
    "This is the recommended quickstart tutorial for analyzing text datasets via the Cleanlab Studio's [Python API](/guide/quickstart/api/).\n",
    "\n",
    "In this tutorial, we demonstrate the metadata Cleanlab Studio automatically generates for any text classification dataset. This metadata (returned as \"Cleanlab columns\") helps you discover various problems in your dataset and understand their severity. This entire notebook is run using the `cleanlab_studio` Python package, so you can audit your datasets programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import dependencies\n",
    "\n",
    "Make sure you have `wget` installed to run this tutorial. You can use pip to install all other packages required for this tutorial as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cleanlab-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset into Cleanlab Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fetch the data for this tutorial, make sure you have `wget` installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://cleanlab-public.s3.amazonaws.com/Datasets/banking-text-quickstart.csv -P data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll use a variant of the [BANKING77](https://paperswithcode.com/dataset/banking77-oos) text dataset. This is a **multi-class classification** dataset where customer service requests are labeled as belonging to one of *K* classes (intent categories).\n",
    "\n",
    "### Dataset Structure\n",
    "\n",
    "The data is stored in a standard CSV file containing the following columns:\n",
    "\n",
    "```\n",
    "text,label\n",
    "<a text example>,<a class label>\n",
    "\"<a text example with quotes, to escape commas as column separators>\",<another class label>\n",
    "...\n",
    "```\n",
    "\n",
    "You can similarly format any other text dataset and run the rest of this tutorial. Details on how to format your dataset can be found in [this guide](/guide/concepts/datasets/), which also outlines other format options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.getcwd()\n",
    "dataset_path = os.path.join(BASE_PATH, \"data/banking-text-quickstart.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next use your API key to instantiate a `studio` object, which analyzes your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab_studio import Studio\n",
    "\n",
    "# you can find your Cleanlab Studio API key by going to app.cleanlab.ai/upload,\n",
    "# clicking \"Upload via Python API\", and copying the API key there\n",
    "API_KEY = \"<insert your API key>\"\n",
    "\n",
    "# initialize studio object\n",
    "studio = Studio(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into Cleanlab Studio (more details/options can be found in [this guide](/guide/quickstart/api/#uploading-a-dataset)). This may take a while for big datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = studio.upload_dataset(dataset_path, dataset_name=\"banking77oos\")\n",
    "print(f\"Dataset ID: {dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch a Project\n",
    "\n",
    "A Cleanlab Studio project automatically trains ML models to provide AI-based analysis of your dataset. Let's launch one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = studio.create_project(\n",
    "    dataset_id=dataset_id,\n",
    "    project_name=\"banking77-oos project\",\n",
    "    modality=\"text\",\n",
    "    task_type=\"multi-class\",\n",
    "    model_type=\"regular\",\n",
    ")\n",
    "print(f\"Project successfully created and training has begun! project_id: {project_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the project has been launched successfully and you see your `project_id` you can feel free to close this notebook. It will take some time for Cleanlabâ€™s AI to train on your data and analyze it. Come back after training is complete (you will receive an email) and continue with the notebook to review your results.\n",
    "\n",
    "You should only execute the above cell once per dataset. After launching the project, you can poll for its status to programmatically wait until the results are ready for review. Each project creates a [cleanset](/guide/concepts/cleanset/), an improved version of your original dataset that contains additional metadata for helping you clean up the data. The next code cell simply waits until this [cleanset](/guide/concepts/cleanset) has been created.\n",
    "\n",
    "**Warning!** For big datasets, this next cell may take a long time to execute while Cleanlab's AI model is training. If your Jupyter notebook has timed out during this process then you can resume work by re-running the below cell (which should return instantly if the project has completed training; **do not** create a new project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanset_id = studio.get_latest_cleanset_id(project_id)\n",
    "print(f\"cleanset_id: {cleanset_id}\")\n",
    "project_status = studio.wait_until_cleanset_ready(cleanset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the above cell completes execution, your project results are ready for review!  At this point, you can optionally view your project in the [Cleanlab Studio web interface](https://app.cleanlab.ai/) and interactively improve your dataset. However this tutorial will stick with a fully programmatic workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Cleanlab columns\n",
    "\n",
    "We can fetch [Cleanlab columns](/guide/concepts/cleanlab_columns/) that store metadata for this [cleanset](/guide/concepts/cleanset) using its `cleanset_id`. These columns have the same length as your original dataset and provide metadata about each indiviudal data point, like what types of issues it exhibits and how severely.\n",
    "\n",
    "If at any point you want to re-run the remaining parts of this notebook (without creating another project), simply call `studio.download_cleanlab_columns(cleanset_id)` with the `cleanset_id` printed from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanlab_row_ID</th>\n",
       "      <th>corrected_label</th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>label_issue_score</th>\n",
       "      <th>suggested_label</th>\n",
       "      <th>is_ambiguous</th>\n",
       "      <th>ambiguous_score</th>\n",
       "      <th>is_well_labeled</th>\n",
       "      <th>is_near_duplicate</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_cluster_id</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>outlier_score</th>\n",
       "      <th>is_initially_unlabeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.335749</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.910778</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.974842</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.034647</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.341566</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.912265</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.963262</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.038207</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.231065</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.847001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.936913</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.072151</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.267550</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.843165</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.974782</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.043101</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.349997</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.910711</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.980708</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.021091</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cleanlab_row_ID corrected_label  is_label_issue  label_issue_score  \\\n",
       "0                0            <NA>           False           0.335749   \n",
       "1                1            <NA>           False           0.341566   \n",
       "2                2            <NA>           False           0.231065   \n",
       "3                3            <NA>           False           0.267550   \n",
       "4                4            <NA>           False           0.349997   \n",
       "\n",
       "  suggested_label  is_ambiguous  ambiguous_score  is_well_labeled  \\\n",
       "0            <NA>         False         0.910778             True   \n",
       "1            <NA>         False         0.912265             True   \n",
       "2            <NA>         False         0.847001             True   \n",
       "3            <NA>         False         0.843165             True   \n",
       "4            <NA>         False         0.910711             True   \n",
       "\n",
       "   is_near_duplicate  near_duplicate_score  near_duplicate_cluster_id  \\\n",
       "0              False              0.974842                       <NA>   \n",
       "1              False              0.963262                       <NA>   \n",
       "2              False              0.936913                       <NA>   \n",
       "3              False              0.974782                       <NA>   \n",
       "4              False              0.980708                       <NA>   \n",
       "\n",
       "   is_outlier  outlier_score  is_initially_unlabeled  \n",
       "0       False       0.034647                   False  \n",
       "1       False       0.038207                   False  \n",
       "2       False       0.072151                   False  \n",
       "3       False       0.043101                   False  \n",
       "4       False       0.021091                   False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanlab_columns_df = studio.download_cleanlab_columns(cleanset_id)\n",
    "cleanlab_columns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of data issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details about all of the Cleanlab columns and their meanings can be found in [this guide](/guide/concepts/cleanlab_columns/). Here we briefly showcase some of the Cleanlab columns that correspond to issues detected in our tutorial dataset:\n",
    "- **Label issue** indicates the given label of this data point is likely wrong. For such data, consider correcting their label to the `suggested_label` if it seems more appropriate.\n",
    "- **Ambiguous** indicates this data point does not clearly belong to any of the classes (e.g. a borderline case). Multiple human annotators might disagree on how to label this data point, so you might consider refining your annotation instructions to clarify how to handle data points like this.\n",
    "- **Outlier** indicates this data point is very different from the rest of the data (looks atypical). The presence of outliers may indicate problems in your data sources, consider deleting such data from your dataset if appropriate.\n",
    "- **Near duplicate** indicates there are other data points that are (exactly or nearly) identical to this data point. Duplicated data points can have an outsized impact on models/analytics, so consider deleting the extra copies from your dataset if appropriate.\n",
    "\n",
    "The data points exhibiting each type of issue are indicated with boolean values in the respective `is_<issue>` column, and the severity of this issue in each data point is quantified in the respective `<issue>_score` column (on a scale of 0-1 with 1 indicating the most severe instances of the issue).\n",
    "\n",
    "Let's go through some of the Cleanlab columns and types of data issues, starting with label issues (i.e. mislabeled data). We first create a `given_label` column in our dataframe to clearly indicate the original class label originally assigned to each data point (customer service request)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Combine the dataset with the cleanlab columns\n",
    "combined_dataset_df = df.merge(cleanlab_columns_df, left_index=True, right_on=\"cleanlab_row_ID\")\n",
    "\n",
    "# Set a \"given_label\" column to the original label\n",
    "combined_dataset_df.rename(columns={\"label\": \"given_label\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see which text examples are estimated to be mislabeled, we filter by `is_label_issue`. We sort by `label_issue_score` to see which of these data points are *most likely* mislabeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanlab_row_ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label_issue_score</th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>978</td>\n",
       "      <td>why am i being charge a fee when using an atm?</td>\n",
       "      <td>0.851647</td>\n",
       "      <td>True</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>974</td>\n",
       "      <td>can i change my pin on holiday?</td>\n",
       "      <td>0.769496</td>\n",
       "      <td>True</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>960</td>\n",
       "      <td>how do i find my new pin?</td>\n",
       "      <td>0.767412</td>\n",
       "      <td>True</td>\n",
       "      <td>visa_or_mastercard</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>980</td>\n",
       "      <td>why do i see extra charges for withdrawing my money?</td>\n",
       "      <td>0.765521</td>\n",
       "      <td>True</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>972</td>\n",
       "      <td>what atms will allow me to change my pin?</td>\n",
       "      <td>0.757016</td>\n",
       "      <td>True</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cleanlab_row_ID                                                  text  \\\n",
       "978              978        why am i being charge a fee when using an atm?   \n",
       "974              974                       can i change my pin on holiday?   \n",
       "960              960                             how do i find my new pin?   \n",
       "980              980  why do i see extra charges for withdrawing my money?   \n",
       "972              972             what atms will allow me to change my pin?   \n",
       "\n",
       "     label_issue_score  is_label_issue              given_label  \\\n",
       "978           0.851647            True     card_about_to_expire   \n",
       "974           0.769496            True  beneficiary_not_allowed   \n",
       "960           0.767412            True       visa_or_mastercard   \n",
       "980           0.765521            True     card_about_to_expire   \n",
       "972           0.757016            True  beneficiary_not_allowed   \n",
       "\n",
       "              suggested_label  \n",
       "978  card_payment_fee_charged  \n",
       "974                change_pin  \n",
       "960                change_pin  \n",
       "980  card_payment_fee_charged  \n",
       "972                change_pin  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_ranked_by_label_issue_score = combined_dataset_df.query(\"is_label_issue\").sort_values(\"label_issue_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"cleanlab_row_ID\", \"text\", \"label_issue_score\", \"is_label_issue\", \"given_label\", \"suggested_label\"]\n",
    "display(samples_ranked_by_label_issue_score.head(5)[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in each of these examples, the `given_label` really does seem wrong (the annotated intent in the original dataset does not appear appropriate for the customer request). Data labeling is an error-prone process and annotators make mistakes! Luckily we can easily correct these data points by just using Cleanlab's `suggested_label` above, which seems like a much more suitable label in most cases.\n",
    "\n",
    "While the boolean flags above can help estimate the overall label error rate, the numeric scores help decide what data to prioritize for review. You can alternatively ignore these boolean `is_label_issue` flags and filter the data by thresholding the `label_issue_score` yourself (if say you find the default thresholds produce false positives/negatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the ambiguous examples detected in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanlab_row_ID</th>\n",
       "      <th>text</th>\n",
       "      <th>ambiguous_score</th>\n",
       "      <th>is_ambiguous</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>954</td>\n",
       "      <td>i tried to withdraw 40 pounds but only 20 came out. did you steal my money?</td>\n",
       "      <td>0.982856</td>\n",
       "      <td>True</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>965</td>\n",
       "      <td>why haven't i gotten my payment yet?</td>\n",
       "      <td>0.979637</td>\n",
       "      <td>True</td>\n",
       "      <td>lost_or_stolen_phone</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>662</td>\n",
       "      <td>payment did not process</td>\n",
       "      <td>0.976018</td>\n",
       "      <td>True</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>958</td>\n",
       "      <td>how long do money transfers take? my friend really needs the money i sent a couple of hours ago but it's not there yet.</td>\n",
       "      <td>0.975079</td>\n",
       "      <td>True</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>967</td>\n",
       "      <td>the card payment didn't work</td>\n",
       "      <td>0.972252</td>\n",
       "      <td>True</td>\n",
       "      <td>change_pin</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cleanlab_row_ID  \\\n",
       "954              954   \n",
       "965              965   \n",
       "662              662   \n",
       "958              958   \n",
       "967              967   \n",
       "\n",
       "                                                                                                                        text  \\\n",
       "954                                              i tried to withdraw 40 pounds but only 20 came out. did you steal my money?   \n",
       "965                                                                                     why haven't i gotten my payment yet?   \n",
       "662                                                                                                  payment did not process   \n",
       "958  how long do money transfers take? my friend really needs the money i sent a couple of hours ago but it's not there yet.   \n",
       "967                                                                                             the card payment didn't work   \n",
       "\n",
       "     ambiguous_score  is_ambiguous                     given_label  \\\n",
       "954         0.982856          True        card_payment_fee_charged   \n",
       "965         0.979637          True            lost_or_stolen_phone   \n",
       "662         0.976018          True         beneficiary_not_allowed   \n",
       "958         0.975079          True  supported_cards_and_currencies   \n",
       "967         0.972252          True                      change_pin   \n",
       "\n",
       "              suggested_label  \n",
       "954                      <NA>  \n",
       "965                      <NA>  \n",
       "662  card_payment_fee_charged  \n",
       "958                      <NA>  \n",
       "967                      <NA>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_ranked_by_ambiguous_score = combined_dataset_df.query(\"is_ambiguous\").sort_values(\"ambiguous_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"cleanlab_row_ID\", \"text\", \"ambiguous_score\", \"is_ambiguous\", \"given_label\", \"suggested_label\"]\n",
    "display(samples_ranked_by_ambiguous_score.head(5)[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the outliers detected in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanlab_row_ID</th>\n",
       "      <th>text</th>\n",
       "      <th>outlier_score</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>636C65616E6C616220697320617765736F6D6521</td>\n",
       "      <td>0.200036</td>\n",
       "      <td>True</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>990</td>\n",
       "      <td>Connection Timed Out</td>\n",
       "      <td>0.190570</td>\n",
       "      <td>True</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>cancel transaction</td>\n",
       "      <td>0.178279</td>\n",
       "      <td>True</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>https://github.com/cleanlab/cleanlab</td>\n",
       "      <td>0.174992</td>\n",
       "      <td>True</td>\n",
       "      <td>visa_or_mastercard</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>662</td>\n",
       "      <td>payment did not process</td>\n",
       "      <td>0.167117</td>\n",
       "      <td>True</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cleanlab_row_ID                                      text  outlier_score  \\\n",
       "999              999  636C65616E6C616220697320617765736F6D6521       0.200036   \n",
       "990              990                      Connection Timed Out       0.190570   \n",
       "81                81                        cancel transaction       0.178279   \n",
       "998              998      https://github.com/cleanlab/cleanlab       0.174992   \n",
       "662              662                   payment did not process       0.167117   \n",
       "\n",
       "     is_outlier              given_label           suggested_label  \n",
       "999        True          cancel_transfer                      <NA>  \n",
       "990        True  apple_pay_or_google_pay                      <NA>  \n",
       "81         True          cancel_transfer                      <NA>  \n",
       "998        True       visa_or_mastercard                      <NA>  \n",
       "662        True  beneficiary_not_allowed  card_payment_fee_charged  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_ranked_by_outlier_score = combined_dataset_df.query(\"is_outlier\").sort_values(\"outlier_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"cleanlab_row_ID\", \"text\", \"outlier_score\", \"is_outlier\", \"given_label\", \"suggested_label\"]\n",
    "display(samples_ranked_by_outlier_score.head(5)[columns_to_display])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the near duplicates detected in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 sets of near duplicate texts in the dataset.\n"
     ]
    }
   ],
   "source": [
    "n_near_duplicate_sets = len(set(combined_dataset_df.loc[combined_dataset_df[\"near_duplicate_cluster_id\"].notna(), \"near_duplicate_cluster_id\"]))\n",
    "print(f\"There are {n_near_duplicate_sets} sets of near duplicate texts in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the near duplicate data points each have an associated `near_duplicate_cluster_id` integer.  Data points that share the same IDs are near duplicates of each other, so you can use this column to find the near duplicates of any data point. And remember the near duplicates also include *exact* duplicates as well (which have `near_duplicate_score` $=1$).\n",
    " \n",
    "\n",
    "Let's check out the near duplicates with id $= 3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanlab_row_ID</th>\n",
       "      <th>text</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>is_near_duplicate</th>\n",
       "      <th>given_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>475</td>\n",
       "      <td>what should i do if my phone is lost or stolen?</td>\n",
       "      <td>0.997346</td>\n",
       "      <td>True</td>\n",
       "      <td>lost_or_stolen_phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>481</td>\n",
       "      <td>what should i do if my smart phone is lost or stolen?</td>\n",
       "      <td>0.997346</td>\n",
       "      <td>True</td>\n",
       "      <td>lost_or_stolen_phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cleanlab_row_ID                                                   text  \\\n",
       "475              475        what should i do if my phone is lost or stolen?   \n",
       "481              481  what should i do if my smart phone is lost or stolen?   \n",
       "\n",
       "     near_duplicate_score  is_near_duplicate           given_label  \n",
       "475              0.997346               True  lost_or_stolen_phone  \n",
       "481              0.997346               True  lost_or_stolen_phone  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "near_duplicate_cluster_id = 3  # play with this value to see other sets of near duplicates\n",
    "selected_samples_by_near_duplicate_cluster_id = combined_dataset_df.query(\"near_duplicate_cluster_id == @near_duplicate_cluster_id\")\n",
    "\n",
    "columns_to_display = [\"cleanlab_row_ID\", \"text\", \"near_duplicate_score\", \"is_near_duplicate\", \"given_label\"]\n",
    "selected_samples_by_near_duplicate_cluster_id[columns_to_display]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the dataset based on the detected issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the results of this analysis appear reasonable, let's use the Cleanlab columns to improve the quality of our dataset. For your own datasets, which actions you should take to remedy the detected issues will depend on what you are using the data for. No action may be the best choice for certain datasets, we caution against blindly copying the actions we perform below. \n",
    "\n",
    "For data marked as `label_issue`, we create a new `corrected_label` column, which will be the given label for data without detected label issues, and the `suggested_label` for data with detected label issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_label = np.where(combined_dataset_df[\"is_label_issue\"],\n",
    "                           combined_dataset_df[\"suggested_label\"],\n",
    "                           combined_dataset_df[\"given_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data marked as outlier or ambiguous, we will simply exclude them from our dataset. Here we create a boolean vector `rows_to_exclude` to track which data points will be excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an exclude column to keep track of the excluded data\n",
    "rows_to_exclude = combined_dataset_df[\"is_outlier\"] | combined_dataset_df[\"is_ambiguous\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each set of near duplicates, we only want to keep one of the data points that share a common `near_duplicate_cluster_id` (so that the resulting dataset will no longer contain any near duplicates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_duplicates_to_exclude = combined_dataset_df['is_near_duplicate'] & combined_dataset_df['near_duplicate_cluster_id'].duplicated(keep='first')\n",
    "\n",
    "rows_to_exclude |= near_duplicates_to_exclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the total amount of excluded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding 29 text examples (out of 1000)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Excluding {rows_to_exclude.sum()} text examples (out of {len(combined_dataset_df)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's actually make a new version of our dataset with these changes. \n",
    "\n",
    "We craft a new dataframe from the original, applying corrections and exclusions, and then use this dataframe to save the new dataset in a separate CSV file. The new dataset is a CSV file that has the same format as our original dataset -- you can use it as a plug-in replacement to get more reliable results in your ML and Analytics pipelines, without any change in your existing modeling code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset_filename = \"improved_dataset.csv\"  # where to save the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the original dataset\n",
    "fixed_dataset = combined_dataset_df[[\"text\"]].copy()\n",
    "\n",
    "# Add the corrected label column \n",
    "fixed_dataset[\"label\"] = corrected_label\n",
    "\n",
    "# Automatically exclude selected rows\n",
    "fixed_dataset = fixed_dataset[~rows_to_exclude]\n",
    "\n",
    "# Check if the file exists before saving\n",
    "if os.path.exists(new_dataset_filename):\n",
    "    raise ValueError(f\"File {new_dataset_filename} already exists. Cannot overwite so please delete it first, or specify a different new_dataset_filename.\")\n",
    "else:\n",
    "    # Save the adjusted dataset to a CSV file\n",
    "    fixed_dataset.to_csv(new_dataset_filename, index=False)\n",
    "    print(f\"Adjusted dataset saved to {new_dataset_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
