{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Issues in (Unsupervised) Datasets Without Labels\n",
    "\n",
    "<head>\n",
    "  <meta name=\"title\" content=\"How to detect issues in datasets without labels (unsupervised learning)\"/>\n",
    "  <meta property=\"og:title\" content=\"How to detect issues in datasets without labels (unsupervised learning)\"/>\n",
    "  <meta name=\"twitter:title\" content=\"How to detect issues in datasets without labels (unsupervised learning)\" />\n",
    "  <meta name=\"image\" content=\"/img/reviewsissues.png\" />\n",
    "  <meta property=\"og:image\" content=\"/img/reviewsissues.png\" />\n",
    "  <meta name=\"description\" content=\"Cleanlab is not just for labeled data, curate many other types of data as well.\"  />\n",
    "  <meta property=\"og:description\" content=\"Cleanlab is not just for labeled data, curate many other types of data as well.\" />\n",
    "  <meta name=\"twitter:description\" content=\"Cleanlab is not just for labeled data, curate many other types of data as well.\" />\n",
    "</head>\n",
    "\n",
    "This tutorial demonstrates how to use Cleanlab Studio's [Python API](/guide/quickstart/api/) to analyze and find issues in datasets without labels. This can be useful if you don't have a single column in your dataset that you want to predict values for but still want to find issues such as low-quality/unsafe image or text content (e.g. NSFW or blurry images, toxic or unreadable text). In machine learning nomenclature, working with such data is called *unsupervised learning* (because there is no supervised label to predict).\n",
    "\n",
    "Cleanlab Studio supports analyzing data without labels for text and image modalities. In this tutorial, we'll look at a text dataset consisting of Tweets about airlines. This tutorial can be generally used to detect issues in *any* text column of a dataset or collection of images.\n",
    "\n",
    "Note: analyzing data without labels is currently only supported in the Python API. If you require an interactive interface to improve your unsupervised dataset, please [contact us](mailto:sales@cleanlab.ai) to discuss your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U cleanlab-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cleanlab_studio import Studio\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and Upload Dataset\n",
    "\n",
    "Our dataset for this tutorial is a collection of Tweets directed at various airlines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "We'll load the dataset into a Pandas DataFrame from a CSV file hosted in S3. The CSV file contains the following columns:\n",
    "```\n",
    "tweet_id,text\n",
    "0,@VirginAmerica What @dhepburn said.\n",
    "1,@VirginAmerica plus you've added commercials to the experience... tacky.\n",
    "<id of tweet>,<tweet text>\n",
    "```\n",
    "You can similarly format any other text or image dataset and run the rest of this tutorial. Details on how to format your dataset can be found in [this guide](/guide/concepts/datasets/), which also outlines other format options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id  \\\n",
       "0         0   \n",
       "1         1   \n",
       "2         2   \n",
       "\n",
       "                                                                       text  \n",
       "0                                       @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials to the experience... tacky.  \n",
       "2   @VirginAmerica I didn't today... Must mean I need to take another trip!  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_url = \"https://cleanlab-public.s3.amazonaws.com/StudioDemoDatasets/tweets-tutorial.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset into Cleanlab Studio\n",
    "\n",
    "First instantiate a `Studio` object, which can be used to analyze your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can find your API key by going to app.cleanlab.ai/upload, \n",
    "# clicking \"Upload via Python API\", and copying the API key there\n",
    "API_KEY = \"<insert your API key>\"\n",
    "\n",
    "studio = Studio(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next load the dataset into Cleanlab Studio (more details/options can be found in [this guide](/guide/quickstart/api/#uploading-a-dataset)). This may take a while for big datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading dataset...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588|\n",
      "Generating schema...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588|\n",
      "Ingesting Dataset...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588|\n"
     ]
    }
   ],
   "source": [
    "dataset_id = studio.upload_dataset(df, dataset_name=\"Tweets (no-labels)\", id_column=\"tweet_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch a Project\n",
    "\n",
    "Let's now create a project using this dataset. A Cleanlab Studio project will automatically train ML models to provide AI-based analysis of your dataset.\n",
    "\n",
    "Here, we explicitly set the `task_type` parameter to `unsupervised` to specify that there is *no* supervised ML training task to run. If you would like to run supervised ML training and detect label errors in a labeled dataset or **annotate unlabeled data**, instead choose another ML task type (e.g. `\"multi-class\"`, `\"multi-label\"`, or `\"regression\"`; see [this guide](/guide/concepts/projects/#machine-learning-task--dataset-type) for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = studio.create_project(\n",
    "    dataset_id=dataset_id,\n",
    "    project_name=\"Tweets (no-labels) Project\",\n",
    "    modality=\"text\",\n",
    "    task_type=\"unsupervised\",\n",
    "    model_type=\"regular\",  # text issue detection is currently only available in Regular mode\n",
    "    label_column=None,\n",
    ")\n",
    "print(f\"Project successfully created and training has begun! project_id: {project_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we specified `modality=\"text\"` because this tutorial uses a text dataset; you can specify `modality=\"image\"` if you're using a image dataset. See the documentation for [`create_project`](/reference/python/studio/#method-create_project) for the full set of options.\n",
    "\n",
    "Once the project has been launched successfully and you see your `project_id`, feel free to close this notebook. It will take some time for Cleanlab\u2019s AI to train on your data and analyze it. Come back after training is complete (you will receive an email) and continue with the notebook to review your results.\n",
    "\n",
    "You should only execute the above cell once per dataset. After launching the project, you can poll for its status to programmatically wait until the results are ready for review. Each project creates a [cleanset](/guide/concepts/cleanset/), an improved version of your original dataset that contains additional metadata for helping you clean up the data. The next code cell simply waits until this *cleanset* has been created.\n",
    "\n",
    "**Warning!** For big datasets, this next cell may take a long time to execute while Cleanlab's AI model is training. If your notebook has timed out during this process, you can resume work by re-running the below cell (which should return the `cleanset_id` instantly if the project has completed training). Do not re-run the above cell and create a new project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanset_id = studio.get_latest_cleanset_id(project_id)\n",
    "print(f\"cleanset_id: {cleanset_id}\")\n",
    "project_status = studio.wait_until_cleanset_ready(cleanset_id, show_cleanset_link=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the above cell completes execution, your project results are ready for review!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Cleanlab columns\n",
    "\n",
    "We can fetch the [Cleanlab columns](/guide/concepts/cleanlab_columns/) that contain the metadata of this *cleanset* using its `cleanset_id`. These columns have the same length as your original dataset and provide metadata about each individual data point, like what types of issues it exhibits and how severe these issues are.\n",
    "\n",
    "If at any point you want to re-run the remaining parts of this notebook (without creating another project), simply call `studio.download_cleanlab_columns(cleanset_id)` with the `cleanset_id` printed from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>is_empty_text</th>\n",
       "      <th>text_num_characters</th>\n",
       "      <th>is_PII</th>\n",
       "      <th>PII_score</th>\n",
       "      <th>PII_types</th>\n",
       "      <th>PII_items</th>\n",
       "      <th>is_informal</th>\n",
       "      <th>informal_score</th>\n",
       "      <th>is_non_english</th>\n",
       "      <th>non_english_score</th>\n",
       "      <th>predicted_language</th>\n",
       "      <th>is_toxic</th>\n",
       "      <th>toxic_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[\"Twitter username\"]</td>\n",
       "      <td>[\"@VirginAmerica\", \"@dhepburn\"]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.548850</td>\n",
       "      <td>False</td>\n",
       "      <td>0.471635</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.088318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>72</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[\"Twitter username\"]</td>\n",
       "      <td>[\"@VirginAmerica\"]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.695925</td>\n",
       "      <td>False</td>\n",
       "      <td>0.049899</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.613281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[\"Twitter username\"]</td>\n",
       "      <td>[\"@VirginAmerica\"]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.579822</td>\n",
       "      <td>False</td>\n",
       "      <td>0.035695</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.111877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>126</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[\"Twitter username\"]</td>\n",
       "      <td>[\"@VirginAmerica\"]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333150</td>\n",
       "      <td>False</td>\n",
       "      <td>0.088203</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.651367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[\"Twitter username\"]</td>\n",
       "      <td>[\"@VirginAmerica\"]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.625234</td>\n",
       "      <td>False</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.296875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id  is_empty_text  text_num_characters  is_PII  PII_score  \\\n",
       "0         0          False                   35    True        0.2   \n",
       "1         1          False                   72    True        0.2   \n",
       "2         2          False                   71    True        0.2   \n",
       "3         3          False                  126    True        0.2   \n",
       "4         4          False                   55    True        0.2   \n",
       "\n",
       "              PII_types                        PII_items  is_informal  \\\n",
       "0  [\"Twitter username\"]  [\"@VirginAmerica\", \"@dhepburn\"]         True   \n",
       "1  [\"Twitter username\"]               [\"@VirginAmerica\"]         True   \n",
       "2  [\"Twitter username\"]               [\"@VirginAmerica\"]         True   \n",
       "3  [\"Twitter username\"]               [\"@VirginAmerica\"]        False   \n",
       "4  [\"Twitter username\"]               [\"@VirginAmerica\"]         True   \n",
       "\n",
       "   informal_score  is_non_english  non_english_score predicted_language  \\\n",
       "0        0.548850           False           0.471635               <NA>   \n",
       "1        0.695925           False           0.049899               <NA>   \n",
       "2        0.579822           False           0.035695               <NA>   \n",
       "3        0.333150           False           0.088203               <NA>   \n",
       "4        0.625234           False           0.059800               <NA>   \n",
       "\n",
       "   is_toxic  toxic_score  \n",
       "0     False     0.088318  \n",
       "1     False     0.613281  \n",
       "2     False     0.111877  \n",
       "3     False     0.651367  \n",
       "4     False     0.296875  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanlab_columns_df = studio.download_cleanlab_columns(cleanset_id)\n",
    "cleanlab_columns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review detected data issues \n",
    "\n",
    "Details about all of the Cleanlab columns and their meanings can be found in [this guide](/guide/concepts/cleanlab_columns/). Here we briefly showcase some of the Cleanlab columns that correspond to issues detected in our tutorial dataset. Since our dataset only has a text column, this tutorial focuses on issues specific to text fields such as the occurence of personally identifiable information (PII) and toxic language (see [here](/guide/concepts/cleanlab_columns/#columns-specific-to-text-data) for details).\n",
    "\n",
    "The data points exhibiting each type of issue are indicated with boolean values in the respective `is_<issue>` column, and the severity of this issue in each data point is quantified in the respective `<issue>_score` column (on a scale of 0-1 with 1 indicating the most severe instances of the issue).\n",
    "\n",
    "Let's take a closer look at some issues flagged in our dataset. We merged the columns from our original dataset with the Cleanlab columns (metadata) produced by Cleanlab Studio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Combine the dataset with the cleanlab columns\n",
    "combined_dataset_df = df.merge(cleanlab_columns_df, on=\"tweet_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Personally Identifiable Information (PII)** is information that could be used to identify an individual or is otherwise sensitive. Exposing PII can compromise an individual's security and hence should be safeguarded and anonymized/removed if discovered in publicly shared data.\n",
    "\n",
    "Cleanlab's [PII detection](https://help.cleanlab.ai/guide/concepts/cleanlab_columns/#personally-identifiable-information-pii) also returns two extra columns, `PII_items` and `PII_types`, which list the specific PII detected in the text and its type. Possible types of PII that can be detected are detailed in the [guide](https://help.cleanlab.ai/guide/concepts/cleanlab_columns/#personally-identifiable-information-pii) and scored according to how sensitive each type of information is.\n",
    "\n",
    "Here are some examples of PII detected in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>PII_score</th>\n",
       "      <th>is_PII</th>\n",
       "      <th>PII_types</th>\n",
       "      <th>PII_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>407</td>\n",
       "      <td>@VirginAmerica FYI the info@virginamerica.com email address you say to contact in password reset emails doesn't exist. Emails bounce.</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"Twitter username\", \"email\"]</td>\n",
       "      <td>[\"@VirginAmerica\", \"info@virginamerica.com\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>3377</td>\n",
       "      <td>@united Need to track lost luggage being shipped to me. Need ph # for human. Not automated 800-335-2247.</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"Twitter username\", \"phone number\"]</td>\n",
       "      <td>[\"@united\", \"800-335-2247\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>742</td>\n",
       "      <td>@united I send you an urgent message via eservice@united.com.  BG0KWM   Narayanan. Please respond ASAP. Also, NO local United Tel # @ KUL</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"Twitter username\", \"email\"]</td>\n",
       "      <td>[\"@united\", \"eservice@united.com\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>3872</td>\n",
       "      <td>@united  delayed about 8 hours because of missed connections due to mechanical issues on 1st flight. rebooked, but please call me 9148445695</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"Twitter username\", \"phone number\"]</td>\n",
       "      <td>[\"@united\", \"9148445695\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>960</td>\n",
       "      <td>@united iCloud it is not there yet -- PLEASE HELP 917 703 1472</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"Twitter username\", \"phone number\"]</td>\n",
       "      <td>[\"@united\", \"917 703 1472\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id  \\\n",
       "407        407   \n",
       "3377      3377   \n",
       "742        742   \n",
       "3872      3872   \n",
       "960        960   \n",
       "\n",
       "                                                                                                                                              text  \\\n",
       "407          @VirginAmerica FYI the info@virginamerica.com email address you say to contact in password reset emails doesn't exist. Emails bounce.   \n",
       "3377                                      @united Need to track lost luggage being shipped to me. Need ph # for human. Not automated 800-335-2247.   \n",
       "742      @united I send you an urgent message via eservice@united.com.  BG0KWM   Narayanan. Please respond ASAP. Also, NO local United Tel # @ KUL   \n",
       "3872  @united  delayed about 8 hours because of missed connections due to mechanical issues on 1st flight. rebooked, but please call me 9148445695   \n",
       "960                                                                                 @united iCloud it is not there yet -- PLEASE HELP 917 703 1472   \n",
       "\n",
       "      PII_score  is_PII                             PII_types  \\\n",
       "407         0.5    True         [\"Twitter username\", \"email\"]   \n",
       "3377        0.5    True  [\"Twitter username\", \"phone number\"]   \n",
       "742         0.5    True         [\"Twitter username\", \"email\"]   \n",
       "3872        0.5    True  [\"Twitter username\", \"phone number\"]   \n",
       "960         0.5    True  [\"Twitter username\", \"phone number\"]   \n",
       "\n",
       "                                         PII_items  \n",
       "407   [\"@VirginAmerica\", \"info@virginamerica.com\"]  \n",
       "3377                   [\"@united\", \"800-335-2247\"]  \n",
       "742             [\"@united\", \"eservice@united.com\"]  \n",
       "3872                     [\"@united\", \"9148445695\"]  \n",
       "960                    [\"@united\", \"917 703 1472\"]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PII_samples = combined_dataset_df.query(\"is_PII\").sort_values(\"PII_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"tweet_id\", \"text\", \"PII_score\", \"is_PII\", \"PII_types\", \"PII_items\"]\n",
    "display(PII_samples.head(5)[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text that contains **toxic language** may have elements of hateful speech and language others may find harmful or aggressive. Identifying toxic language is vital in tasks such as content moderation and LLM training/evaluation, where appropriate action should be taken to ensure safe platforms, chatbots, or other applications depending on this dataset.\n",
    "\n",
    "Here are some examples in this dataset detected to contain toxic language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic_score</th>\n",
       "      <th>is_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>1197</td>\n",
       "      <td>@united you are the worst airline in the world! From your crap website to your worthless app to your Late Flight flight. You SUCK! Just shut down.</td>\n",
       "      <td>0.911133</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>2122</td>\n",
       "      <td>@united I hope your corporate office is ready to deal with the rage created by your shitty service and bullshit pilots. #UnitedAirlinesSucks</td>\n",
       "      <td>0.904297</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>2039</td>\n",
       "      <td>@united thanks for letting me sleep at DIA to ensure you ruin as much of my vacation as possible. Wait, no, fuck you. #unitedairlinessucks</td>\n",
       "      <td>0.895996</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>2566</td>\n",
       "      <td>@united no. U guys suck. I'll never fly with u again. And ur supervisors suck too.</td>\n",
       "      <td>0.893066</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>2185</td>\n",
       "      <td>@united please fire the captain of flight 6232 today. He single handedly ruined every passengers day by being a piece of shit. #unitedsucks</td>\n",
       "      <td>0.888672</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id  \\\n",
       "1197      1197   \n",
       "2122      2122   \n",
       "2039      2039   \n",
       "2566      2566   \n",
       "2185      2185   \n",
       "\n",
       "                                                                                                                                                    text  \\\n",
       "1197  @united you are the worst airline in the world! From your crap website to your worthless app to your Late Flight flight. You SUCK! Just shut down.   \n",
       "2122        @united I hope your corporate office is ready to deal with the rage created by your shitty service and bullshit pilots. #UnitedAirlinesSucks   \n",
       "2039          @united thanks for letting me sleep at DIA to ensure you ruin as much of my vacation as possible. Wait, no, fuck you. #unitedairlinessucks   \n",
       "2566                                                                  @united no. U guys suck. I'll never fly with u again. And ur supervisors suck too.   \n",
       "2185         @united please fire the captain of flight 6232 today. He single handedly ruined every passengers day by being a piece of shit. #unitedsucks   \n",
       "\n",
       "      toxic_score  is_toxic  \n",
       "1197     0.911133      True  \n",
       "2122     0.904297      True  \n",
       "2039     0.895996      True  \n",
       "2566     0.893066      True  \n",
       "2185     0.888672      True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toxic_samples = combined_dataset_df.query(\"is_toxic\").sort_values(\"toxic_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"tweet_id\", \"text\", \"toxic_score\", \"is_toxic\"]\n",
    "display(toxic_samples.head(5)[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above only showcases a small subset of all the different types of issues and metadata that Cleanlab Studio can provide for an unsupervised dataset with no labels. See [this guide](/guide/concepts/cleanlab_columns/) for the full set of issues that Cleanlab Studio audits your data for to help you prevent problems.\n",
    "\n",
    "![Visualizing issues in an unsupervised text dataset](../assets/unsupervised-tutorial/reviewsissues.png)\n",
    "\n",
    "## Using these results\n",
    "\n",
    "Depending on your goal, you may want to take some steps to improve your dataset based on these results (i.e. by removing text detected to be low-quality or unsafe from your dataset). Alternatively, you might use the Cleanlab-generated metadata to better understand your dataset (e.g. understanding the prevalence of toxic language). Determining how to use the results of these analyses will vary based on your dataset and use case. Remember that Cleanlab Studio can also auto-detect low-quality or unsafe **images** as well. If you'd like to discuss your use case, please [contact us](mailto:sales@cleanlab.ai).\n",
    "\n",
    "![Visualizing issues in an unsupervised image dataset](../assets/unsupervised-tutorial/unsupervisedimageissues.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docs-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}