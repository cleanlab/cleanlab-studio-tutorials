{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0098db02",
   "metadata": {},
   "source": [
    "# Integrate Codex as-a-Tool with AWS Bedrock Knowledge Bases\n",
    "\n",
    "This tutorial assumes you have a RAG app that supports tool calls, built using [AWS Bedrock Knowledge Bases](https://aws.amazon.com/bedrock/knowledge-bases/).\n",
    "Learn how to add tool calls to your AWS RAG app via our tutorial: [RAG with Tool Calls in AWS Knowledge Bases](/codex/tutorials/aws/AWSBedrock_ToolCalls/).\n",
    "\n",
    "Once you have a RAG app that supports tool calling, **adding Codex as an additional Tool takes minimal effort but guarantees better responses from your AI application.**\n",
    "\n",
    "![RAG Workflow](../assets/codexastool_retrievalfirst.png)\n",
    "\n",
    "If you prefer to integrate Codex without adding tool calls to your application, check out our tutorial: [Integrate Codex as-a-Backup with AWS Knowledge Bases](/codex/tutorials/aws/AWSBedrock_CodexAsBackup/).\n",
    "\n",
    "Let's first install packages required for this tutorial and set up required AWS configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e2967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install boto3  # we used package-version 1.36.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ffeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade cleanlab-codex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0febba66-abf2-4d06-8293-233252d6c9a7",
   "metadata": {},
   "source": [
    "**Optional: Set up AWS configurations**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d8db5-184a-4f6c-988e-a822cbf71958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = (\n",
    "    \"<YOUR_AWS_ACCESS_KEY_ID>\"  # Your permament access key (not session access key)\n",
    ")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = (\n",
    "    \"<YOUR_AWS_SECRET_ACCESS_KEY>\"  # Your permament secret access key (not session secret access key)\n",
    ")\n",
    "os.environ[\"MFA_DEVICE_ARN\"] = (\n",
    "    \"<YOUR_MFA_DEVICE_ARN>\"  # Find this in AWS Console under: settings -> security credentials -> your mfa device\n",
    ")\n",
    "os.environ[\"AWS_REGION\"] = \"us-east-1\"  # Specify your AWS region\n",
    "\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "region_name = os.getenv(\"AWS_REGION\", \"us-east-1\")  # Default to 'us-east-1' if not set\n",
    "mfa_serial_number = os.getenv(\"MFA_DEVICE_ARN\")\n",
    "\n",
    "if not all([aws_access_key_id, aws_secret_access_key, mfa_serial_number]):\n",
    "    raise EnvironmentError(\n",
    "        \"Missing required environment variables. Ensure AWS_ACCESS_KEY_ID, \"\n",
    "        \"AWS_SECRET_ACCESS_KEY, and MFA_DEVICE_ARN are set.\"\n",
    "    )\n",
    "\n",
    "# Enter MFA code in case your AWS organization requires it\n",
    "mfa_token_code = input(\"Enter your MFA code: \")\n",
    "print(\"MFA code entered:\", mfa_token_code)\n",
    "\n",
    "sts_client = boto3.client(\n",
    "    \"sts\",\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=region_name,\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Request temporary credentials\n",
    "    response = sts_client.get_session_token(\n",
    "        DurationSeconds=3600 * 24,  # Valid for 24 hours\n",
    "        SerialNumber=mfa_serial_number,\n",
    "        TokenCode=mfa_token_code,\n",
    "    )\n",
    "\n",
    "    temp_credentials = response[\"Credentials\"]\n",
    "    temp_access_key = temp_credentials[\"AccessKeyId\"]\n",
    "    temp_secret_key = temp_credentials[\"SecretAccessKey\"]\n",
    "    temp_session_token = temp_credentials[\"SessionToken\"]\n",
    "\n",
    "    # Create a Bedrock Agent Runtime client\n",
    "    client = boto3.client(\n",
    "        \"bedrock-agent-runtime\",\n",
    "        aws_access_key_id=temp_access_key,\n",
    "        aws_secret_access_key=temp_secret_key,\n",
    "        aws_session_token=temp_session_token,\n",
    "        region_name=region_name,\n",
    "    )\n",
    "    print(\"Bedrock client successfully created.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Bedrock client: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b96ab5",
   "metadata": {},
   "source": [
    "## Example RAG App: Product Customer Support\n",
    "\n",
    "Let's revisit our RAG app built in the [RAG with Tool Calls in AWS Knowledge Bases](/codex/tutorials/aws/AWSBedrock_ToolCalls/) tutorial, which has the option to call a `get_todays_date()` tool. This example represents a customer support / e-commerce use-case where the Knowledge Base contains product listings like the following:\n",
    "\n",
    "![Simple water bottle product listing](../assets/simple_water_bottle.png)\n",
    "\n",
    "The details of this minimal RAG app are unimportant if you are familiar with RAG and Tool Calling in AWS, otherwise refer to the [RAG with Tool Calls in AWS Knowledge Bases](/codex/tutorials/aws/AWSBedrock_ToolCalls/) tutorial. That tutorial walks through the helper methods defined below and how to set up a Knowledge Base.\n",
    "To keep our example minimal, we assume the product description text above has already been uploaded into a Knowledge Base for our RAG app. In practice, your Knowledge Base will have more documents/data than this single product description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa6e62e-009f-4ac1-83fb-991b4f2555ed",
   "metadata": {},
   "source": [
    "**Optional: Helper methods from prior tutorial (RAG with Tool Calls in AWS Bedrock Knowledge Bases)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "273b5fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Choices that govern how your AI behaves\n",
    "fallback_answer = \"Based on the available information, I cannot provide a complete answer to this question.\"\n",
    "\n",
    "system_prompt_without_codex = f\"\"\"You are a helpful assistant designed to help users navigate a complex set of documents for question-answering tasks. Answer the user's Question based on the following possibly relevant Context and previous chat history using the tools provided if necessary. Follow these rules in order:\n",
    "    1. NEVER use phrases like \"according to the context\", \"as the context states\", etc. Treat the Context as your own knowledge, not something you are referencing.\n",
    "    2. Use only information from the provided Context.\n",
    "    3. Give a clear, short, and accurate Answer. Explain complex terms if needed.\n",
    "    4. If the answer to the question requires today's date, use the following tool: get_todays_date. Return the date in the exact format the tool provides it.\n",
    "    5. If the Context doesn't adequately address the Question or you are unsure how to answer the Question, say: \"{fallback_answer}\" only, nothing else.\n",
    "\n",
    "    Remember, your purpose is to provide information based on the Context, not to offer original advice.\n",
    "\"\"\"\n",
    "\n",
    "# Define tool that is available for LLM to call\n",
    "def get_todays_date(date_format: str) -> str:\n",
    "  \"\"\"A tool that returns today's date in the date format requested.\"\"\"\n",
    "  datetime_str = datetime.now().strftime(date_format)\n",
    "  return datetime_str\n",
    "\n",
    "todays_date_tool_json = {\n",
    "  \"toolSpec\": {\n",
    "    \"name\": \"get_todays_date\",\n",
    "    \"description\": \"A tool that returns today's date in the date format requested. Options are: '%Y-%m-%d', '%d', '%m', '%Y'.\",\n",
    "    \"inputSchema\": {\n",
    "      \"json\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"date_format\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The format that the tool requests the date in.\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"date_format\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "tool_config_without_codex = {\n",
    "    \"tools\": [todays_date_tool_json]\n",
    "}\n",
    "\n",
    "\n",
    "model = 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0'  # Which LLM to use\n",
    "KNOWLEDGE_BASE_ID = 'DASYAHIOKX'  # See previous tutorial for how to set up the Knowledge Base\n",
    "messages = []  # For you to later inspect logs of what happened (educational purposes), we'll track all conversation history by appending to this variable in each RAG call\n",
    "\n",
    "# Setup retrieval for AWS Bedrock Knowledge Bases\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "\n",
    "BEDROCK_RETRIEVE_CLIENT = boto3.client(\n",
    "    \"bedrock-agent-runtime\",\n",
    "    config=bedrock_config,\n",
    "    aws_access_key_id=temp_access_key,\n",
    "    aws_secret_access_key=temp_secret_key,\n",
    "    aws_session_token=temp_session_token,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "BEDROCK_GENERATION_CLIENT = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    aws_access_key_id=temp_access_key,\n",
    "    aws_secret_access_key=temp_secret_key,\n",
    "    aws_session_token=temp_session_token,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "def retrieve(query, knowledgebase_id, numberOfResults=3):\n",
    "    return BEDROCK_RETRIEVE_CLIENT.retrieve(\n",
    "        retrievalQuery= {\n",
    "            'text': query\n",
    "        },\n",
    "        knowledgeBaseId=knowledgebase_id,\n",
    "        retrievalConfiguration= {\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': numberOfResults,\n",
    "                'overrideSearchType': \"HYBRID\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "def retrieve_and_get_contexts(query, knowledgebase_id, numberOfResults=3):\n",
    "    retrieval_results = retrieve(query, knowledgebase_id, numberOfResults)\n",
    "    contexts = []\n",
    "    for retrievedResult in retrieval_results['retrievalResults']:\n",
    "        text = retrievedResult['content']['text']\n",
    "        if text.startswith(\"Document 1: \"):\n",
    "            text = text[len(\"Document 1: \"):]\n",
    "        contexts.append(text)\n",
    "    return contexts\n",
    "\n",
    "# Methods for LLM response generation with Tool Calls (via AWS Converse API)\n",
    "def form_prompt(user_question: str, contexts: list) -> str:\n",
    "    \"\"\"Forms the prompt to be used for querying the model.\"\"\"\n",
    "    context_strings = \"\\n\\n\".join([f\"Context {i + 1}: {context}\" for i, context in enumerate(contexts)])\n",
    "    query_with_context = f\"{context_strings}\\n\\nQUESTION:\\n{user_question}\"\n",
    "\n",
    "    # Below step is just formatting the final prompt for readability in the tutorial\n",
    "    indented_question_with_context = \"\\n\".join(f\"  {line}\" for line in query_with_context.splitlines())\n",
    "    return indented_question_with_context\n",
    "\n",
    "def generate_text(user_question: str, model: str, tools: list[dict], system_prompts: list, messages: list[dict], bedrock_client) -> list[dict]:\n",
    "    \"\"\"Generates text dynamically handling tool use within Amazon Bedrock.\n",
    "    Params:\n",
    "        messages: List of message history in the desired format.\n",
    "        model: Identifier for the Amazon Bedrock model.\n",
    "        tools: List of tools the model can call.\n",
    "        bedrock_client: Client to interact with Bedrock API.\n",
    "    Returns:\n",
    "        messages: Final updated list of messages including tool interactions and responses.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initial call to the model\n",
    "    response = bedrock_client.converse(\n",
    "        modelId=model,\n",
    "        messages=messages,\n",
    "        toolConfig=tools,\n",
    "        system=system_prompts,\n",
    "    )\n",
    "\n",
    "    output_message = response[\"output\"][\"message\"]\n",
    "    stop_reason = response[\"stopReason\"]\n",
    "    messages.append(output_message)\n",
    "\n",
    "    while stop_reason == \"tool_use\":\n",
    "        # Extract tool requests from the model response\n",
    "        tool_requests = output_message.get(\"content\", [])\n",
    "\n",
    "        for tool_request in tool_requests:\n",
    "            if \"toolUse\" in tool_request:\n",
    "                tool = tool_request[\"toolUse\"]\n",
    "                tool_name = tool[\"name\"]\n",
    "                tool_input = tool[\"input\"]\n",
    "                tool_use_id = tool[\"toolUseId\"]\n",
    "                \n",
    "                try:\n",
    "                    # If you don't want the original question to be modified, use this instead\n",
    "                    if 'question' in tool['input'].keys():\n",
    "                        tool['input']['question'] = user_question\n",
    "                    print(f\"[internal log] Requesting tool {tool['name']}. with arguments: {tool_input}.\")\n",
    "                    tool_output_json = _handle_any_tool_call_for_stream_response(tool_name, tool_input)\n",
    "                    tool_result = json.loads(tool_output_json)\n",
    "                    print(f\"[internal log] Tool response: {tool_result}\")\n",
    "\n",
    "                    # If tool call resulted in an error\n",
    "                    if \"error\" in tool_result:\n",
    "                        tool_result_message = {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [{\"toolResult\": {\n",
    "                                \"toolUseId\": tool_use_id,\n",
    "                                \"content\": [{\"text\": tool_result[\"error\"]}],\n",
    "                                \"status\": \"error\"\n",
    "                            }}]\n",
    "                        }\n",
    "                    else:\n",
    "                        # Format successful tool response\n",
    "                        tool_result_message = {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [{\"toolResult\": {\n",
    "                                \"toolUseId\": tool_use_id,\n",
    "                                \"content\": [{\"json\": {\"response\": tool_result}}]\n",
    "                            }}]\n",
    "                        }\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Handle unexpected exceptions during tool handling\n",
    "                    tool_result_message = {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [{\"toolResult\": {\n",
    "                            \"toolUseId\": tool_use_id,\n",
    "                            \"content\": [{\"text\": f\"Error processing tool: {str(e)}\"}],\n",
    "                            \"status\": \"error\"\n",
    "                        }}]\n",
    "                    }\n",
    "\n",
    "                # Append the tool result to messages\n",
    "                messages.append(tool_result_message)\n",
    "\n",
    "        # Send the updated messages back to the model\n",
    "        response = bedrock_client.converse(\n",
    "            modelId=model,\n",
    "            messages=messages,\n",
    "            toolConfig=tools,\n",
    "            system=system_prompts,\n",
    "        )\n",
    "\n",
    "        output_message = response[\"output\"][\"message\"]\n",
    "        stop_reason = response[\"stopReason\"]\n",
    "        messages.append(output_message)\n",
    "\n",
    "    return messages\n",
    "\n",
    "def _handle_any_tool_call_for_stream_response(function_name: str, arguments: dict) -> str:\n",
    "    \"\"\"Handles any tool dynamically by calling the function by name and passing in collected arguments.\n",
    "       Returns a dictionary of the tool output.\n",
    "       Returns error message if the tool is not found, not callable, or called incorrectly.\n",
    "    \"\"\"\n",
    "    tool_function = globals().get(function_name) or locals().get(function_name)\n",
    "\n",
    "    if callable(tool_function):\n",
    "        try:\n",
    "            # Dynamically call the tool function with arguments\n",
    "            tool_output = tool_function(**arguments)\n",
    "            return json.dumps(tool_output)\n",
    "        except Exception as e:\n",
    "            return json.dumps({\n",
    "                \"error\": f\"Exception while calling tool '{function_name}': {str(e)}\",\n",
    "                \"arguments\": arguments,\n",
    "            })\n",
    "    else:\n",
    "        return json.dumps({\n",
    "            \"error\": f\"Tool '{function_name}' not found or not callable.\",\n",
    "            \"arguments\": arguments,\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab0a043",
   "metadata": {},
   "source": [
    "To generate responses to user queries using the AWS APIs, we define a standard RAG method. See the [RAG with Tool Calls in AWS Knowledge Bases](/codex/tutorials/aws/AWSBedrock_ToolCalls/) tutorial for details.\n",
    "Subsequently, we integrate Codex-as-a-Tool and demonstrate its benefits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e129b46-7d28-45f0-8757-3731c661d131",
   "metadata": {},
   "source": [
    "**Optional: RAG method from prior tutorial (RAG with Tool Calls in AWS Bedrock Knowledge Bases)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf5a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rag(model: str, user_question: str, system_prompt: str, tools: list[dict], messages: list, knowledgebase_id: str) -> str:\n",
    "    \"\"\"Performs RAG (Retrieval-Augmented Generation) using the provided model and tools, via AWS Bedrock Knowledge Bases and the Converse API.\"\"\"\n",
    "    contexts = retrieve_and_get_contexts(user_question, knowledgebase_id)    \n",
    "    query_with_context = form_prompt(user_question, contexts)\n",
    "    print(f\"[internal log] Invoking LLM text\\n{query_with_context}\\n\\n\")\n",
    "\n",
    "    user_message = {\"role\": \"user\", \"content\": [{\"text\": query_with_context}]}\n",
    "    messages.append(user_message)\n",
    "    system_prompts = [{'text': system_prompt}]\n",
    "\n",
    "    final_messages = generate_text(user_question=user_question, model=model, tools=tools, system_prompts=system_prompts, messages=messages, bedrock_client=BEDROCK_GENERATION_CLIENT)\n",
    "    return final_messages[-1][\"content\"][-1][\"text\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ceccd6",
   "metadata": {},
   "source": [
    "## Create Project in Codex Web App\n",
    "\n",
    "To use Codex, you first need to [create a Project](/codex/web_tutorials/create_project/).\n",
    "\n",
    "Here we assume some common (question, answer) pairs about the *Simple Water Bottle* have already been added to a Codex Project.\n",
    "To learn how that was done, see our tutorial: [Populating Codex](/codex/web_tutorials/populating_codex/).\n",
    "\n",
    "Our existing Codex Project contains the following entries:\n",
    "\n",
    "![Codex Knowledge Base Example](../assets/codex_kb.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d7f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = \"<YOUR-PROJECT-ACCESS-KEY>\"  # Obtain from your Project's settings page: https://codex.cleanlab.ai/projects/<YOUR-PROJECT-ID>/settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9a6471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Programmatically populate the Codex Project with above (question, answer) pairs. Note: The recommended flow is to do this manually in the Web App.\n",
    "from cleanlab_codex.client import Client\n",
    "\n",
    "os.environ[\"CODEX_API_KEY\"] = \"<YOUR-KEY-HERE>\"  # Replace with your Codex API key\n",
    "codex_client = Client()\n",
    "\n",
    "# Create a project\n",
    "project = codex_client.create_project(\n",
    "    name=\"Product FAQs\",\n",
    "    description=\"Questions about product pages\",\n",
    ")\n",
    "\n",
    "# Add entries to the project\n",
    "project.add_entries(\n",
    "    entries=[\n",
    "        {\"question\": \"How much water can the Simple Water Bottle hold?\", \"answer\": \"32oz\"},\n",
    "        {\"question\": \"Can I return my Simple Water Bottle?\", \"answer\": \"Return it within 30 days for a full refund-- no questions asked. Contact our support team to initiate your return!\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "access_key = project.create_access_key(\"test access key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfdd13f",
   "metadata": {},
   "source": [
    "## Integrate Codex as an additional tool\n",
    "\n",
    "Integrating Codex into a RAG app that supports tool calling requires minimal code changes:\n",
    "\n",
    "1. Import Codex and add it into your list of `tools`.\n",
    "2. Update your system prompt to include instructions for calling Codex, as demonstrated below in: `system_prompt_with_codex`.\n",
    "\n",
    "After that, call your original RAG pipeline with these updated variables to start experiencing the benefits of Codex!\n",
    "\n",
    "**Note:** Here we obtain a Codex tool description in AWS-ready format via `to_aws_converse_tool()`. You can obtain the Codex tool description in other provided formats as well, or manually write it yourself to suit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b6af892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab_codex import CodexTool\n",
    "\n",
    "codex_tool = CodexTool.from_access_key(access_key=access_key, fallback_answer=fallback_answer)\n",
    "codex_tool_aws = codex_tool.to_aws_converse_tool()\n",
    "\n",
    "globals()[codex_tool.tool_name] = (\n",
    "    codex_tool.query\n",
    ")  # Optional step for convenience: make function to call the tool globally accessible\n",
    "\n",
    "tool_config_with_codex = {\n",
    "    \"tools\": [codex_tool_aws, todays_date_tool_json]\n",
    "}  # Add Codex to the list of tools that LLM can call\n",
    "\n",
    "# Update the RAG system prompt with instructions for handling Codex (adjust based on your needs)\n",
    "system_prompt_with_codex = f\"\"\"You are a helpful assistant designed to help users navigate a complex set of documents for question-answering tasks. Answer the user's Question based on the following possibly relevant Context and previous chat history using the tools provided if necessary. Follow these rules in order:\n",
    "    1. NEVER use phrases like \"according to the context\", \"as the context states\", etc. Treat the Context as your own knowledge, not something you are referencing.\n",
    "    2. Use only information from the provided Context.\n",
    "    3. Give a clear, short, and accurate Answer. Explain complex terms if needed.\n",
    "    4. When the Context does not answer the user's Question, call the `{codex_tool.tool_name}` tool.\n",
    "        - Always use `{codex_tool.tool_name}` if the provided Context lacks the necessary information.\n",
    "        - Your query to `{codex_tool.tool_name}` should closely match the user\u2019s original Question, with only minor clarifications if needed.\n",
    "        - Evaluate the response from `{codex_tool.tool_name}`. If the response is helpful, use it to answer the user\u2019s Question. If the response is not helpful, ignore it.\n",
    "    5. If the answer to the question requires today's date, use the following tool: get_todays_date. Return the date in the exact format the tool provides it.\n",
    "    6. If you still cannot confidently answer the user's Question (even after using `{codex_tool.tool_name}` and other tools), say: \"{fallback_answer}\".\n",
    "    \n",
    "    Remember, your purpose is to provide information based on the Context and make effective use of `{codex_tool.tool_name}` when necessary, not to offer original advice.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedab48c",
   "metadata": {},
   "source": [
    "## RAG with Codex in action \n",
    "\n",
    "Integrating Codex as-a-Tool allows your RAG app to answer more questions than it was originally capable of.\n",
    "\n",
    "### Example 1\n",
    "\n",
    "Let's ask a question to our **original** RAG app (before Codex was integrated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c2de6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[internal log] Invoking LLM text\n",
      "  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\nDimensions: 10 inches height x 4 inches width\n",
      "  \n",
      "  QUESTION:\n",
      "  Can I return my Simple Water Bottle?\n",
      "\n",
      "\n",
      "[internal log] Requesting tool get_todays_date. with arguments: {'date_format': '%Y-%m-%d'}.\n",
      "[internal log] Tool response: 2025-02-25\n",
      "[RAG response] Based on the information provided in the Context, the Simple Water Bottle is a limited edition product that was launched on January 1st, 2025. Since today's date is <result>2025-02-25</result>, which is after the launch date, you should be able to return the water bottle as long as it is within the return policy period set by the manufacturer. The specific return policy details are not provided, so I cannot confirm the exact return terms. However, in general, customers are typically able to return products within a certain number of days or weeks after purchase, so you may want to check with the manufacturer or seller about their return policy.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Can I return my Simple Water Bottle?\"\n",
    "\n",
    "rag_response = rag(model=model, user_question=user_question, system_prompt=system_prompt_without_codex, tools=tool_config_without_codex, messages=messages, knowledgebase_id=KNOWLEDGE_BASE_ID)\n",
    "print(f'[RAG response] {rag_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca30a04",
   "metadata": {},
   "source": [
    "The **original RAG app is unable to answer**, in this case because the required information is not in its Knowledge Base.\n",
    "\n",
    "Let's ask the same question to our RAG app with Codex added as an additional tool. \n",
    "Note that we use the updated system prompt and tool list when Codex is integrated in the RAG app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30bdf4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[internal log] Invoking LLM text\n",
      "  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\nDimensions: 10 inches height x 4 inches width\n",
      "  \n",
      "  QUESTION:\n",
      "  Can I return my simple water bottle?\n",
      "\n",
      "\n",
      "[internal log] Requesting tool consult_codex. with arguments: {'question': 'Can I return my simple water bottle?'}.\n",
      "[internal log] Tool response: Return it within 30 days for a full refund-- no questions asked. Contact our support team to initiate your return!\n",
      "[RAG response] Based on the information provided by the CodeX tool, you should be able to return your simple water bottle for a full refund within 30 days of purchase. The manufacturer likely has a 30-day return policy, so as long as you're within that time frame, you can contact their support team to initiate the return process.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Can I return my simple water bottle?\"\n",
    "\n",
    "rag_response = rag(model=model, user_question=user_question, system_prompt=system_prompt_with_codex, tools=tool_config_with_codex, messages=messages, knowledgebase_id=KNOWLEDGE_BASE_ID)  # Codex is added here\n",
    "print(f'[RAG response] {rag_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53864ab1",
   "metadata": {},
   "source": [
    "As you see, **integrating Codex enables your RAG app to answer questions it originally strugged with**, as long as a similar question was already answered in the corresponding Codex Project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d9a3e-a55c-4d5d-8b1f-64bd5fb6cfb7",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "Let's ask another question to our RAG app with Codex integrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eabcb770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[internal log] Invoking LLM text\n",
      "  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\nDimensions: 10 inches height x 4 inches width\n",
      "  \n",
      "  QUESTION:\n",
      "  How can I order the Simple Water Bottle in bulk?\n",
      "\n",
      "\n",
      "[internal log] Requesting tool consult_codex. with arguments: {'question': 'How can I order the Simple Water Bottle in bulk?'}.\n",
      "[internal log] Tool response: Based on the available information, I cannot provide a complete answer to this question.\n",
      "[RAG response] The context provided does not contain any information about ordering the Simple Water Bottle in bulk. The details given focus on the product specifications and pricing for a single unit, but do not mention anything about bulk ordering options or procedures. Without additional information from the manufacturer or seller about their bulk ordering policies and processes, I am unable to provide a complete answer to your question. My recommendation would be to contact the company directly to inquire about their bulk ordering capabilities and requirements.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"How can I order the Simple Water Bottle in bulk?\"\n",
    "\n",
    "rag_response = rag(model=model, user_question=user_question, system_prompt=system_prompt_with_codex, tools=tool_config_with_codex, messages=messages, knowledgebase_id=KNOWLEDGE_BASE_ID)  # Codex is added here\n",
    "print(f'[RAG response] {rag_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ec91c",
   "metadata": {},
   "source": [
    "Our RAG app is unable to answer this question because there is no relevant information in its Knowledge Base, nor has a similar question been answered in the Codex Project (see the contents of the Codex Project above).\n",
    "\n",
    "**Codex automatically recognizes this question could not be answered and logs it into the Project where it awaits an answer from a SME**.\n",
    "\n",
    "![Codex Project with asked question that has not been answered yet](../assets/codex_kb_unanswered.png)\n",
    "\n",
    "As soon as an answer is provided in Codex, our RAG app will be able to answer all similar questions going forward (as seen for the previous query).\n",
    "\n",
    "### Example 3\n",
    "\n",
    "Let's ask another query to our RAG app with Codex integrated. This is a query the original RAG app was able to correctly answer without Codex (since the relevant information exists in the Knowledge Base)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3d0a966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[internal log] Invoking LLM text\n",
      "  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\nDimensions: 10 inches height x 4 inches width\n",
      "  \n",
      "  QUESTION:\n",
      "  How big is the water bottle?\n",
      "\n",
      "\n",
      "[RAG response] According to the context provided, the dimensions of the Simple Water Bottle are:\n",
      "\n",
      "Height: 10 inches\n",
      "Width: 4 inches\n",
      "\n",
      "So the overall size of the water bottle is 10 inches in height and 4 inches in width.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"How big is the water bottle?\"\n",
    "\n",
    "rag_response = rag(model=model, user_question=user_question, system_prompt=system_prompt_with_codex, tools=tool_config_with_codex, messages=messages, knowledgebase_id=KNOWLEDGE_BASE_ID)  # Codex is added here\n",
    "print(f'[RAG response] {rag_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c139ddd-c58c-4330-ac8b-f441b8915571",
   "metadata": {},
   "source": [
    "We see that the RAG app with Codex integrated is still able to correctly answer this query. **Integrating Codex has no negative effect on questions your original RAG app could answer**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd38d7f0-d4db-4b51-9545-32f82bdabd1f",
   "metadata": {},
   "source": [
    "**Optional: Review full message history (includes tool calls)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5f264c7-821d-4175-8282-59d022617138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': [{'text': '  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\\\nDimensions: 10 inches height x 4 inches width\\n  \\n  QUESTION:\\n  Can I return my Simple Water Bottle?'}]}\n",
      "{'role': 'assistant', 'content': [{'toolUse': {'toolUseId': 'tooluse_i4TBsnvmTKOhDC7C5DO2SA', 'name': 'get_todays_date', 'input': {'date_format': '%Y-%m-%d'}}}]}\n",
      "{'role': 'user', 'content': [{'toolResult': {'toolUseId': 'tooluse_i4TBsnvmTKOhDC7C5DO2SA', 'content': [{'json': {'response': '2025-02-25'}}]}}]}\n",
      "{'role': 'assistant', 'content': [{'text': \"Based on the information provided in the Context, the Simple Water Bottle is a limited edition product that was launched on January 1st, 2025. Since today's date is <result>2025-02-25</result>, which is after the launch date, you should be able to return the water bottle as long as it is within the return policy period set by the manufacturer. The specific return policy details are not provided, so I cannot confirm the exact return terms. However, in general, customers are typically able to return products within a certain number of days or weeks after purchase, so you may want to check with the manufacturer or seller about their return policy.\"}]}\n",
      "{'role': 'user', 'content': [{'text': '  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\\\nDimensions: 10 inches height x 4 inches width\\n  \\n  QUESTION:\\n  Can I return my simple water bottle?'}]}\n",
      "{'role': 'assistant', 'content': [{'toolUse': {'toolUseId': 'tooluse_DAybOrsRRO-IVBar-0--1g', 'name': 'consult_codex', 'input': {'question': 'Can I return my simple water bottle?'}}}]}\n",
      "{'role': 'user', 'content': [{'toolResult': {'toolUseId': 'tooluse_DAybOrsRRO-IVBar-0--1g', 'content': [{'json': {'response': 'Return it within 30 days for a full refund-- no questions asked. Contact our support team to initiate your return!'}}]}}]}\n",
      "{'role': 'assistant', 'content': [{'text': \"Based on the information provided by the CodeX tool, you should be able to return your simple water bottle for a full refund within 30 days of purchase. The manufacturer likely has a 30-day return policy, so as long as you're within that time frame, you can contact their support team to initiate the return process.\"}]}\n",
      "{'role': 'user', 'content': [{'text': '  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\\\nDimensions: 10 inches height x 4 inches width\\n  \\n  QUESTION:\\n  How can I order the Simple Water Bottle in bulk?'}]}\n",
      "{'role': 'assistant', 'content': [{'toolUse': {'toolUseId': 'tooluse_CjasWEwXQXeqyANbmlWSIA', 'name': 'consult_codex', 'input': {'question': 'How can I order the Simple Water Bottle in bulk?'}}}]}\n",
      "{'role': 'user', 'content': [{'toolResult': {'toolUseId': 'tooluse_CjasWEwXQXeqyANbmlWSIA', 'content': [{'json': {'response': 'Based on the available information, I cannot provide a complete answer to this question.'}}]}}]}\n",
      "{'role': 'assistant', 'content': [{'text': 'The context provided does not contain any information about ordering the Simple Water Bottle in bulk. The details given focus on the product specifications and pricing for a single unit, but do not mention anything about bulk ordering options or procedures. Without additional information from the manufacturer or seller about their bulk ordering policies and processes, I am unable to provide a complete answer to your question. My recommendation would be to contact the company directly to inquire about their bulk ordering capabilities and requirements.'}]}\n",
      "{'role': 'user', 'content': [{'text': '  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\\\nDimensions: 10 inches height x 4 inches width\\n  \\n  QUESTION:\\n  How big is the water bottle?'}]}\n",
      "{'role': 'assistant', 'content': [{'text': 'According to the context provided, the dimensions of the Simple Water Bottle are:\\n\\nHeight: 10 inches\\nWidth: 4 inches\\n\\nSo the overall size of the water bottle is 10 inches in height and 4 inches in width.'}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For educational purposes, we passed `messages` into every RAG call and logged every step in this variable.\n",
    "\n",
    "for message in messages:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d979ef",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that Codex is integrated with your RAG app, you and SMEs can [open the Codex Project and answer questions](/codex/web_tutorials/codex_as_sme/) logged there to continuously improve your AI.\n",
    "\n",
    "**Adding Codex only improves your RAG app.** As seen here, integrating Codex into your RAG app requires minimal extra code. Once integrated, the Codex Project automatically logs all user queries that your original RAG app handles poorly. Using a [simple web interface](/codex/web_tutorials/codex_as_sme/), SMEs at your company can answer the highest priority questions in the Codex Project. As soon as an answer is entered in Codex, your RAG app will be able to properly handle all similar questions encountered in the future\n",
    "\n",
    "Codex is **the fastest way for nontechnical SMEs to directly improve your RAG app**. As the Developer, you simply integrate Codex once, and from then on, SMEs can continuously improve how your AI handles common user queries without needing your help. Codex remains compatible with [any RAG architecture](/codex/tutorials/other_rag_frameworks/OtherRAG_CodexAsTool/), so engineers can update your RAG system unhindered.\n",
    "\n",
    "Need help, more capabilities, or other deployment options? \n",
    "Check the [FAQ](/codex/FAQ/) or email us at: support@cleanlab.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f9bcf4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}