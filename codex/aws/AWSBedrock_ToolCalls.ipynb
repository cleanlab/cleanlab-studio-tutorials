{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef439dee",
   "metadata": {},
   "source": [
    "# RAG with Tool Calls in AWS Bedrock Knowledge Bases\n",
    "\n",
    "This tutorial covers the basics of building a conversational RAG application that supports tool calls, via the [AWS Bedrock Knowledge Bases](https://aws.amazon.com/bedrock/knowledge-bases/) and [Converse](https://docs.aws.amazon.com/bedrock/latest/userguide/tool-use-inference-call.html) APIs.\n",
    "Here we demonstrate how to build the specific RAG app used in our [Integrate Codex as-a-Tool with AWS Bedrock Knowledge Bases](/codex/tutorials/aws/AWSBedrock_AddingCodexAsTool/) tutorial. Remember that Codex works with *any* RAG app, you can easily translate these ideas to more complex RAG pipelines.\n",
    "\n",
    "Here's a typical architecture for RAG apps with tool calling:\n",
    "\n",
    "![RAG Workflow](../assets/codexastool_retrievalfirst.png)\n",
    "\n",
    "Let's first install packages required for this tutorial and set up AWS credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f921c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U boto3  # we used package-version 1.36.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22928a3-8f00-4a0a-a6a3-3c733a7c5ab3",
   "metadata": {},
   "source": [
    "**Optional: Set up AWS configurations**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d8db5-184a-4f6c-988e-a822cbf71958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = (\n",
    "    \"<YOUR_AWS_ACCESS_KEY_ID>\"  # Your permament access key (not session access key)\n",
    ")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = (\n",
    "    \"<YOUR_AWS_SECRET_ACCESS_KEY>\"  # Your permament secret access key (not session secret access key)\n",
    ")\n",
    "os.environ[\"MFA_DEVICE_ARN\"] = (\n",
    "    \"<YOUR_MFA_DEVICE_ARN>\"  # If your organization requires MFA, find this in AWS Console under: settings -> security credentials -> your mfa device\n",
    ")\n",
    "os.environ[\"AWS_REGION\"] = \"us-east-1\"  # Specify your AWS region\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "region_name = os.getenv(\"AWS_REGION\", \"us-east-1\")  # Default to 'us-east-1' if not set\n",
    "mfa_serial_number = os.getenv(\"MFA_DEVICE_ARN\")\n",
    "\n",
    "# Ensure required environment variables are set\n",
    "if not all([aws_access_key_id, aws_secret_access_key, mfa_serial_number]):\n",
    "    raise EnvironmentError(\n",
    "        \"Missing required environment variables. Ensure AWS_ACCESS_KEY_ID, \"\n",
    "        \"AWS_SECRET_ACCESS_KEY, and MFA_DEVICE_ARN are set.\"\n",
    "    )\n",
    "\n",
    "# Enter MFA code in case your AWS organization requires it\n",
    "mfa_token_code = input(\"Enter your MFA code: \")\n",
    "print(\"MFA code entered: \", mfa_token_code)\n",
    "\n",
    "sts_client = boto3.client(\n",
    "    \"sts\",\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=region_name,\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Request temporary credentials\n",
    "    response = sts_client.get_session_token(\n",
    "        DurationSeconds=3600 * 24,  # Valid for 24 hours\n",
    "        SerialNumber=mfa_serial_number,\n",
    "        TokenCode=mfa_token_code,\n",
    "    )\n",
    "\n",
    "    temp_credentials = response[\"Credentials\"]\n",
    "    temp_access_key = temp_credentials[\"AccessKeyId\"]\n",
    "    temp_secret_key = temp_credentials[\"SecretAccessKey\"]\n",
    "    temp_session_token = temp_credentials[\"SessionToken\"]\n",
    "\n",
    "    print(\"Successfully set up AWS credentials.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error setting up AWS credentials: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f831704",
   "metadata": {},
   "source": [
    "Next we'll initialize Bedrock clients for the retrieval and generation steps of our RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46279df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.client import Config\n",
    "\n",
    "bedrock_config = Config(\n",
    "    connect_timeout=120, read_timeout=120, retries={\"max_attempts\": 0}\n",
    ")\n",
    "\n",
    "BEDROCK_RETRIEVE_CLIENT = boto3.client(\n",
    "    \"bedrock-agent-runtime\",\n",
    "    config=bedrock_config,\n",
    "    aws_access_key_id=temp_access_key,\n",
    "    aws_secret_access_key=temp_secret_key,\n",
    "    aws_session_token=temp_session_token,\n",
    "    region_name=region_name,\n",
    ")\n",
    "\n",
    "BEDROCK_GENERATION_CLIENT = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    aws_access_key_id=temp_access_key,\n",
    "    aws_secret_access_key=temp_secret_key,\n",
    "    aws_session_token=temp_session_token,\n",
    "    region_name=region_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b96ab5",
   "metadata": {},
   "source": [
    "## Example RAG App: Product Customer Support\n",
    "\n",
    "Consider a customer support / e-commerce RAG use-case where the Knowledge Base contains product listings like the following:\n",
    "\n",
    "![Simple water bottle product listing](../assets/simple_water_bottle.png)\n",
    "\n",
    "### Creating a Knowledge Base\n",
    "\n",
    "To keep our example simple, we upload the product description to AWS S3 as a single file: `simple_water_bottle.txt`. This is the sole file our Knowledge Base will contain, but you can populate your actual Knowledge Base with many heterogeneous documents.\n",
    "\n",
    "To create a Knowledge Base using Amazon Bedrock, refer to the [official documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-create.html).\n",
    "\n",
    "After you've created it, add your `KNOWLEDGE_BASE_ID` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef2399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWLEDGE_BASE_ID = \"DASYAHIOKX\"  # replace with your own Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ceaea-53ec-42dd-89f7-66f39676eade",
   "metadata": {},
   "source": [
    "### Implement a standard RAG pipeline\n",
    "\n",
    "A RAG pipeline has two key steps -- retrieval and generation, which we implement using AWS Bedrock APIs. Building on the most basic RAG pipeline, we'll add tool calling support to the generation step.\n",
    "\n",
    "#### Retrieval in AWS Knowledge Bases\n",
    "\n",
    "We've defined some helper methods for retrieving context from our Knowledge Base below. You may want to modify these or use your own retrieval logic to fit your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d807b4c7-6a9c-440f-801a-6825f515d5bd",
   "metadata": {},
   "source": [
    "**Optional: Helper methods for Retrieval in AWS Knowledge Bases**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b7b8362-f4e6-4f8f-886b-5dfccce6e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def retrieve(\n",
    "    bedrock_client: boto3.client,\n",
    "    query: str,\n",
    "    knowledge_base_id: str,\n",
    "    number_of_results: int = 3,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Fetches relevant document chunks to query from Knowledge Base using AWS Bedrock Agent Runtime\"\"\"\n",
    "    return bedrock_client.retrieve(\n",
    "        retrievalQuery={\"text\": query},\n",
    "        knowledgeBaseId=knowledge_base_id,\n",
    "        retrievalConfiguration={\n",
    "            \"vectorSearchConfiguration\": {\n",
    "                \"numberOfResults\": number_of_results,\n",
    "                \"overrideSearchType\": \"HYBRID\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "def retrieve_and_format_context(\n",
    "    bedrock_client: boto3.client,\n",
    "    query: str,\n",
    "    knowledge_base_id: str,\n",
    "    number_of_results: int = 3,\n",
    "    threshold: float = 0.0,\n",
    ") -> list[str]:\n",
    "    \"\"\"Fetches relevant contexts and does some processing to format results for the subsequent LLM response generation step.\"\"\"\n",
    "    retrieval_results = retrieve(\n",
    "        bedrock_client, query, knowledge_base_id, number_of_results\n",
    "    )\n",
    "    contexts = []\n",
    "\n",
    "    for result in retrieval_results[\"retrievalResults\"]:\n",
    "        if result[\"score\"] >= threshold:\n",
    "            contexts.append(result[\"content\"][\"text\"])\n",
    "\n",
    "    return contexts\n",
    "\n",
    "\n",
    "# Similarity score threshold for retrieving context to use in our RAG app\n",
    "SCORE_THRESHOLD = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0cd392",
   "metadata": {},
   "source": [
    "Let's test our retrieval component with a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c05a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\\\nDimensions: 10 inches height x 4 inches width'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the Simple Water Bottle?\"\n",
    "\n",
    "results = retrieve_and_format_context(BEDROCK_RETRIEVE_CLIENT, query, KNOWLEDGE_BASE_ID)\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b41e92",
   "metadata": {},
   "source": [
    "### Response generation with tool calling\n",
    "\n",
    "To generate responses with an LLM that can also call tools, we pass the user query and retrieved context from our Knowledge Base into the AWS Converse API.\n",
    "\n",
    "This API can either return a string response from the LLM or a tool call. We define our generation logic so that if the output is a tool call, we keep prompting the Converse API with the result of the tool call until the LLM returns a string response.\n",
    "\n",
    "Our generation method is defined below. You may want to modify this or use your own response generation logic to fit your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd6fa45-a04a-446a-a722-2f7539b46876",
   "metadata": {},
   "source": [
    "**Optional: Helper methods for response generation with tool calling via AWS Converse API**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06cfe0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def form_prompt(user_question: str, contexts: list[str]) -> str:\n",
    "    \"\"\"Forms the prompt to be used for querying the model.\"\"\"\n",
    "    context_strings = \"\\n\\n\".join(\n",
    "        [f\"Context {i + 1}: {context}\" for i, context in enumerate(contexts)]\n",
    "    )\n",
    "    query_with_context = f\"{context_strings}\\n\\nQUESTION:\\n{user_question}\"\n",
    "\n",
    "    indented_question_with_context = \"\\n\".join(\n",
    "        f\"  {line}\" for line in query_with_context.splitlines()\n",
    "    )\n",
    "    return indented_question_with_context\n",
    "\n",
    "\n",
    "def generate_text(\n",
    "    bedrock_client: boto3.client,\n",
    "    user_question: str,\n",
    "    model: str,\n",
    "    tools: list[dict[str, Any]],\n",
    "    system_prompts: list[dict[str, Any]],\n",
    "    messages: list[dict[str, Any]],\n",
    ") -> list[dict[str, Any]]:\n",
    "    \"\"\"Generates a response from the LLM using AWS Converse API, handling tool calls as necessary.\n",
    "    Params:\n",
    "        bedrock_client: Client to interact with Bedrock API.\n",
    "        user_question: The user's question or query.\n",
    "        model: Identifier for the Amazon Bedrock model.\n",
    "        tools: List of tools the model can call. See https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Tool.html for expected format.\n",
    "        system_prompts: System message to provide instructions or context to the LLM. See https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_SystemContentBlock.html for expected format.\n",
    "        messages: List of message history in the desired format (see https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Message.html). This should include the current user question as the latest message.\n",
    "    Returns:\n",
    "        messages: Final updated list of messages including tool interactions and responses.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initial call to the model\n",
    "    response = bedrock_client.converse(\n",
    "        modelId=model,\n",
    "        messages=messages,\n",
    "        toolConfig=tools,\n",
    "        system=system_prompts,\n",
    "    )\n",
    "\n",
    "    output_message = response[\"output\"][\"message\"]\n",
    "    stop_reason = response[\"stopReason\"]\n",
    "    messages.append(output_message)\n",
    "\n",
    "    while stop_reason == \"tool_use\":\n",
    "        # Extract tool requests from the model response\n",
    "        tool_requests = output_message.get(\"content\", [])\n",
    "\n",
    "        for tool_request in tool_requests:\n",
    "            if \"toolUse\" in tool_request:\n",
    "                messages.append(\n",
    "                    _handle_tool_request(user_question, tool_request[\"toolUse\"])\n",
    "                )\n",
    "\n",
    "        # Send the updated messages back to the model\n",
    "        response = bedrock_client.converse(\n",
    "            modelId=model,\n",
    "            messages=messages,\n",
    "            toolConfig=tools,\n",
    "            system=system_prompts,\n",
    "        )\n",
    "\n",
    "        output_message = response[\"output\"][\"message\"]\n",
    "        stop_reason = response[\"stopReason\"]\n",
    "        messages.append(output_message)\n",
    "\n",
    "    return messages\n",
    "\n",
    "\n",
    "def _handle_tool_request(\n",
    "    user_question: str, tool_use_block: dict[str, Any]\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Handles a tool request by calling the tool function and returning the result formatted as a ToolResultBlock\n",
    "    (see https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ToolResultBlock.html).\n",
    "    \"\"\"\n",
    "    tool_name = tool_use_block[\"name\"]\n",
    "    tool_input = tool_use_block[\"input\"]\n",
    "    tool_use_id = tool_use_block[\"toolUseId\"]\n",
    "\n",
    "    try:\n",
    "        # If you don't want the original question to be modified, use this instead\n",
    "        if \"question\" in tool_input.keys():\n",
    "            tool_input[\"question\"] = user_question\n",
    "        print(\n",
    "            f\"[internal log] Requesting tool {tool_name} with arguments: {tool_input}.\"\n",
    "        )\n",
    "        try:\n",
    "            tool_result = _execute_tool_call(tool_name, tool_input)\n",
    "            print(f\"[internal log] Tool response: {tool_result}\")\n",
    "            return _format_tool_result_message(tool_use_id, tool_result)\n",
    "        except Exception as e:\n",
    "            return _format_tool_error_message(tool_use_id, str(e))\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle unexpected exceptions during tool handling\n",
    "        return _format_tool_error_message(\n",
    "            tool_use_id, f\"Error processing tool: {str(e)}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def _format_tool_result_message(tool_use_id: str, tool_result: Any) -> dict[str, Any]:\n",
    "    \"\"\"Formats a tool result message.\"\"\"\n",
    "    return {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"toolResult\": {\n",
    "                    \"toolUseId\": tool_use_id,\n",
    "                    \"content\": [{\"json\": {\"response\": tool_result}}],\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "def _format_tool_error_message(tool_use_id: str, error_message: str) -> dict[str, Any]:\n",
    "    \"\"\"Handles tool errors by returning a dictionary with the error message and arguments.\"\"\"\n",
    "    return {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"toolResult\": {\n",
    "                    \"toolUseId\": tool_use_id,\n",
    "                    \"content\": [{\"text\": error_message}],\n",
    "                    \"status\": \"error\",\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "def _execute_tool_call(function_name: str, arguments: dict[str, Any]) -> Any:\n",
    "    \"\"\"Handles any tool dynamically by calling the function by name and passing in collected arguments.\n",
    "    Returns:\n",
    "        The tool output.\n",
    "    Raises:\n",
    "        Exception: If the tool is not found, not callable, or called incorrectly.\n",
    "    \"\"\"\n",
    "    tool_function = globals().get(function_name) or locals().get(function_name)\n",
    "\n",
    "    if callable(tool_function):\n",
    "        try:\n",
    "            # Dynamically call the tool function with arguments\n",
    "            tool_output = tool_function(**arguments)\n",
    "            return tool_output\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Exception while calling tool '{function_name}': {str(e)}\")\n",
    "    else:\n",
    "        raise Exception(f\"Tool '{function_name}' not found or not callable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d098d34a",
   "metadata": {},
   "source": [
    "### Define single-turn RAG app\n",
    "\n",
    "We integrate the above helper methods into a standard RAG app that can respond to any user query, calling tools as the LLM deems necessary. Our `rag()` method can be called multiple times in a conversation, as long as a `messages` variable is provided each time to track conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69af81b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(\n",
    "    model: str,\n",
    "    user_question: str,\n",
    "    system_prompt: str,\n",
    "    tools: list[dict[str, Any]],\n",
    "    messages: list[dict[str, Any]],\n",
    "    knowledge_base_id: str,\n",
    ") -> str:\n",
    "    \"\"\"Performs Retrieval-Augmented Generation using the provided model and tools.\n",
    "    Params:\n",
    "        model: Model name or ID.\n",
    "        user_question: The user's question or query.\n",
    "        system_prompt: System message to provide instructions or context to the LLM.\n",
    "        tools: List of tools the model can call. See https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_ToolConfiguration.html for expected format.\n",
    "        messages: Optional list of prior conversation history. See https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Message.html for expected format.\n",
    "        knowledge_base_id: Knowledge base ID for retrieving contexts.\n",
    "    Returns:\n",
    "        Final response text generated by the model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve contexts based on the user query and knowledge base ID\n",
    "    contexts = retrieve_and_format_context(\n",
    "        BEDROCK_RETRIEVE_CLIENT,\n",
    "        user_question,\n",
    "        knowledge_base_id,\n",
    "        threshold=SCORE_THRESHOLD,\n",
    "    )\n",
    "    query_with_context = form_prompt(user_question, contexts)\n",
    "    print(\n",
    "        f\"[internal log] Invoking LLM text:\\n{query_with_context}\\n\\n\"\n",
    "    )\n",
    "\n",
    "    # Construct the user message with the retrieved contexts and add to message history\n",
    "    user_message = {\"role\": \"user\", \"content\": [{\"text\": query_with_context}]}\n",
    "    messages.append(user_message)\n",
    "\n",
    "    # Construct system prompt in the format required by the AWS Converse API\n",
    "    system_prompts = [{\"text\": system_prompt}]\n",
    "\n",
    "    # Call generate_text with the updated messages\n",
    "    final_messages = generate_text(\n",
    "        user_question=user_question,\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        system_prompts=system_prompts,\n",
    "        messages=messages,\n",
    "        bedrock_client=BEDROCK_GENERATION_CLIENT,\n",
    "    )\n",
    "\n",
    "    # Extract and return the final response text\n",
    "    return final_messages[-1][\"content\"][-1][\"text\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a904f7ec",
   "metadata": {},
   "source": [
    "## Example tool: get_todays_date\n",
    "\n",
    "Let's define an example tool, `get_todays_date()`, to use in our RAG system. We provide the corresponding function and instructions on how to use it in the [JSON format required by the AWS Converse API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Tool.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cf945de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_todays_date(date_format: str) -> str:\n",
    "    \"\"\"A tool that returns today's date in the date format requested.\"\"\"\n",
    "    datetime_str = datetime.now().strftime(date_format)\n",
    "    return datetime_str\n",
    "\n",
    "\n",
    "todays_date_tool_json = {\n",
    "    \"toolSpec\": {\n",
    "        \"name\": \"get_todays_date\",\n",
    "        \"description\": \"A tool that returns today's date in the date format requested. Options are: '%Y-%m-%d', '%d', '%m', '%Y'.\",\n",
    "        \"inputSchema\": {\n",
    "            \"json\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"date_format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The format that the tool requests the date in.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"date_format\"],\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23f578",
   "metadata": {},
   "source": [
    "### System prompt with tool use instructions\n",
    "\n",
    "For best performance, **add clear instructions on when to use the tool into the system prompt** that governs your LLM. In our system prompt below, we add Step **4** to what is otherwise a typical RAG system prompt. The prompt also instructs the LLM on what fallback answer to respond with when it does not know how to answer a user's query. Such fallback instructions help you reduce hallucinations and more precisely control the AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2695d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "fallback_answer = \"Based on the available information, I cannot provide a complete answer to this question.\"\n",
    "\n",
    "system_prompt = f\"\"\"You are a helpful assistant designed to help users navigate a complex set of documents for question-answering tasks. Answer the user's Question based on the following possibly relevant Context and previous chat history using the tools provided if necessary. Follow these rules in order:\n",
    "    1. NEVER use phrases like \"according to the context\", \"as the context states\", etc. Treat the Context as your own knowledge, not something you are referencing.\n",
    "    2. Use only information from the provided Context.\n",
    "    3. Give a clear, short, and accurate Answer. Explain complex terms if needed.\n",
    "    4. If the answer to the question requires today's date, use the following tool: get_todays_date. Return the date in the exact format the tool provides it.\n",
    "    5. If the Context doesn't adequately address the Question or you are unsure how to answer the Question, say: \"{fallback_answer}\" only, nothing else.\n",
    "\n",
    "    Remember, your purpose is to provide information based on the Context, not to offer original advice.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca3e74",
   "metadata": {},
   "source": [
    "## Conversational RAG with tool calling\n",
    "\n",
    "Now we're ready to run our RAG pipeline. Let's first initialize a `messages` variable to track conversation history. This variable is updated each time we call the `rag()` method to respond to a user query. \n",
    "We'll also select an LLM for our RAG pipeline and define a list of tools that are available (using the `get_todays_date` tool we defined above).\n",
    "\n",
    "After that, we can chat with our RAG app! Here we try a few user queries to evaluate different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "506c8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "model = \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "\n",
    "tool_config = {\"tools\": [todays_date_tool_json]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b874f0-2cf6-4934-99c3-d1c61ffaa4de",
   "metadata": {},
   "source": [
    "### Scenario 1: RAG can answer the question without tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08981e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[internal log] Invoking LLM text:\n",
      "  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\nDimensions: 10 inches height x 4 inches width\n",
      "  \n",
      "  QUESTION:\n",
      "  How big is the water bottle?\n",
      "\n",
      "\n",
      "[RAG response] The Simple Water Bottle - Amber has the following dimensions:\n",
      "\n",
      "10 inches in height\n",
      "4 inches in width\n",
      "\n",
      "These measurements provide a clear picture of the size of the water bottle. It's a relatively tall and slender design, which is common for many reusable water bottles. The 10-inch height would make it suitable for most cup holders, while the 4-inch width ensures it's easy to grip and carry.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"How big is the water bottle?\"\n",
    "\n",
    "rag_response = rag(\n",
    "    model=model,\n",
    "    user_question=user_question,\n",
    "    system_prompt=system_prompt,\n",
    "    tools=tool_config,\n",
    "    messages=messages,\n",
    "    knowledge_base_id=KNOWLEDGE_BASE_ID,\n",
    ")\n",
    "print(f\"[RAG response] {rag_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d9ca5",
   "metadata": {},
   "source": [
    "For this user query, the necessary information is available in the Knowledge Base (as part of the product description).\n",
    "\n",
    "### Scenario 2: RAG can answer the question using tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4061153d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[internal log] Invoking LLM text:\n",
      "  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\nDimensions: 10 inches height x 4 inches width\n",
      "  \n",
      "  QUESTION:\n",
      "  Has the limited edition Amber water bottle already launched?\n",
      "\n",
      "\n",
      "[internal log] Requesting tool get_todays_date with arguments: {'date_format': '%Y-%m-%d'}.\n",
      "[internal log] Tool response: 2025-02-25\n",
      "[RAG response] Based on the information provided in the context and the current date, we can determine that:\n",
      "\n",
      "The Simple Water Bottle - Amber limited edition was launched on January 1st, 2025.\n",
      "Today's date is February 25, 2025.\n",
      "\n",
      "Since today's date (February 25, 2025) is after the launch date (January 1st, 2025), the limited edition Amber water bottle has already launched. It has been available for nearly two months at this point.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Has the limited edition Amber water bottle already launched?\"\n",
    "\n",
    "rag_response = rag(\n",
    "    model=model,\n",
    "    user_question=user_question,\n",
    "    system_prompt=system_prompt,\n",
    "    tools=tool_config,\n",
    "    messages=messages,\n",
    "    knowledge_base_id=KNOWLEDGE_BASE_ID,\n",
    ")\n",
    "print(f\"[RAG response] {rag_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2322f4ef",
   "metadata": {},
   "source": [
    "For this user query, the LLM chose to call our `get_todays_date` tool to obtain necessary information. Note that a proper answer to this question requires considering information from the Knowledge Base as well.\n",
    "\n",
    "### Scenario 3: RAG can answer the question considering conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a941bc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[internal log] Invoking LLM text:\n",
      "  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\nDimensions: 10 inches height x 4 inches width\n",
      "  \n",
      "  QUESTION:\n",
      "  What is the full name of it?\n",
      "\n",
      "\n",
      "[RAG response] The full name of the product is Simple Water Bottle - Amber. This is a limited edition version of the water bottle that was launched on January 1st, 2025.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What is the full name of it?\"\n",
    "\n",
    "rag_response = rag(\n",
    "    model=model,\n",
    "    user_question=user_question,\n",
    "    system_prompt=system_prompt,\n",
    "    tools=tool_config,\n",
    "    messages=messages,\n",
    "    knowledge_base_id=KNOWLEDGE_BASE_ID,\n",
    ")\n",
    "print(f\"[RAG response] {rag_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8899dd",
   "metadata": {},
   "source": [
    "This user query only makes sense when taking the conversation history into account.\n",
    "\n",
    "### Scenario 4: RAG cannot answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bf3786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[internal log] Invoking LLM text:\n",
      "  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\nDimensions: 10 inches height x 4 inches width\n",
      "  \n",
      "  QUESTION:\n",
      "  Can I return my simple water bottle?\n",
      "\n",
      "\n",
      "[RAG response] Based on the available information, I cannot provide a complete answer to this question.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Can I return my simple water bottle?\"\n",
    "\n",
    "rag_response = rag(\n",
    "    model=model,\n",
    "    user_question=user_question,\n",
    "    system_prompt=system_prompt,\n",
    "    tools=tool_config,\n",
    "    messages=messages,\n",
    "    knowledge_base_id=KNOWLEDGE_BASE_ID,\n",
    ")\n",
    "print(f\"[RAG response] {rag_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c139ddd-c58c-4330-ac8b-f441b8915570",
   "metadata": {},
   "source": [
    "Note that the Knowledge Base does not contain information about the return policy, and the `get_todays_date` tool would not help either. In this case, the best our RAG app can do is to return our fallback response to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb4f060-cc3a-492e-aa0d-20904802d94f",
   "metadata": {},
   "source": [
    "**Optional: Review full message history (includes tool calls)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5f264c7-821d-4175-8282-59d022617138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': [{'text': '  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\\\nDimensions: 10 inches height x 4 inches width\\n  \\n  QUESTION:\\n  How big is the water bottle?'}]}\n",
      "{'role': 'assistant', 'content': [{'text': \"The Simple Water Bottle - Amber has the following dimensions:\\n\\n10 inches in height\\n4 inches in width\\n\\nThese measurements provide a clear picture of the size of the water bottle. It's a relatively tall and slender design, which is common for many reusable water bottles. The 10-inch height would make it suitable for most cup holders, while the 4-inch width ensures it's easy to grip and carry.\"}]}\n",
      "{'role': 'user', 'content': [{'text': '  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\\\nDimensions: 10 inches height x 4 inches width\\n  \\n  QUESTION:\\n  Has the limited edition Amber water bottle already launched?'}]}\n",
      "{'role': 'assistant', 'content': [{'text': \"To answer this question accurately, we need to know today's date and compare it to the launch date of the Simple Water Bottle - Amber limited edition. Let's use the get_todays_date tool to find out the current date.\"}, {'toolUse': {'toolUseId': 'tooluse_gnYJBA6sSiy2gt7Mr1CJbw', 'name': 'get_todays_date', 'input': {'date_format': '%Y-%m-%d'}}}]}\n",
      "{'role': 'user', 'content': [{'toolResult': {'toolUseId': 'tooluse_gnYJBA6sSiy2gt7Mr1CJbw', 'content': [{'json': {'response': '2025-02-25'}}]}}]}\n",
      "{'role': 'assistant', 'content': [{'text': \"Based on the information provided in the context and the current date, we can determine that:\\n\\nThe Simple Water Bottle - Amber limited edition was launched on January 1st, 2025.\\nToday's date is February 25, 2025.\\n\\nSince today's date (February 25, 2025) is after the launch date (January 1st, 2025), the limited edition Amber water bottle has already launched. It has been available for nearly two months at this point.\"}]}\n",
      "{'role': 'user', 'content': [{'text': '  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\\\nDimensions: 10 inches height x 4 inches width\\n  \\n  QUESTION:\\n  What is the full name of it?'}]}\n",
      "{'role': 'assistant', 'content': [{'text': 'The full name of the product is Simple Water Bottle - Amber. This is a limited edition version of the water bottle that was launched on January 1st, 2025.'}]}\n",
      "{'role': 'user', 'content': [{'text': '  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\\\nDimensions: 10 inches height x 4 inches width\\n  \\n  QUESTION:\\n  Can I return my simple water bottle?'}]}\n",
      "{'role': 'assistant', 'content': [{'text': 'Based on the available information, I cannot provide a complete answer to this question.'}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# message history\n",
    "for message in messages:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f722da24",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Adding tool calls to your RAG system expands the capabilities of what your AI can do and the types of questions it can answer.\n",
    "\n",
    "Once you have a RAG app with tools set up, adding **Codex as-a-Tool** takes only a few lines of code.\n",
    "Codex enables your RAG app to answer questions it previously could not (like [Scenario 4 above](/codex/tutorials/aws/AWSBedrock_ToolCalls/#scenario-4-rag-cannot-answer-the-question)). Learn how via our tutorial: [Integrate Codex as-a-Tool with AWS Bedrock Knowledge Bases](/codex/tutorials/aws/AWSBedrock_AddingCodexAsTool/).\n",
    "\n",
    "Need help? Check the [FAQ](/codex/FAQ/) or email us at: support@cleanlab.ai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d139b7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}