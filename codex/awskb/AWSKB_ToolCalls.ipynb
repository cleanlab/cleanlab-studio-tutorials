{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef439dee",
   "metadata": {},
   "source": [
    "# RAG with Tool Calls in AWS Bedrock Knowledge Bases\n",
    "\n",
    "This tutorial covers the basics of building a conversational RAG application that supports tool calls, via the [AWS Bedrock Knowledge Bases](https://aws.amazon.com/bedrock/knowledge-bases/) and [Converse](https://docs.aws.amazon.com/bedrock/latest/userguide/tool-use-inference-call.html) APIs.\n",
    "Here we demonstrate how to build the specific RAG app used in our [Integrate Codex as-a-Tool with AWS Bedrock Knowledge Bases](/codex/tutorials/awskb/AWSKB_AddingCodexAsTool/) tutorial. Remember that Codex works with *any* RAG app, you can easily translate these ideas to more complex RAG pipelines.\n",
    "\n",
    "Here's a typical architecture for RAG apps with tool calling:\n",
    "\n",
    "![RAG Workflow](../assets/codexastool_retrievalfirst.png)\n",
    "\n",
    "Let's first install packages required for this tutorial and set up required AWS configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f921c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U boto3  # we used package-version 1.36.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffce3d6-3ab0-40a4-b3a9-6da66bbb41ec",
   "metadata": {},
   "source": [
    "**Optional: Set up AWS configurations**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d8db5-184a-4f6c-988e-a822cbf71958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = (\n",
    "    \"<YOUR_AWS_ACCESS_KEY_ID>\"  # Your permament access key (not session access key)\n",
    ")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = (\n",
    "    \"<YOUR_AWS_SECRET_ACCESS_KEY>\"  # Your permament secret access key (not session secret access key)\n",
    ")\n",
    "os.environ[\"MFA_DEVICE_ARN\"] = (\n",
    "    \"<YOUR_MFA_DEVICE_ARN>\"  # If your organization requires MFA, find this in AWS Console under: settings -> security credentials -> your mfa device\n",
    ")\n",
    "os.environ[\"AWS_REGION\"] = \"us-east-1\"  # Specify your AWS region\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "region_name = os.getenv(\"AWS_REGION\", \"us-east-1\")  # Default to 'us-east-1' if not set\n",
    "mfa_serial_number = os.getenv(\"MFA_DEVICE_ARN\")\n",
    "\n",
    "# Ensure required environment variables are set\n",
    "if not all([aws_access_key_id, aws_secret_access_key, mfa_serial_number]):\n",
    "    raise EnvironmentError(\n",
    "        \"Missing required environment variables. Ensure AWS_ACCESS_KEY_ID, \"\n",
    "        \"AWS_SECRET_ACCESS_KEY, and MFA_DEVICE_ARN are set.\"\n",
    "    )\n",
    "\n",
    "# Enter MFA code in case your AWS organization requires it\n",
    "mfa_token_code = input(\"Enter your MFA code: \")\n",
    "print(\"MFA code entered: \", mfa_token_code)\n",
    "\n",
    "sts_client = boto3.client(\n",
    "    \"sts\",\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=region_name,\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Request temporary credentials\n",
    "    response = sts_client.get_session_token(\n",
    "        DurationSeconds=3600 * 24,  # Valid for 24 hours\n",
    "        SerialNumber=mfa_serial_number,\n",
    "        TokenCode=mfa_token_code,\n",
    "    )\n",
    "\n",
    "    temp_credentials = response[\"Credentials\"]\n",
    "    temp_access_key = temp_credentials[\"AccessKeyId\"]\n",
    "    temp_secret_key = temp_credentials[\"SecretAccessKey\"]\n",
    "    temp_session_token = temp_credentials[\"SessionToken\"]\n",
    "\n",
    "    # Create a Bedrock Agent Runtime client\n",
    "    client = boto3.client(\n",
    "        \"bedrock-agent-runtime\",\n",
    "        aws_access_key_id=temp_access_key,\n",
    "        aws_secret_access_key=temp_secret_key,\n",
    "        aws_session_token=temp_session_token,\n",
    "        region_name=region_name,\n",
    "    )\n",
    "    print(\"Bedrock client successfully created.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Bedrock client: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f831704",
   "metadata": {},
   "source": [
    "Initialize Bedrock retrieval and generation clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46279df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "\n",
    "BEDROCK_RETRIEVE_CLIENT = boto3.client(\n",
    "    \"bedrock-agent-runtime\",\n",
    "    config=bedrock_config,\n",
    "    aws_access_key_id=temp_access_key,\n",
    "    aws_secret_access_key=temp_secret_key,\n",
    "    aws_session_token=temp_session_token,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "BEDROCK_GENERATION_CLIENT = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    aws_access_key_id=temp_access_key,\n",
    "    aws_secret_access_key=temp_secret_key,\n",
    "    aws_session_token=temp_session_token,\n",
    "    region_name=region_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b96ab5",
   "metadata": {},
   "source": [
    "## Example RAG App: Product Customer Support\n",
    "\n",
    "Consider a customer support / e-commerce RAG use-case where the Knowledge Base contains product listings like the following:\n",
    "\n",
    "![Simple water bottle product listing](../assets/simple_water_bottle.png)\n",
    "\n",
    "### Creating a Knowledge Base\n",
    "\n",
    "To keep our example simple, we upload the product description to AWS S3 as a single file: `simple_water_bottle.txt`. This is the sole file our Knowledge Base will contain, but you can populate your actual Knowledge Base with many heterogeneous documents.\n",
    "\n",
    "To create a Knowledge Base using Amazon Bedrock, refer to the [official documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-create.html).\n",
    "\n",
    "After you've created it, add your `KNOWLEDGE_BASE_ID` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef2399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWLEDGE_BASE_ID = 'DASYAHIOKX'  # replace with your own Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ceaea-53ec-42dd-89f7-66f39676eade",
   "metadata": {},
   "source": [
    "### Implement a standard RAG pipeline\n",
    "\n",
    "A RAG pipeline has two key steps -- retrieval and generation, which implement using AWS Bedrock APIs. We'll add tool calling support to the generation step.\n",
    "\n",
    "#### Retrieval in AWS Knowledge Bases\n",
    "\n",
    "We define helper methods for retrieving context from our Knowledge Base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64ff7b9-e81f-4d41-9310-d48f66ca9d55",
   "metadata": {},
   "source": [
    "**Optional: Helper methods for Retrieval in AWS Knowledge Bases**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b7b8362-f4e6-4f8f-886b-5dfccce6e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve(query, knowledgebase_id, numberOfResults=3):\n",
    "    \"\"\"Fetches relevant document chunks to query from Knowledge Base using AWS Bedrock Agent Runtime\"\"\"\n",
    "    return BEDROCK_RETRIEVE_CLIENT.retrieve(\n",
    "        retrievalQuery= {\n",
    "            'text': query\n",
    "        },\n",
    "        knowledgeBaseId=knowledgebase_id,\n",
    "        retrievalConfiguration= {\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': numberOfResults,\n",
    "                'overrideSearchType': \"HYBRID\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def retrieve_and_get_contexts(query, kbId, numberOfResults=3, threshold=0.0):\n",
    "    \"\"\"Fetches relevant contexts and properly formats them for the subsequent LLM response generation step.\"\"\"\n",
    "    retrieval_results = retrieve(query, kbId, numberOfResults)\n",
    "    contexts = []\n",
    "    \n",
    "    for retrievedResult in retrieval_results['retrievalResults']:\n",
    "        if retrievedResult['score'] >= threshold:\n",
    "            text = retrievedResult['content']['text']\n",
    "            if text.startswith(\"Document 1: \"):\n",
    "                text = text[len(\"Document 1: \"):]  # Remove prefix if present\n",
    "            contexts.append(text)\n",
    "    \n",
    "    return contexts\n",
    "\n",
    "\n",
    "SCORE_THRESHOLD = 0.3  #  Similarity score threshold for retrieving context to use in our RAG app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0cd392",
   "metadata": {},
   "source": [
    "Let's run our retrieval with a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0c05a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\nDimensions: 10 inches height x 4 inches width\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the Simple Water Bottle?\"\n",
    "\n",
    "print(retrieve_and_get_contexts(query, KNOWLEDGE_BASE_ID)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b41e92",
   "metadata": {},
   "source": [
    "### Response generation with tool calling\n",
    "\n",
    "To generate responses with an LLM that can also call tools, we pass the user query and retrieved context from our Knowledge Base into the AWS Converse API.\n",
    "\n",
    "This API can either return a string response from the LLM or a tool call. If the output is a tool call, our method will keep prompting the Converse API until the LLM returns a string response after processing the result of tool call(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cfeb3d-7026-4e34-8a8d-252f96cfa4c6",
   "metadata": {},
   "source": [
    "**Optional: Helper methods for response generation with tool calling via AWS Converse API**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06cfe0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "def form_prompt(user_question: str, contexts: list) -> str:\n",
    "    \"\"\"Forms the prompt to be used for querying the model.\"\"\"\n",
    "    context_strings = \"\\n\\n\".join([f\"Context {i + 1}: {context}\" for i, context in enumerate(contexts)])\n",
    "    query_with_context = f\"{context_strings}\\n\\nQUESTION:\\n{user_question}\"\n",
    "\n",
    "    indented_question_with_context = \"\\n\".join(f\"  {line}\" for line in query_with_context.splitlines())\n",
    "    return indented_question_with_context\n",
    "\n",
    "def generate_text(user_question: str, model: str, tools: list[dict], system_prompts: list, messages: list[dict], bedrock_client) -> list[dict]:\n",
    "    \"\"\"Generates text dynamically handling tool use within Amazon Bedrock.\n",
    "    Params:\n",
    "        messages: List of message history in the desired format.\n",
    "        model: Identifier for the Amazon Bedrock model.\n",
    "        tools: List of tools the model can call.\n",
    "        bedrock_client: Client to interact with Bedrock API.\n",
    "    Returns:\n",
    "        messages: Final updated list of messages including tool interactions and responses.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initial call to the model\n",
    "    response = bedrock_client.converse(\n",
    "        modelId=model,\n",
    "        messages=messages,\n",
    "        toolConfig=tools,\n",
    "        system=system_prompts,\n",
    "    )\n",
    "\n",
    "    output_message = response[\"output\"][\"message\"]\n",
    "    stop_reason = response[\"stopReason\"]\n",
    "    messages.append(output_message)\n",
    "\n",
    "    while stop_reason == \"tool_use\":\n",
    "        # Extract tool requests from the model response\n",
    "        tool_requests = output_message.get(\"content\", [])\n",
    "\n",
    "        for tool_request in tool_requests:\n",
    "            if \"toolUse\" in tool_request:\n",
    "                tool = tool_request[\"toolUse\"]\n",
    "                tool_name = tool[\"name\"]\n",
    "                tool_input = tool[\"input\"]\n",
    "                tool_use_id = tool[\"toolUseId\"]\n",
    "                \n",
    "                try:\n",
    "                    # If you don't want the original question to be modified, use this instead\n",
    "                    if 'question' in tool['input'].keys():\n",
    "                        tool['input']['question'] = user_question\n",
    "                    print(f\"[internal log] Requesting tool {tool['name']}. with arguments: {tool_input}.\")\n",
    "                    tool_output_json = _handle_any_tool_call_for_stream_response(tool_name, tool_input)\n",
    "                    tool_result = json.loads(tool_output_json)\n",
    "                    print(f\"[internal log] Tool response: {tool_result}\")\n",
    "\n",
    "                    # If tool call resulted in an error\n",
    "                    if \"error\" in tool_result:\n",
    "                        tool_result_message = {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [{\"toolResult\": {\n",
    "                                \"toolUseId\": tool_use_id,\n",
    "                                \"content\": [{\"text\": tool_result[\"error\"]}],\n",
    "                                \"status\": \"error\"\n",
    "                            }}]\n",
    "                        }\n",
    "                    else:\n",
    "                        # Format successful tool response\n",
    "                        tool_result_message = {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [{\"toolResult\": {\n",
    "                                \"toolUseId\": tool_use_id,\n",
    "                                \"content\": [{\"json\": {\"response\": tool_result}}]\n",
    "                            }}]\n",
    "                        }\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Handle unexpected exceptions during tool handling\n",
    "                    tool_result_message = {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [{\"toolResult\": {\n",
    "                            \"toolUseId\": tool_use_id,\n",
    "                            \"content\": [{\"text\": f\"Error processing tool: {str(e)}\"}],\n",
    "                            \"status\": \"error\"\n",
    "                        }}]\n",
    "                    }\n",
    "\n",
    "                # Append the tool result to messages\n",
    "                messages.append(tool_result_message)\n",
    "\n",
    "        # Send the updated messages back to the model\n",
    "        response = bedrock_client.converse(\n",
    "            modelId=model,\n",
    "            messages=messages,\n",
    "            toolConfig=tools,\n",
    "            system=system_prompts,\n",
    "        )\n",
    "\n",
    "        output_message = response[\"output\"][\"message\"]\n",
    "        stop_reason = response[\"stopReason\"]\n",
    "        messages.append(output_message)\n",
    "\n",
    "    return messages\n",
    "\n",
    "def _handle_any_tool_call_for_stream_response(function_name: str, arguments: dict) -> str:\n",
    "    \"\"\"Handles any tool dynamically by calling the function by name and passing in collected arguments.\n",
    "       Returns a dictionary of the tool output.\n",
    "       Returns error message if the tool is not found, not callable, or called incorrectly.\n",
    "    \"\"\"\n",
    "    tool_function = globals().get(function_name) or locals().get(function_name)\n",
    "\n",
    "    if callable(tool_function):\n",
    "        try:\n",
    "            # Dynamically call the tool function with arguments\n",
    "            tool_output = tool_function(**arguments)\n",
    "            return json.dumps(tool_output)\n",
    "        except Exception as e:\n",
    "            return json.dumps({\n",
    "                \"error\": f\"Exception while calling tool '{function_name}': {str(e)}\",\n",
    "                \"arguments\": arguments,\n",
    "            })\n",
    "    else:\n",
    "        return json.dumps({\n",
    "            \"error\": f\"Tool '{function_name}' not found or not callable.\",\n",
    "            \"arguments\": arguments,\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d098d34a",
   "metadata": {},
   "source": [
    "### Define single-turn RAG app\n",
    "\n",
    "We integrate the above helper methods into a standard RAG app that can respond to any user query, calling tools as the LLM deems necessary. Our `rag()` method can be called multiple times in a conversation, as long as a `messages` variable is provided each time to track conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69af81b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(model: str, user_question: str, system_prompt: str, tools: list[dict], messages: list, knowledgebase_id: str) -> str:\n",
    "    \"\"\"Performs Retrieval-Augmented Generation using the provided model and tools.\n",
    "    Params:\n",
    "        model: Model name or ID.\n",
    "        user_question: The user's question or query.\n",
    "        system_prompt: System message to set context or behavior.\n",
    "        tools: List of tools the model can call.\n",
    "        knowledgebase_id: Knowledge base ID for retrieving contexts.\n",
    "        messages: Optional list of prior conversation history.\n",
    "    Returns:\n",
    "        Final response text generated by the model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve contexts based on the user query and knowledge base ID\n",
    "    contexts = retrieve_and_get_contexts(user_question, knowledgebase_id,threshold= SCORE_THRESHOLD)\n",
    "    query_with_context = form_prompt(user_question, contexts)\n",
    "    print(f\"[internal log] Invoking LLM with prompt + context\\n{query_with_context}\\n\\n\")\n",
    "\n",
    "    # Construct the user message with the retrieved contexts\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": query_with_context}]\n",
    "    }\n",
    "    messages.append(user_message)\n",
    "    system_prompts = [{'text': system_prompt}]\n",
    "    # Call generate_text with the updated messages\n",
    "    final_messages = generate_text(\n",
    "        user_question=user_question,\n",
    "        model=model,\n",
    "        tools=tools,\n",
    "        system_prompts=system_prompts,\n",
    "        messages=messages,\n",
    "        bedrock_client=BEDROCK_GENERATION_CLIENT, \n",
    "    )\n",
    "\n",
    "    # Extract and return the final response text\n",
    "    return final_messages[-1][\"content\"][-1][\"text\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a904f7ec",
   "metadata": {},
   "source": [
    "## Example tool: get_todays_date\n",
    "\n",
    "Let's define an example tool, `get_todays_date()`, to use in our RAG system. We provide the corresponding function and instructions on how to use it in a JSON format required by the AWS Converse API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cf945de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_todays_date(date_format: str) -> str:\n",
    "  \"\"\"A tool that returns today's date in the date format requested.\"\"\"\n",
    "  datetime_str = datetime.now().strftime(date_format)\n",
    "  return datetime_str\n",
    "\n",
    "todays_date_tool_json = {\n",
    "  \"toolSpec\": {\n",
    "    \"name\": \"get_todays_date\",\n",
    "    \"description\": \"A tool that returns today's date in the date format requested. Options are: '%Y-%m-%d', '%d', '%m', '%Y'.\",\n",
    "    \"inputSchema\": {\n",
    "      \"json\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"date_format\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The format that the tool requests the date in.\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"date_format\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23f578",
   "metadata": {},
   "source": [
    "### System prompt with tool use instructions\n",
    "\n",
    "For the best performance, **add clear instructions on when to use the tool into the system prompt** that governs your LLM. Below we simply add Step **3.** in our list of instructions, which otherwise represent a typical RAG system prompt. In most RAG apps, one instructs the LLM on what fallback answer to respond with when it does not know how to answer a user's query. Such fallback instructions help you reduce hallucinations and more precisely control the AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2695d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "fallback_answer = \"Based on the available information, I cannot provide a complete answer to this question.\"\n",
    "\n",
    "system_prompt = f\"\"\"You are a helpful assistant designed to help users navigate a complex set of documents for question-answering tasks. Answer the user's Question based on the following possibly relevant Context and previous chat history using the tools provided if necessary. Follow these rules in order:\n",
    "    1. NEVER use phrases like \"according to the context,\" \"as the context states,\" etc. Treat the Context as your own knowledge, not something you are referencing.\n",
    "    2. Use only information from the provided Context. Your purpose is to provide information based on the Context, not to offer original advice.\n",
    "    3. Give a clear, short, and accurate answer. Explain complex terms if needed.\n",
    "    4. If the answer to the question requires today's date, use the following tool: get_todays_date. Return the date in the exact format the tool provides it.\n",
    "    5. If you remain unsure how to answer the Question  then only respond with: \"{fallback_answer}\".\n",
    "\n",
    "    Remember, your purpose is to provide information based on the Context, not to offer original advice.\n",
    "\"\"\".format(\n",
    "        fallback_answer=fallback_answer\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca3e74",
   "metadata": {},
   "source": [
    "## Conversational RAG with tool calling\n",
    "\n",
    "We track conversation history in a `messages` variable that is updated each time we call the `rag()` method to respond to a user query. \n",
    "Let's also select a LLM for our RAG pipeline and which tools are available.\n",
    "\n",
    "After that, we can chat with our RAG app! Here we try a few user queries to evaluate different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "506c8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "model = 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "\n",
    "tool_config = {\n",
    "    \"tools\": [todays_date_tool_json]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b874f0-2cf6-4934-99c3-d1c61ffaa4de",
   "metadata": {},
   "source": [
    "### Scenario 1: RAG can answer the question without tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08981e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[internal log] Invoking LLM with prompt + context\n",
      "  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\nDimensions: 10 inches height x 4 inches width\n",
      "  \n",
      "  QUESTION:\n",
      "  How big is the water bottle?\n",
      "\n",
      "\n",
      "[RAG response] The Simple Water Bottle - Amber has the following dimensions:\n",
      "\n",
      "10 inches in height\n",
      "4 inches in width\n",
      "\n",
      "These dimensions indicate that it's a fairly standard-sized water bottle, tall enough to hold a good amount of liquid while still being easy to carry and fit into most cup holders or bag pockets.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"How big is the water bottle?\"\n",
    "\n",
    "rag_response = rag(model=model, user_question=user_question, system_prompt=system_prompt, tools=tool_config, messages=messages, knowledgebase_id=KNOWLEDGE_BASE_ID)\n",
    "print(f'[RAG response] {rag_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d9ca5",
   "metadata": {},
   "source": [
    "For this user query, the necessary information is available in the Knowledge Base (as part of the product description).\n",
    "\n",
    "### Scenario 2: RAG can answer the question using tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4061153d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[internal log] Invoking LLM with prompt + context\n",
      "  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\nDimensions: 10 inches height x 4 inches width\n",
      "  \n",
      "  QUESTION:\n",
      "  Has the limited edition Amber water bottle already launched?\n",
      "\n",
      "\n",
      "[internal log] Requesting tool get_todays_date. with arguments: {'date_format': '%Y-%m-%d'}.\n",
      "[internal log] Tool response: 2025-02-13\n",
      "[RAG response] Based on the information provided and today's date, I can answer your question:\n",
      "\n",
      "The limited edition Amber water bottle has already launched. The context states that it was launched on January 1st, 2025, and today's date is February 13, 2025. This means the water bottle has been available for about a month and a half.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Has the limited edition Amber water bottle already launched?\"\n",
    "\n",
    "rag_response = rag(model=model, user_question=user_question, system_prompt=system_prompt, tools=tool_config, messages=messages, knowledgebase_id=KNOWLEDGE_BASE_ID)\n",
    "print(f'[RAG response] {rag_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2322f4ef",
   "metadata": {},
   "source": [
    "For this user query, the LLM chose to call our `get_todays_date` tool to obtain necessary information. Note that a proper answer to this question also requires considering information from the Knowledge Base as well.\n",
    "\n",
    "### Scenario 3: RAG can answer the question considering conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a941bc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[internal log] Invoking LLM with prompt + context\n",
      "  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\nDimensions: 10 inches height x 4 inches width\n",
      "  \n",
      "  QUESTION:\n",
      "  What is the full name of it?\n",
      "\n",
      "\n",
      "[RAG response] The full name of the product is:\n",
      "\n",
      "Simple Water Bottle - Amber\n",
      "\n",
      "This name encompasses both the product type and its specific color variant, which is described as a limited edition.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What is the full name of it?\"\n",
    "\n",
    "rag_response = rag(model=model, user_question=user_question, system_prompt=system_prompt, tools=tool_config, messages=messages, knowledgebase_id=KNOWLEDGE_BASE_ID)\n",
    "print(f'[RAG response] {rag_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8899dd",
   "metadata": {},
   "source": [
    "This user query only makes sense taking the conversation history into account.\n",
    "\n",
    "### Scenario 4: RAG cannot answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bf3786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[internal log] Invoking LLM with prompt + context\n",
      "  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\nDimensions: 10 inches height x 4 inches width\n",
      "  \n",
      "  QUESTION:\n",
      "  Can I return my simple water bottle?\n",
      "\n",
      "\n",
      "[RAG response] Based on the available information, I cannot provide a complete answer to this question. The given context does not include any details about return policies or procedures for the Simple Water Bottle - Amber. To answer this question accurately, we would need additional information about the company's return policy or specific terms and conditions for this product.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Can I return my simple water bottle?\"\n",
    "\n",
    "rag_response = rag(model=model, user_question=user_question, system_prompt=system_prompt, tools=tool_config, messages=messages, knowledgebase_id=KNOWLEDGE_BASE_ID)\n",
    "print(f'[RAG response] {rag_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c139ddd-c58c-4330-ac8b-f441b8915570",
   "metadata": {},
   "source": [
    "Note that the Knowledge Base does not contain information about the return policy, and the `get_todays_date` tool would not help either. In this case, the best our RAG app can do is to return our fallback response to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0b1d2-6e49-4fee-8c15-5c84da81838c",
   "metadata": {},
   "source": [
    "**Optional: Review full message history (includes tool calls)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5f264c7-821d-4175-8282-59d022617138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': [{'text': '  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\\\nDimensions: 10 inches height x 4 inches width\\n  \\n  QUESTION:\\n  How big is the water bottle?'}]}\n",
      "{'role': 'assistant', 'content': [{'text': \"The Simple Water Bottle - Amber has the following dimensions:\\n\\n10 inches in height\\n4 inches in width\\n\\nThese dimensions indicate that it's a fairly standard-sized water bottle, tall enough to hold a good amount of liquid while still being easy to carry and fit into most cup holders or bag pockets.\"}]}\n",
      "{'role': 'user', 'content': [{'text': '  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\\\nDimensions: 10 inches height x 4 inches width\\n  \\n  QUESTION:\\n  Has the limited edition Amber water bottle already launched?'}]}\n",
      "{'role': 'assistant', 'content': [{'text': \"To answer this question accurately, I need to know today's date and compare it with the launch date of the Simple Water Bottle - Amber limited edition. Let me use the available tool to get today's date.\"}, {'toolUse': {'toolUseId': 'tooluse_yjXK7j33T7yCaR-cXHVsvQ', 'name': 'get_todays_date', 'input': {'date_format': '%Y-%m-%d'}}}]}\n",
      "{'role': 'user', 'content': [{'toolResult': {'toolUseId': 'tooluse_yjXK7j33T7yCaR-cXHVsvQ', 'content': [{'json': {'response': '2025-02-13'}}]}}]}\n",
      "{'role': 'assistant', 'content': [{'text': \"Based on the information provided and today's date, I can answer your question:\\n\\nThe limited edition Amber water bottle has already launched. The context states that it was launched on January 1st, 2025, and today's date is February 13, 2025. This means the water bottle has been available for about a month and a half.\"}]}\n",
      "{'role': 'user', 'content': [{'text': '  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\\\nDimensions: 10 inches height x 4 inches width\\n  \\n  QUESTION:\\n  What is the full name of it?'}]}\n",
      "{'role': 'assistant', 'content': [{'text': 'The full name of the product is:\\n\\nSimple Water Bottle - Amber\\n\\nThis name encompasses both the product type and its specific color variant, which is described as a limited edition.'}]}\n",
      "{'role': 'user', 'content': [{'text': '  Context 1: Simple Water Bottle - Amber (limited edition launched Jan 1st 2025) A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish. Price: $24.99 \\\\nDimensions: 10 inches height x 4 inches width\\n  \\n  QUESTION:\\n  Can I return my simple water bottle?'}]}\n",
      "{'role': 'assistant', 'content': [{'text': \"Based on the available information, I cannot provide a complete answer to this question. The given context does not include any details about return policies or procedures for the Simple Water Bottle - Amber. To answer this question accurately, we would need additional information about the company's return policy or specific terms and conditions for this product.\"}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For educational purposes, we passed `messages` into every RAG call and logged every step in this variable.\n",
    "\n",
    "for message in messages:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f722da24",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Adding tool calls to your RAG system expands the capabilities of what your AI can do and the types of questions it can answer.\n",
    "\n",
    "Once you have a RAG app with tools set up, adding **Codex as-a-Tool** takes only a few lines of code.\n",
    "Codex enables your RAG app to answer questions it previously could not (like Scenario 4 above). Learn how via our tutorial: [Integrate Codex as-a-Tool with AWS Bedrock Knowledge Bases](/codex/tutorials/awskb/AWSKB_AddingCodexAsTool/).\n",
    "\n",
    "Need help? Check the [FAQ](/codex/FAQ/) or email us at: support@cleanlab.ai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}