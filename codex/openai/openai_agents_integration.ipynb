{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Cleanlab with OpenAI Agents\n",
    "\n",
    "This tutorial demonstrates how to add real-time validation and trustworthiness scoring to AI Agents built with the [OpenAI Agents SDK](https://openai.github.io/openai-agents-python/). With *minimal* changes to your existing OpenAI Agent code, you can detect problematic responses and automatically remediate them in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The Python packages required for this tutorial can be installed using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade cleanlab-codex openai-agents tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial requires a Cleanlab API key. Get one [here](https://codex.cleanlab.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CODEX_API_KEY\"] = \"<Cleanlab Codex API key>\"  # Get your API key from: https://codex.cleanlab.ai/\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<OpenAI API key>\"  # Get API key from: https://platform.openai.com/signup\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"<TAVILY API KEY>\"  # for using a web search tool (get your free API key from Tavily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab_codex.client import Client\n",
    "from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of this tutorial\n",
    "\n",
    "This tutorial showcases using Cleanlab's validation hooks to add real-time validation to OpenAI Agents. \n",
    "\n",
    "We'll demonstrate five key scenarios:\n",
    "\n",
    "1. **Conversational Chat Response** - Basic agent interaction with validation\n",
    "2. **Tool Call Response** - Agent response using tools with validation\n",
    "3. **Bad AI Response** - How Cleanlab detects and scores problematic responses\n",
    "4. **Expert Answer Response** - A deterministic remediation to problematic responses\n",
    "5. **Information Retrieval Tool Call Response** - Context-aware validation with web search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Cleanlab Project\n",
    "\n",
    "To use the Cleanlab AI Platform for validation, we must first [create a Project](/codex/web_tutorials/create_project/).\n",
    "Here we assume no (question, answer) pairs have already been added to the Project yet.\n",
    "\n",
    "User queries where Cleanlab detected a bad response from your AI app will be logged in this Project for SMEs to later answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Cleanlab project\n",
    "client = Client()\n",
    "\n",
    "project = client.create_project(\n",
    "    name=\"OpenAI Agent with Cleanlab Validation Tutorial\",\n",
    "    description=\"Tutorial demonstrating validation of an OpenAI Agent with Cleanlab hooks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Use Case: Bank Loan Customer Support\n",
    "\n",
    "We'll build a customer support agent for bank loans to demonstrate validation scenarios.\n",
    "\n",
    "Let's define tools representing different response quality levels:\n",
    "- a *good* tool that returns reasonable information\n",
    "- a *bad* tool that returns problematic information\n",
    "- a web search tool that provides additional *context* to the Agent\n",
    "\n",
    "**Note:** The web search tool follows the example information retrieval function defined in the [Strands Web Search tutorial](https://aws.amazon.com/blogs/machine-learning/build-dynamic-web-research-agents-with-the-strands-agents-sdk-and-tavily/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce4ecbc-3968-4493-9e6a-12d32a21613c",
   "metadata": {},
   "source": [
    "**Optional: Tool definitions for demonstration scenarios**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.tool import function_tool\n",
    "\n",
    "# ============ Good Tool: Returns reasonable information ============\n",
    "@function_tool\n",
    "def get_payment_schedule(account_id: str) -> str:\n",
    "    \"\"\"Get payment schedule for an account.\"\"\"\n",
    "    payment_schedule = f\"\"\"Account {account_id} has: \n",
    "        Bi-weekly payment plan\n",
    "        Upcoming payment scheduled for next Friday\n",
    "    \"\"\"\n",
    "    return payment_schedule\n",
    "\n",
    "# ============ Bad Tool: Returns problematic information ============\n",
    "@function_tool\n",
    "def get_total_amount_owed(account_id: str) -> dict:\n",
    "    \"\"\"A tool that simulates fetching the total amount owed for a loan.\n",
    "    **Note:** This tool returns a hardcoded *unrealistic* total amount for demonstration purposes.\"\"\"\n",
    "    return {\n",
    "        \"account_id\": account_id,\n",
    "        \"currency\": \"USD\",\n",
    "        \"total\": 7000000000000000000000000000000000000.00,\n",
    "    }\n",
    "\n",
    "# ============ Web Search Tool: Provides context for the Agent ============\n",
    "@function_tool\n",
    "def web_search(\n",
    "    query: str, time_range: str | None = None, include_domains: str | None = None\n",
    ") -> str:\n",
    "    \"\"\"Perform a web search. Returns the search results as a string, with the title, url, and content of each result ranked by relevance.\n",
    "    Args:\n",
    "        query (str): The search query to be sent for the web search.\n",
    "        time_range (str | None, optional): Limits results to content published within a specific timeframe.\n",
    "            Valid values: 'd' (day - 24h), 'w' (week - 7d), 'm' (month - 30d), 'y' (year - 365d).\n",
    "            Defaults to None.\n",
    "        include_domains (list[str] | None, optional): A list of domains to restrict search results to.\n",
    "            Only results from these domains will be returned. Defaults to None.\n",
    "    Returns:\n",
    "        formatted_results (str): The web search results\n",
    "    \"\"\"\n",
    "    \n",
    "    def format_search_results_for_agent(search_results: list[dict]) -> str:\n",
    "        \"\"\"Format search results into a numbered context string for the agent.\"\"\"\n",
    "        results = search_results[\"results\"]\n",
    "        parts = []\n",
    "        for i, r in enumerate(results, start=1):\n",
    "            title = r.get(\"title\", \"\").strip()\n",
    "            content = r.get(\"content\", \"\").strip()\n",
    "            if title or content:\n",
    "                block = (\n",
    "                    f\"Context {i}:\\n\"\n",
    "                    f\"title: {title}\\n\"\n",
    "                    f\"content: {content}\"\n",
    "                )\n",
    "                parts.append(block)\n",
    "        return \"\\n\\n\".join(parts)\n",
    "    \n",
    "    client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "    formatted_results = format_search_results_for_agent(\n",
    "        client.search(\n",
    "            query=query,\n",
    "            max_results=2,\n",
    "            time_range=time_range,\n",
    "            include_domains=include_domains\n",
    "        )\n",
    "    )\n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Setup and Context\n",
    "\n",
    "OpenAI Agents support persistent conversation history through sessions. We'll create a session and context to track our conversation and validation results.\n",
    "\n",
    "**Note:** For Cleanlab integration, you can use any pre-defined Context class, just make sure to pass in `session_id` if you want conversations to be tracked in the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from agents.memory.sqlite_session import SQLiteSession\n",
    "\n",
    "@dataclass\n",
    "class ExampleContext:\n",
    "    session_id: str | None  # Add this for session tracking in Cleanlab UI\n",
    "    environment: str = \"development\"\n",
    "\n",
    "# Create session for conversation history\n",
    "session = SQLiteSession(session_id=\"cleanlab_loan_support_demo\")\n",
    "\n",
    "# Create your context with session info\n",
    "example_context = ExampleContext(\n",
    "    session_id=session.session_id,  # Get from your session\n",
    "    environment=\"production\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Agents Integration\n",
    "\n",
    "To add response validation to your OpenAI agent, we add a Cleanlab hook that intercepts LLM responses, validates them in real-time, and can replace bad responses with fallbacks or expert answers where appropriate.\n",
    "\n",
    "**Integration steps:**\n",
    "1. Create your Agent (optionally Session, Context, ...)\n",
    "2. Create the validation hook with CleanlabHook\n",
    "3. Use the hook when running the agent with `Runner.run()` like so:\n",
    "\n",
    "```python\n",
    "    result = await Runner.run(\n",
    "        starting_agent=agent,\n",
    "        input=query,\n",
    "        hooks=cleanlab_hook,\n",
    "        session=session,\n",
    "        context=example_context\n",
    "    )\n",
    "```\n",
    "\n",
    "#### Context-Aware Validation for Information Retrieval\n",
    "\n",
    "For agents with tools that retrieve information (e.g., RAG, web search, database queries), Cleanlab can use this retrieved content as **context** during validation. This enables more accurate evaluation by:\n",
    "\n",
    "- Checking if the AI response is grounded in the retrieved information\n",
    "- Measuring context sufficiency (whether enough information was retrieved)\n",
    "- Detecting hallucinations by comparing the response against actual context\n",
    "\n",
    "To enable this, specify the names of your context-providing tools in the `context_retrieval_tools` parameter during hook initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a customer service agent for bank loans. Be polite and concise in your responses. Always rely on the tool answers.\"\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"BankLoanSupport\",\n",
    "    instructions=SYSTEM_PROMPT,\n",
    "    tools=[get_payment_schedule, get_total_amount_owed, web_search],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### New code to add for Cleanlab API ###\n",
    "from cleanlab_codex.experimental.openai_agents.cleanlab_hook import CleanlabHook\n",
    "\n",
    "FALLBACK_RESPONSE = \"Sorry I am unsure. You can try rephrasing your request.\"\n",
    "\n",
    "cleanlab_hook = CleanlabHook(\n",
    "    cleanlab_project=project,\n",
    "    fallback_response=FALLBACK_RESPONSE,\n",
    "    skip_validating_tool_calls=True,\n",
    "    context_retrieval_tools=[\"get_payment_schedule\", \"get_total_amount_owed\", \"web_search\"],  # Specify tool(s) that provide context\n",
    "    validate_every_response=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1: Conversational Chat Response\n",
    "\n",
    "Let's start with a basic agent interaction without tools. \n",
    "\n",
    "The Cleanlab hook validates the response in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b53c291-8079-43b9-bfd5-cc7ba350a6bb",
   "metadata": {},
   "source": [
    "**Optional: Helper method to run the agent and print Cleanlab validation results**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_openai_validation_results(final_output, initial_llm_response, validation_result, query):\n",
    "    \"\"\"Helper function to display OpenAI Agent validation results with consistent formatting\"\"\"\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Response Delivered to User:\")\n",
    "    print(\"-\" * 30)  \n",
    "    print() \n",
    "    print(final_output)\n",
    "    print()\n",
    "    print()\n",
    "    print(\"=== Internal Trace (not shown to user) ===\")\n",
    "    print()\n",
    "    \n",
    "    if validation_result:\n",
    "        # Group core detection metrics\n",
    "        should_guardrail = validation_result.should_guardrail\n",
    "        escalated_to_sme = validation_result.escalated_to_sme\n",
    "        is_bad_response = validation_result.is_bad_response\n",
    "        expert_answer_available = bool(validation_result.expert_answer)\n",
    "\n",
    "        print(\"-\" * 30)\n",
    "        if should_guardrail or expert_answer_available:\n",
    "            print(f\"Original AI Response (not delivered to user):\")\n",
    "            print(\"-\" * 30)\n",
    "            print()\n",
    "            print(initial_llm_response)\n",
    "            print()\n",
    "        else:\n",
    "            print(f\"Original AI Response:\")\n",
    "            print(\"-\" * 30)  \n",
    "            print()\n",
    "            print(\"[Same as \\\"Response Delivered to User\\\"]\")\n",
    "            print()\n",
    "        \n",
    "        print(\"-\" * 30) \n",
    "        print(\"Cleanlab Analysis:\")\n",
    "        print(\"-\" * 30)\n",
    "        print()\n",
    "        \n",
    "        print(f\"Should Guardrail: {should_guardrail}\")\n",
    "        print(f\"Escalated to SME: {escalated_to_sme}\")\n",
    "        print(f\"Is Bad Response: {is_bad_response}\")\n",
    "        print(f\"Expert Answer Available: {expert_answer_available}\")\n",
    "        \n",
    "        # Show evaluation scores if available\n",
    "        if getattr(validation_result, 'eval_scores', None) is not None:\n",
    "            eval_scores = validation_result.eval_scores\n",
    "            print()\n",
    "\n",
    "            # Access trustworthiness score\n",
    "            if 'trustworthiness' in eval_scores:\n",
    "                trust_score = eval_scores['trustworthiness'].score\n",
    "                print(f\"Trustworthiness: {trust_score:.3f} (triggered_guardrail = {eval_scores['trustworthiness'].triggered_guardrail})\")\n",
    "\n",
    "            # Access response helpfulness score\n",
    "            if 'response_helpfulness' in eval_scores:\n",
    "                help_score = eval_scores['response_helpfulness'].score\n",
    "                print(f\"Response Helpfulness: {help_score:.3f} (triggered_guardrail = {eval_scores['response_helpfulness'].triggered_guardrail})\")\n",
    "\n",
    "            # Access context sufficiency score (for retrieval scenarios)\n",
    "            if 'context_sufficiency' in eval_scores:\n",
    "                context_score = eval_scores['context_sufficiency'].score\n",
    "                print(f\"Context Sufficiency: {context_score:.3f} (triggered_guardrail = {eval_scores['context_sufficiency'].triggered_guardrail})\")\n",
    "\n",
    "        # Show expert answer if available\n",
    "        if expert_answer_available:\n",
    "            print()\n",
    "            print(\"-\" * 30)\n",
    "            print(\"Expert Answer Available:\")\n",
    "            print(\"-\" * 30)\n",
    "            print()\n",
    "            print(validation_result.expert_answer)\n",
    "            print()\n",
    "        \n",
    "        # Show validation status summary\n",
    "        if should_guardrail or is_bad_response or expert_answer_available:\n",
    "            print()\n",
    "            if expert_answer_available:\n",
    "                print(\"\ud83d\udca1 EXPERT ANSWER AVAILABLE: Expert answer was available and delivered to user instead of Original AI Response\")\n",
    "            elif should_guardrail:\n",
    "                print(\"\u26a0\ufe0f GUARDRAIL TRIGGERED: Original AI Response was blocked and a fallback response was delivered to user\")\n",
    "            if escalated_to_sme and (not expert_answer_available) and (not should_guardrail):\n",
    "                print(\"\ud83d\udd04 ESCALATED: This case was flagged as problematic for subject matter expert review in the Cleanlab Project Interface\")\n",
    "        else:\n",
    "            print()\n",
    "            print(\"\u2705 VALIDATION PASSED: Original AI Response delivered to user\")\n",
    "    \n",
    "    else:\n",
    "        print(\"No validation results available\")\n",
    "\n",
    "def print_last_n_messages(message_history, n=3):\n",
    "    \"\"\"Pretty print the last n messages from the conversation history\"\"\"\n",
    "    for msg in message_history[-n:]:\n",
    "        type = msg.get('type', 'unknown')\n",
    "        role = msg.get('role', type)\n",
    "        arguments = msg.get('arguments', '')\n",
    "        output = msg.get('output', arguments)\n",
    "        content = str(msg.get('content', '')[0].get('text', ''))[:100] + \"...\" if len(str(msg.get('content', ''))) > 100 else str(msg.get('content', output))\n",
    "        print(f\"- {role}: {content}\")\n",
    "\n",
    "async def run_with_validation(query: str):\n",
    "    \"\"\"Run agent and display formatted validation results\"\"\"\n",
    "    result = await Runner.run(\n",
    "        starting_agent=agent,\n",
    "        input=query,\n",
    "        hooks=cleanlab_hook,\n",
    "        session=session,\n",
    "        context=example_context\n",
    "    )\n",
    "    \n",
    "    validation_result = getattr(example_context, 'latest_cleanlab_validation_result', None)\n",
    "    initial_llm_response = getattr(example_context, 'latest_initial_response_text', None)\n",
    "    display_openai_validation_results(result.final_output, initial_llm_response, validation_result, query)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Response Delivered to User:\n",
      "------------------------------\n",
      "\n",
      "A credit score is a numerical representation of your creditworthiness, typically ranging from 300 to 850. It is based on your credit history and helps lenders determine the likelihood that you will repay borrowed money. Factors that influence your credit score include payment history, amounts owed, length of credit history, new credit, and types of credit used. A higher score generally indicates better creditworthiness, which can lead to better loan terms and interest rates.\n",
      "\n",
      "\n",
      "=== Internal Trace (not shown to user) ===\n",
      "\n",
      "------------------------------\n",
      "Original AI Response:\n",
      "------------------------------\n",
      "\n",
      "[Same as \"Response Delivered to User\"]\n",
      "\n",
      "------------------------------\n",
      "Cleanlab Analysis:\n",
      "------------------------------\n",
      "\n",
      "Should Guardrail: False\n",
      "Escalated to SME: False\n",
      "Is Bad Response: False\n",
      "Expert Answer Available: False\n",
      "\n",
      "Trustworthiness: 0.937 (triggered_guardrail = False)\n",
      "Response Helpfulness: 0.998 (triggered_guardrail = False)\n",
      "\n",
      "\u2705 VALIDATION PASSED: Original AI Response delivered to user\n"
     ]
    }
   ],
   "source": [
    "run_result = await run_with_validation(\"What is a credit score?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without Cleanlab:** The agent would deliver its response directly to the user without any validation or safety checks.\n",
    "\n",
    "**With Cleanlab:** The above response is automatically validated for trustworthiness and helpfulness before reaching the user. In this case, Cleanlab found the response trustworthy, so it allowed the original response to be delivered to the user.\n",
    "\n",
    "## Scenario 2: Tool Call Response\n",
    "\n",
    "Now let's test an agent interaction that uses tools. Cleanlab validation checks both tool usage and the final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Response Delivered to User:\n",
      "------------------------------\n",
      "\n",
      "The payment schedule for account ID 12345 is as follows:\n",
      "\n",
      "- **Payment Plan:** Bi-weekly\n",
      "- **Next Payment:** Scheduled for next Friday. \n",
      "\n",
      "If you have any other questions, feel free to ask!\n",
      "\n",
      "\n",
      "=== Internal Trace (not shown to user) ===\n",
      "\n",
      "------------------------------\n",
      "Original AI Response:\n",
      "------------------------------\n",
      "\n",
      "[Same as \"Response Delivered to User\"]\n",
      "\n",
      "------------------------------\n",
      "Cleanlab Analysis:\n",
      "------------------------------\n",
      "\n",
      "Should Guardrail: False\n",
      "Escalated to SME: False\n",
      "Is Bad Response: False\n",
      "Expert Answer Available: False\n",
      "\n",
      "Trustworthiness: 1.000 (triggered_guardrail = False)\n",
      "Response Helpfulness: 0.997 (triggered_guardrail = False)\n",
      "\n",
      "\u2705 VALIDATION PASSED: Original AI Response delivered to user\n"
     ]
    }
   ],
   "source": [
    "run_result = await run_with_validation(\"What is the payment schedule for account ID 12345?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without Cleanlab:** The agent would deliver its tool-based response directly to the user without validation.\n",
    "\n",
    "**With Cleanlab:** The response is validated even when tools are used. Cleanlab evaluated both the which tools are called and the final response, found them highly trustworthy,  and delivered the original response to the user.\n",
    "\n",
    "After this interaction, we can see the tool calls and response show up in the message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation now has 6 messages\n",
      "\n",
      "Last 4 messages:\n",
      "- user: What is the payment schedule for account ID 12345?\n",
      "- function_call: {\"account_id\":\"12345\"}\n",
      "- function_call_output: Account 12345 has: \n",
      "        Bi-weekly payment plan\n",
      "        Upcoming payment scheduled for next Friday\n",
      "    \n",
      "- assistant: The payment schedule for account ID 12345 is as follows:\n",
      "\n",
      "- **Payment Plan:** Bi-weekly\n",
      "- **Next Pay...\n"
     ]
    }
   ],
   "source": [
    "# Show conversation history\n",
    "message_history = await session.get_items()\n",
    "print(f\"\\nConversation now has {len(message_history)} messages\")\n",
    "print(\"\\nLast 4 messages:\")\n",
    "print_last_n_messages(message_history, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3: Bad AI Response\n",
    "\n",
    "When an Agent calls an incorrect tool or summarizes problematic information returned from the tool call, Cleanlab automatically:\n",
    "\n",
    "1. **Detects** the problematic response with a low trustworthiness score\n",
    "2. **Blocks** it from reaching the user \n",
    "3. **Substitutes** a safe fallback response\n",
    "4. **Logs** the interaction for expert review\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Response Delivered to User:\n",
      "------------------------------\n",
      "\n",
      "Sorry I am unsure. You can try rephrasing your request.\n",
      "\n",
      "\n",
      "=== Internal Trace (not shown to user) ===\n",
      "\n",
      "------------------------------\n",
      "Original AI Response (not delivered to user):\n",
      "------------------------------\n",
      "\n",
      "You currently owe **$7,000,000,000,000,000,000,000,000,000,000,000,000** on your loan for account ID 12345. If you have any further questions or need assistance, please let me know!\n",
      "\n",
      "------------------------------\n",
      "Cleanlab Analysis:\n",
      "------------------------------\n",
      "\n",
      "Should Guardrail: True\n",
      "Escalated to SME: True\n",
      "Is Bad Response: True\n",
      "Expert Answer Available: False\n",
      "\n",
      "Trustworthiness: 0.076 (triggered_guardrail = True)\n",
      "Response Helpfulness: 0.918 (triggered_guardrail = False)\n",
      "\n",
      "\u26a0\ufe0f GUARDRAIL TRIGGERED: Original AI Response was blocked and a fallback response was delivered to user\n"
     ]
    }
   ],
   "source": [
    "run_result = await run_with_validation(\"How much do I owe on my loan for account ID 12345?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without Cleanlab:** The user would receive the problematic response: \"The total amount owed on your loan for account ID 12345 is $7,000,000,000,000,000,000,000,000,000,000,000,000,000...\" - clearly an unrealistic and harmful amount that could confuse or alarm the user.\n",
    "\n",
    "**With Cleanlab:** Cleanlab's validation detects the unrealistic amount, assigns a very low trustworthiness score, blocks the problematic response, and instead delivers a configurable fallback response to the user.\n",
    "\n",
    "After this interaction, we can see the conversation history is updated with the safe fallback response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation now has 10 messages\n",
      "\n",
      "Lastest message:\n",
      "- user: How much do I owe on my loan for account ID 12345?\n",
      "- function_call: {\"account_id\":\"12345\"}\n",
      "- function_call_output: {'account_id': '12345', 'currency': 'USD', 'total': 7e+36}\n",
      "- assistant: Sorry I am unsure. You can try rephrasing your request....\n"
     ]
    }
   ],
   "source": [
    "# Show updated conversation history\n",
    "message_history = await session.get_items()\n",
    "print(f\"\\nConversation now has {len(message_history)} messages\")\n",
    "print(\"\\nLastest message:\")\n",
    "print_last_n_messages(message_history, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 4: Expert Answer Response\n",
    "\n",
    "After setting up the project in Cleanlab UI, you can add expert answer to common queries that could be deterministically returned to the user instead of the Agent response.\n",
    "\n",
    "Consider the following user query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Response Delivered to User:\n",
      "------------------------------\n",
      "\n",
      "Sorry I am unsure. You can try rephrasing your request.\n",
      "\n",
      "\n",
      "=== Internal Trace (not shown to user) ===\n",
      "\n",
      "------------------------------\n",
      "Original AI Response (not delivered to user):\n",
      "------------------------------\n",
      "\n",
      "To add a payee to your Mortgage lender loan, follow these general steps:\n",
      "\n",
      "1. **Log Into Your Account:**\n",
      "   - Visit your Mortgage lender's website and log into your account using your credentials.\n",
      "\n",
      "2. **Navigate to Payment Options:**\n",
      "   - Look for a section labeled \"Payments\" or \"Manage Payees.\"\n",
      "\n",
      "3. **Select \"Add Payee\":**\n",
      "   - Click on the option to add a new payee or manage payees.\n",
      "\n",
      "4. **Enter Payee Information:**\n",
      "   - Input the required details for the new payee, such as name, address, and payment details.\n",
      "\n",
      "5. **Verify Information:**\n",
      "   - Review the information you've entered to ensure it's accurate.\n",
      "\n",
      "6. **Save Changes:**\n",
      "   - Click the \"Save\" or \"Add Payee\" button to finalize the addition.\n",
      "\n",
      "7. **Confirmation:**\n",
      "   - You may receive a confirmation message or email indicating that the payee has been successfully added.\n",
      "\n",
      "If you encounter any issues or need specific guidance for your lender, it's best to contact their customer service directly.\n",
      "\n",
      "------------------------------\n",
      "Cleanlab Analysis:\n",
      "------------------------------\n",
      "\n",
      "Should Guardrail: True\n",
      "Escalated to SME: True\n",
      "Is Bad Response: True\n",
      "Expert Answer Available: False\n",
      "\n",
      "Trustworthiness: 0.213 (triggered_guardrail = True)\n",
      "Response Helpfulness: 0.997 (triggered_guardrail = False)\n",
      "\n",
      "\u26a0\ufe0f GUARDRAIL TRIGGERED: Original AI Response was blocked and a fallback response was delivered to user\n"
     ]
    }
   ],
   "source": [
    "run_result = await run_with_validation(\"How do I add a payee to my Mortgagelender loan? Give me specific steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we did not give our Agent specific context on how to do this action, the steps outlined in the Original LLM Response are *hallucinated*. \n",
    "\n",
    "As expected, the Trustworthiness score is low and the query, answer pair is marked as an *Issue* in the Web UI. \n",
    "\n",
    "Consider adding an expert answer for the Question above on the proper steps like:\n",
    "\n",
    "```text\n",
    "1. Open the Mortgagelender site or app and sign into your profile.\n",
    "2. Go to the section where you handle billing or transfer details.\n",
    "3. Look for an option to set up a new recipient for payments.\n",
    "4. Fill in the recipient\u2019s required details (name, account info, etc.).\n",
    "5. Confirm the details and complete the setup.\n",
    "6. Wait for a notice or email confirming the payee has been linked.\n",
    "```\n",
    "\n",
    "Now, when we re-run the same exact query the expert answer will be used, immediately improving the accuracy of the Agent responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Response Delivered to User:\n",
      "------------------------------\n",
      "\n",
      "1\\. Open the Mortgagelender site or app and sign into your profile.\n",
      "\n",
      "2\\. Go to the section where you handle billing or transfer details.\n",
      "\n",
      "3\\. Look for an option to set up a new recipient for payments.\n",
      "\n",
      "4\\. Fill in the recipient\u2019s required details (name, account info, etc.).\n",
      "\n",
      "5\\. Confirm the details and complete the setup.\n",
      "\n",
      "6\\. Wait for a notice or email confirming the payee has been linked.\n",
      "\n",
      "\n",
      "=== Internal Trace (not shown to user) ===\n",
      "\n",
      "------------------------------\n",
      "Original AI Response (not delivered to user):\n",
      "------------------------------\n",
      "\n",
      "While I don't have specific instructions for adding a payee to a Mortgagelender loan, typically the process involves the following steps:\n",
      "\n",
      "1. **Log in to Your Account:** Visit the Mortgagelender website and log into your account.\n",
      "\n",
      "2. **Navigate to Payments:** Look for a section related to payments or payees.\n",
      "\n",
      "3. **Add Payee:** There should be an option to add a new payee or manage payees. Click on it.\n",
      "\n",
      "4. **Input Payee Information:** Enter the required details for the new payee, such as name, address, and account number.\n",
      "\n",
      "5. **Save Changes:** Review the information and save the changes.\n",
      "\n",
      "6. **Confirm Addition:** You may receive a confirmation that the payee has been successfully added.\n",
      "\n",
      "For specific instructions, please refer to Mortgagelender\u2019s customer support or help section on their website. If you need any more assistance, feel free to ask!\n",
      "\n",
      "------------------------------\n",
      "Cleanlab Analysis:\n",
      "------------------------------\n",
      "\n",
      "Should Guardrail: True\n",
      "Escalated to SME: True\n",
      "Is Bad Response: True\n",
      "Expert Answer Available: True\n",
      "\n",
      "Trustworthiness: 0.366 (triggered_guardrail = True)\n",
      "Response Helpfulness: 0.995 (triggered_guardrail = False)\n",
      "\n",
      "------------------------------\n",
      "Expert Answer Available:\n",
      "------------------------------\n",
      "\n",
      "1\\. Open the Mortgagelender site or app and sign into your profile.\n",
      "\n",
      "2\\. Go to the section where you handle billing or transfer details.\n",
      "\n",
      "3\\. Look for an option to set up a new recipient for payments.\n",
      "\n",
      "4\\. Fill in the recipient\u2019s required details (name, account info, etc.).\n",
      "\n",
      "5\\. Confirm the details and complete the setup.\n",
      "\n",
      "6\\. Wait for a notice or email confirming the payee has been linked.\n",
      "\n",
      "\n",
      "\ud83d\udca1 EXPERT ANSWER AVAILABLE: Expert answer was available and delivered to user instead of Original AI Response\n"
     ]
    }
   ],
   "source": [
    "run_result = await run_with_validation(\"How do I add a payee to my Mortgagelender loan? Give me specific steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without Cleanlab:** The agent would deliver potentially inaccurate step-by-step instructions for adding a payee, which could mislead users or waste their time with incorrect procedures.\n",
    "\n",
    "**With Cleanlab:** When no expert answer exists, problematic responses are blocked with fallback messages. When expert answers are available they deterministically replace the agent's potentially inaccurate response. This incorrect case is tracked and escalated to SMEs.\n",
    "\n",
    "## Scenario 5: Information Retrieval Tool Call Response\n",
    "\n",
    "Now let's ask a question that requires our Agent to use web search, which we specified in our `context_retrieval_tools` list. \n",
    "\n",
    "To flag answers based on their provided context, go into your Project UI \"Evaluations\" section, click on the `search_failure` Eval edit button and toggle the \"should escalate\" or \"should guardrail\" sections on the bottom.\n",
    "\n",
    "**What happens with context-aware validation:**\n",
    "- Tool results are automatically passed to Cleanlab as context\n",
    "- Cleanlab can evaluate whether the AI response is grounded in the retrieved information\n",
    "- You'll see a \"Retrieved Context\" section in the Cleanlab Project UI showing what information was available for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Response Delivered to User:\n",
      "------------------------------\n",
      "\n",
      "As of today, the current average mortgage interest rates are:\n",
      "\n",
      "- **30-Year Fixed Mortgage Rate:** 6.43%\n",
      "\n",
      "Rates can fluctuate, so it's always a good idea to check regularly or consult with your lender for the most accurate information. If you have any more questions, feel free to ask!\n",
      "\n",
      "\n",
      "=== Internal Trace (not shown to user) ===\n",
      "\n",
      "------------------------------\n",
      "Original AI Response:\n",
      "------------------------------\n",
      "\n",
      "[Same as \"Response Delivered to User\"]\n",
      "\n",
      "------------------------------\n",
      "Cleanlab Analysis:\n",
      "------------------------------\n",
      "\n",
      "Should Guardrail: False\n",
      "Escalated to SME: False\n",
      "Is Bad Response: False\n",
      "Expert Answer Available: False\n",
      "\n",
      "Trustworthiness: 0.953 (triggered_guardrail = False)\n",
      "Response Helpfulness: 0.997 (triggered_guardrail = False)\n",
      "\n",
      "\u2705 VALIDATION PASSED: Original AI Response delivered to user\n"
     ]
    }
   ],
   "source": [
    "run_result = await run_with_validation(\"What are current mortgage interest rates?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context is now automatically extracted from web search tool result and passed to Cleanlab validation, improving evaluation accuracy for information retrieval scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final conversation has 18 messages\n",
      "\n",
      "Last 3 messages (showing web search interaction):\n",
      "- function_call: {\"query\":\"current mortgage interest rates\",\"time_range\":\"w\",\"include_domains\":null}\n",
      "- function_call_output: Context 1:\n",
      "title: Mortgage Rates\n",
      "content: Following several weeks of decline,mortgage rates inched up this week. Housing market activity continues to hold up with purchase and refinance applications\n",
      "\n",
      "Context 2:\n",
      "title: Compare current mortgage rates for today\n",
      "content: For today, Tuesday, September 30, 2025, thecurrent average 30-year fixed mortgage interest rate is 6.43%. If you're looking to refinance your current mortgage\n",
      "- assistant: As of today, the current average mortgage interest rates are:\n",
      "\n",
      "- **30-Year Fixed Mortgage Rate:** 6....\n"
     ]
    }
   ],
   "source": [
    "# Show the last few messages to see web search tool call and context\n",
    "message_history = await session.get_items()\n",
    "print(f\"\\nFinal conversation has {len(message_history)} messages\")\n",
    "print(\"\\nLast 3 messages (showing web search interaction):\")\n",
    "print_last_n_messages(message_history, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Cleanlab Validation Works\n",
    "\n",
    "Cleanlab evaluates AI responses across multiple dimensions (trustworthiness, helpfulness, reasoning quality, etc.) and provides scores, guardrail decisions, and expert remediation.\n",
    "\n",
    "For detailed information on Cleanlab's validation methodology, see:\n",
    "- [Cleanlab Validation Overview](/codex/tutorials/other_rag_frameworks/validator/)\n",
    "- [Understanding Evaluation Metrics](/codex/tutorials/other_rag_frameworks/validator_conversational/#evaluation-metrics)\n",
    "- [Configuring Validation Thresholds](/codex/web_tutorials/create_project/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated integrating Cleanlab validation with OpenAI Agents using validation hooks. \n",
    "\n",
    "### Key benefits:\n",
    "\n",
    "- **Real-time validation** during response generation\n",
    "- **Automatic remediation** with expert answers and fallbacks\n",
    "- **Context-aware validation** for retrieval-based agents\n",
    "- **Session management** for persistent conversation history\n",
    "- **Minimal code changes** to existing OpenAI Agent applications\n",
    "\n",
    "### Integration is simple:\n",
    "\n",
    "1. Create a `CleanlabHook` with your project\n",
    "2. Specify `context_retrieval_tools` for better validation\n",
    "3. Pass the hook to `Runner.run()` along with session and context\n",
    "4. Access validation results from the context object\n",
    "\n",
    "The hook-based approach provides enterprise-grade safety with minimal code changes to your existing OpenAI Agent workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codex (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}