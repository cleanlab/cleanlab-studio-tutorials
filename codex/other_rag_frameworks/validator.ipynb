{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect and remediate bad responses from any RAG system with Cleanlab\n",
    "\n",
    "\n",
    "This tutorial demonstrates how to automatically improve any RAG application by integrating Codex as-a-backup.  For each user query, simply provide the retrieved context and generated response from your RAG app.  Cleanlab will automatically detect if the response is bad (unhelpful/untrustworthy), and if so: provide an alternative response whenever a similar query has been answered in the connected Codex Project, or otherwise log this query into the Codex Project for SMEs to answer.\n",
    "\n",
    "!['Codex as a backup'](../assets/codexasbackup.png)\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "Here's all the code needed for using Codex as-a-backup with your RAG system.\n",
    "\n",
    "```python\n",
    "from cleanlab_codex import Validator\n",
    "validator = Validator(codex_access_key=...) # optional configurations can improve accuracy/latency\n",
    "\n",
    "# Your existing RAG code:\n",
    "context = rag_retrieve_context(user_query)\n",
    "prompt = rag_form_prompt(user_query, retrieved_context)\n",
    "response = rag_generate_response(prompt)\n",
    "\n",
    "# Detect bad responses and remediate with Cleanlab\n",
    "results = validator.validate(query=query, context=context, response=response, \n",
    "    form_prompt=rag_form_prompt)\n",
    "\n",
    "final_response = (\n",
    "    results[\"expert_answer\"] # Codex's answer\n",
    "    if results[\"is_bad_response\"] and results[\"expert_answer\"]\n",
    "    else response # Your RAG system's initial response\n",
    ")\n",
    "```\n",
    "\n",
    "## Setup\n",
    "\n",
    "This tutorial requires a TLM API key. Get one [here](https://tlm.cleanlab.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade cleanlab-codex pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your TLM API key\n",
    "import os\n",
    "os.environ[\"CLEANLAB_TLM_API_KEY\"] = \"<API key>\" # Get your free API key from: https://tlm.cleanlab.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from cleanlab_codex.validator import Validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example RAG App: Product Customer Support\n",
    "\n",
    "Consider a customer support / e-commerce RAG use-case where the Knowledge Base contains product listings like the following:\n",
    "\n",
    "![Simple water bottle product listing](../assets/simple_water_bottle.png)\n",
    "\n",
    "Here, the inner workings of the RAG app are not important for this tutorial. What is important is that the RAG app generates a response based on a user query and a context, which are all made available for evaluation.\n",
    "\n",
    "\n",
    "For simplicity, our context is hardcoded as the product listing below. You should replace these with the outputs of your RAG system, noting that Cleanlab can detect issues in these outputs in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_listing = \"\"\"Simple Water Bottle - Amber (limited edition launched Jan 1st 2025)\n",
    "A water bottle designed with a perfect blend of functionality and aesthetics in mind. Crafted from high-quality, durable plastic with a sleek honey-colored finish.\n",
    "Price: $24.99\n",
    "Dimensions: 10 inches height x 4 inches width\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How much water can the Simple Water Bottle hold?</td>\n",
       "      <td>Simple Water Bottle - Amber (limited edition l...</td>\n",
       "      <td>The Simple Water Bottle can hold 16 oz of Water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I order the Simple Water Bottle in bulk?</td>\n",
       "      <td>Simple Water Bottle - Amber (limited edition l...</td>\n",
       "      <td>Based on the available information, I cannot p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How much does the Simple Water Bottle cost?</td>\n",
       "      <td>Simple Water Bottle - Amber (limited edition l...</td>\n",
       "      <td>The Simple Water Bottle costs $24.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              query  \\\n",
       "0  How much water can the Simple Water Bottle hold?   \n",
       "1  How can I order the Simple Water Bottle in bulk?   \n",
       "2       How much does the Simple Water Bottle cost?   \n",
       "\n",
       "                                             context  \\\n",
       "0  Simple Water Bottle - Amber (limited edition l...   \n",
       "1  Simple Water Bottle - Amber (limited edition l...   \n",
       "2  Simple Water Bottle - Amber (limited edition l...   \n",
       "\n",
       "                                            response  \n",
       "0    The Simple Water Bottle can hold 16 oz of Water  \n",
       "1  Based on the available information, I cannot p...  \n",
       "2               The Simple Water Bottle costs $24.99  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example queries and retrieved context + generated response from RAG system\n",
    "data = [\n",
    "    {\n",
    "        \"query\": \"How much water can the Simple Water Bottle hold?\",\n",
    "        \"context\": product_listing,\n",
    "        \"response\": \"The Simple Water Bottle can hold 16 oz of Water\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How can I order the Simple Water Bottle in bulk?\",\n",
    "        \"context\": product_listing,\n",
    "        \"response\": \"Based on the available information, I cannot provide a complete answer to this question.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How much does the Simple Water Bottle cost?\",\n",
    "        \"context\": product_listing,\n",
    "        \"response\": \"The Simple Water Bottle costs $24.99\"\n",
    "    },\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, your RAG system should already have functions to retrieve context and generate responses. For this tutorial, we'll simulate these functions using the above fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541aa1e7-8af5-4c44-821a-c8bda971ec17",
   "metadata": {},
   "source": [
    "**Optional: Toy RAG methods you should replace with existing methods from your RAG system**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_retrieve_context(query):\n",
    "    \"\"\"Simulate retrieval from a knowledge base\"\"\"\n",
    "    # In a real system, this would search the knowledge base\n",
    "    for item in data:\n",
    "        if item[\"query\"] == query:\n",
    "            return item[\"context\"]\n",
    "    return \"\"\n",
    "\n",
    "def rag_form_prompt(query, context):\n",
    "    \"\"\"Format a prompt for the RAG system\"\"\"\n",
    "    return f\"\"\"You are a customer service agent. Your task is to answer the following customer questions based on the product listing.\n",
    "\n",
    "Product Listing: {context}\n",
    "Customer Question: {query}\n",
    "\"\"\"\n",
    "\n",
    "def rag_generate_response(prompt):\n",
    "    \"\"\"Simulate LLM response generation\"\"\"\n",
    "    # In a real system, this would call an LLM\n",
    "    query = prompt.split(\"Customer Question: \")[1].split(\"\\n\")[0]\n",
    "    for item in data:\n",
    "        if item[\"query\"] == query:\n",
    "            return item[\"response\"]\n",
    "    \n",
    "    # Return a fallback response if the LLM is unable to answer the question\n",
    "    return \"Based on the available information, I cannot provide a complete answer to this question.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Codex Project\n",
    "\n",
    "To later use Codex, we must first [create a Project](/codex/web_tutorials/create_project/).\n",
    "Here we assume some (question, answer) pairs have already been added to the Codex Project.\n",
    "To learn how that was done, see our tutorial: [Populating Codex](/codex/web_tutorials/populating_codex/).\n",
    "\n",
    "Our existing Codex Project contains the following entries:\n",
    "\n",
    "![Codex Project Example](../assets/codex_kb.png)\n",
    "\n",
    "User queries where Codex detected a bad response from your RAG app will be logged in this Project for SMEs to later answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Programmatically populate the Codex Project with above (question, answer) pairs. Note: The recommended flow is to do this manually in the Web App.\n",
    "from cleanlab_codex.client import Client\n",
    "\n",
    "os.environ[\"CODEX_API_KEY\"] = \"<YOUR-KEY-HERE>\"  # Replace with your Codex API key\n",
    "codex_client = Client()\n",
    "\n",
    "# Create a project\n",
    "project = codex_client.create_project(\n",
    "    name=\"Product FAQs\",\n",
    "    description=\"Questions about product pages\",\n",
    ")\n",
    "\n",
    "# Add entries to the project\n",
    "project.add_entries(\n",
    "    entries=[\n",
    "        {\"question\": \"How much water can the Simple Water Bottle hold?\", \"answer\": \"32oz\"},\n",
    "        {\"question\": \"Can I return my Simple Water Bottle?\", \"answer\": \"Return it within 30 days for a full refund-- no questions asked. Contact our support team to initiate your return!\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "access_key = project.create_access_key(\"test access key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running detection and remediation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our Codex Project is configured, we can initialize a Validator object. This Validator uses the `validate()` method to detect bad responses in our RAG applications by running Evals, scoring responses, and flagging them as bad when they fall below certain thresholds.\n",
    "When a response is flagged as bad, the Validator will query Codex for an expert answer that can remediate the bad response. If no suitable answer is found, the Validator will log the query into the Codex Project for SMEs to answer.\n",
    "\n",
    "Let's initialize the Validator using our access key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = \"<YOUR-PROJECT-ACCESS-KEY>\"  # Obtain from your Project's settings page: https://codex.cleanlab.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = Validator(codex_access_key=access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying this Validator to a RAG system is straightfoward. Here we do this using a helper function that applies the Validator to one row from our example dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_row_validation(df, row_index, validator, verbosity=0):\n",
    "    \"\"\"\n",
    "    Detect and remediate bad responses in a specific row from the dataframe\n",
    "    \n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The dataframe containing the query, context, and response to validate.\n",
    "        row_index (int): The index of the row in the dataframe to validate.\n",
    "        validator (Validator): The Validator object to use for detection and remediation of bad responses.\n",
    "        verbosity (int): Whether to print verbose output. Defaults to 0.\n",
    "            At verbosity level 0, only the query and final response are printed.\n",
    "            At verbosity level 1, the initial RAG response and the validation results are printed as well.\n",
    "            At verbosity level 2, the retrieved context is also printed.\n",
    "    \"\"\"\n",
    "    # 1. Get user query\n",
    "    user_query = df.iloc[row_index][\"query\"]\n",
    "    print(f\"Query: {user_query}\\n\")\n",
    "    \n",
    "    # 2. Standard RAG pipeline\n",
    "    retrieved_context = rag_retrieve_context(user_query)\n",
    "    if verbosity >= 2:\n",
    "        print(f\"Retrieved context:\\n{retrieved_context}\\n\")\n",
    "    \n",
    "    # Format the RAG prompt\n",
    "    rag_prompt = rag_form_prompt(user_query, retrieved_context)\n",
    "    initial_response = rag_generate_response(rag_prompt)\n",
    "    if verbosity >= 1:\n",
    "        print(f\"Initial RAG response: {initial_response}\\n\")\n",
    "\n",
    "    # 3. Detect and remediate bad responses\n",
    "    results = validator.validate(\n",
    "        query=user_query,\n",
    "        context=retrieved_context,\n",
    "        response=initial_response,\n",
    "        form_prompt=rag_form_prompt,\n",
    "    )\n",
    "    \n",
    "    # Use expert answer if available and response was flagged as bad\n",
    "    final_response = (\n",
    "        results[\"expert_answer\"] \n",
    "        if results[\"is_bad_response\"] and results[\"expert_answer\"]\n",
    "        else initial_response\n",
    "    )\n",
    "    print(f\"Final Response: {final_response}\\n\")\n",
    "    \n",
    "    # For tutorial purposes, show validation results\n",
    "    if verbosity >= 1:\n",
    "        print(\"Validation Results:\")\n",
    "        for key, value in results.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's validate the RAG response to our first example query. The final dictionary printed by our helper functions are the results of `Validator.validate()`, which we'll break down below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How much water can the Simple Water Bottle hold?\n",
      "\n",
      "Initial RAG response: The Simple Water Bottle can hold 16 oz of Water\n",
      "\n",
      "Final Response: 32oz\n",
      "\n",
      "Validation Results:\n",
      "    expert_answer: 32oz\n",
      "    is_bad_response: True\n",
      "    trustworthiness: {'log': {'explanation': \"This response is untrustworthy due to lack of consistency in possible responses from the model. Here's one inconsistent alternate response that the model considered (which may not be accurate either): \\nThank you for your question! Unfortunately, the product listing does not specify the water capacity of the Simple Water Bottle. If you\u2019re looking for a water bottle suitable for daily hydration, it typically holds around 16-20 ounces, but I recommend checking the product specifications or contacting the manufacturer for detailed information. Let me know if there's anything else I can assist you with!\"}, 'score': 0.48383545940159745, 'is_bad': True}\n",
      "    response_helpfulness: {'score': 0.9975122945166285, 'is_bad': False}\n"
     ]
    }
   ],
   "source": [
    "df_row_validation(df, 0, validator, verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Validator.validate()` method returns a comprehensive dictionary containing multiple evaluation metrics and remediation options. Let's examine the key components of these results:\n",
    "\n",
    "### Core Validation Results\n",
    "\n",
    "1. **`expert_answer` (String | None)**\n",
    "   - Contains the remediation response retrieved from the Codex Project.\n",
    "   - Returns `None` in two scenarios:\n",
    "     - When `is_bad_response` is `False` (indicating no remediation needed, so Codex is not queried).\n",
    "     - When no suitable expert answer exists in the Codex Project for similar queries.\n",
    "   - Returns a string containing the expert-provided answer when:\n",
    "     - The response is flagged as requiring remediation (`is_bad_response=True`).\n",
    "     - A semantically similar query exists in the Codex Project with an expert answer.\n",
    "\n",
    "2. **`is_bad_response` (Boolean)**\n",
    "   - This is the primary validation indicator that determines if a response requires remediation (i.e. for `expert_answer` to contain a string value).\n",
    "   - Will be `True` when any evaluation metric falls below its configured threshold.\n",
    "   - Controls whether the system will attempt to fetch an expert answer from Codex. Only when `is_bad_response=True` will the system lookup an expert answer from Codex (which logs the corresponding query into the Codex Project).\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "The Validator extends [TrustworthyRAG's evaluation scores](/tlm/api/python/utils.rag/#class-trustworthyragscore) by adding an `is_bad` boolean flag to each metric. This flag indicates whether the metric's score falls below its configured threshold, which determines if a response needs remediation.\n",
    "\n",
    "By default, the Validator uses the following metrics:\n",
    "- `trustworthiness`: overall confidence that your RAG system's response is correct\n",
    "- `response_helpfulness`: evaluates whether the response effectively addresses the user query and appears helpful.\n",
    "\n",
    "You can modify these metrics by providing a custom list of `evals` in the `trustworthy_rag_config` dictionary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's validate another example from our RAG system.  For this example, the response is flagged as bad, but no expert answer is available in the Codex Project. The corresponding query will be logged there for SMEs to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How can I order the Simple Water Bottle in bulk?\n",
      "\n",
      "Initial RAG response: Based on the available information, I cannot provide a complete answer to this question.\n",
      "\n",
      "Final Response: Based on the available information, I cannot provide a complete answer to this question.\n",
      "\n",
      "Validation Results:\n",
      "    expert_answer: None\n",
      "    is_bad_response: True\n",
      "    trustworthiness: {'log': {'explanation': 'The prompt/response appear atypical or vague.'}, 'score': 0.4924309760346324, 'is_bad': True}\n",
      "    response_helpfulness: {'score': 0.0024875641966603293, 'is_bad': True}\n"
     ]
    }
   ],
   "source": [
    "df_row_validation(df, 1, validator, verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RAG system is unable to answer this question because there is no relevant information in the retrieved context, nor has a similar question been answered in the Codex Project (see the contents of the Codex Project above).\n",
    "\n",
    "**Codex automatically recognizes this question could not be answered and logs it into the Project where it awaits an answer from a SME.**\n",
    "Navigate to your Codex Project in the [Web App](https://codex.cleanlab.ai/) where you (or a SME at your company) can enter the desired answer for this query.\n",
    "\n",
    "As soon as an answer is provided in Codex, our RAG system will be able to answer all similar questions going forward (as seen for the previous query)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "\n",
    "You can configure many aspects of the bad response detection like what score thresholds to use and [TrustworthyRAG](/tlm/use-cases/tlm_rag/) settings.\n",
    "\n",
    "### Response Quality Thresholds\n",
    "\n",
    "Thresholds determine when a response needs intervention:\n",
    "- Each metric (trustworthiness, helpfulness, etc.) has its own threshold (0-1)\n",
    "- If any metric's score falls below its threshold, the response is marked as \"bad\"\n",
    "- Example: With trustworthiness_threshold = 0.85\n",
    "  - Score 0.80 -> Marked as bad (below threshold)\n",
    "  - Score 0.90 -> Passes validation (above threshold)\n",
    "\n",
    "Setting thresholds affects your validation strategy:\n",
    "- Higher thresholds (e.g. 0.9) = Stricter validation\n",
    "  - More responses marked as \"bad\"\n",
    "  - More queries logged for SMEs to answer\n",
    "  - Better response quality but higher SME workload\n",
    "   \n",
    "- Lower thresholds (e.g. 0.7) = More lenient validation\n",
    "  - Fewer responses marked as \"bad\"\n",
    "  - Fewer queries logged for SMEs to answer\n",
    "  - Lower SME workload, but may allow lower quality responses from your RAG app to be returned unremediated.\n",
    "\n",
    "Learn more about the thresholds in the [BadResponseThresholds documentation](\n",
    "\n",
    "### Additional Configuration\n",
    "\n",
    "The Validator combines powerful detection capabilities with automatic remediation of bad responses. For detection, you can customize the evaluation process using the `trustworthy_rag_config` dictionary parameter.\n",
    "\n",
    "The Validator supports all configuration options available in [TrustworthyRAG](/tlm/use-cases/tlm_rag/) for the detection of bad responses. You can refer to the TrustworthyRAG documentation for the complete list of supported options that can be passed in this dictionary.\n",
    "\n",
    "The following example shows how to configure the Validator with custom thresholds and evaluation settings:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae7416c-ce34-4a0d-b449-1a0d07361c16",
   "metadata": {},
   "source": [
    "**Optional: Configure custom Evals**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab_tlm.utils.rag import Eval, get_default_evals\n",
    "\n",
    "# Select the \"resonse_helpfulness\" Eval\n",
    "evals = [evaluation for evaluation in get_default_evals() if evaluation.name == \"response_helpfulness\"]\n",
    "\n",
    "evals.append(\n",
    "    Eval(\n",
    "        name=\"self_containedness\",\n",
    "        criteria=\"\"\"Assess whether the AI Assistant Response provides a self-contained, standalone information that would be clear to someone who hasn't seen the User Query or Context.\n",
    "\n",
    "        A good response should:\n",
    "        - Include relevant subjects and context from the User Query (and Context if necessary)\n",
    "        - Avoid pronouns (like \"it\", \"he\", \"she\") without clear antecedents\n",
    "        - Be understandable on its own without requiring the original User Query (and Context if necessary) for reference\n",
    "\n",
    "        For example:\n",
    "        - \"27\" is less self-contained than \"I am 27 years old\"\n",
    "        - \"Yes\" is less self-contained than \"Yes, the store is open on Sundays\"\n",
    "        - \"$50\" is less self-contained than \"The product costs $50\"\n",
    "        - \"He is\" is less self-contained than \"He is a good person\", which itself is less self-contained than \"John is a good person\"\n",
    "        \n",
    "        A self-contained, complete AI Assistant Response would be considered good when the AI Assistant doesn't require the Context for reference when asked the same User Query again.\n",
    "        \"\"\",\n",
    "        query_identifier=\"User Query\",\n",
    "        context_identifier=\"Context\",\n",
    "        response_identifier=\"AI Assistant Response\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = Validator(\n",
    "    codex_access_key=access_key,\n",
    "    tlm_api_key=os.environ[\"CLEANLAB_TLM_API_KEY\"],\n",
    "    bad_response_thresholds={\n",
    "        \"trustworthiness\": 0.85,\n",
    "        \"response_helpfulness\": 0.9,\n",
    "        \"self_containedness\": 0.75,\n",
    "    },\n",
    "    trustworthy_rag_config={\n",
    "        \"quality_preset\": \"base\",\n",
    "        \"options\": {\n",
    "            \"model\": \"gpt-4o-mini\", \n",
    "            \"log\": [\"explanation\"],\n",
    "        },\n",
    "        \"evals\": evals,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's validate another example from our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How much does the Simple Water Bottle cost?\n",
      "\n",
      "Initial RAG response: The Simple Water Bottle costs $24.99\n",
      "\n",
      "Final Response: The Simple Water Bottle costs $24.99\n",
      "\n",
      "Validation Results:\n",
      "    expert_answer: None\n",
      "    is_bad_response: False\n",
      "    trustworthiness: {'log': {'explanation': 'Did not find a reason to doubt trustworthiness.'}, 'score': 1.0, 'is_bad': False}\n",
      "    response_helpfulness: {'score': 0.9975124087312727, 'is_bad': False}\n",
      "    self_containedness: {'score': 0.995846566624026, 'is_bad': False}\n"
     ]
    }
   ],
   "source": [
    "df_row_validation(df, 2, validator, verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection-Only Mode\n",
    "\n",
    "While `Validator.validate()` provides a complete solution to detect, log, and fix bad responses, you might want to detect RAG issues without logging/remediation or other side-effects.\n",
    "\n",
    "`Validator.detect()` runs the same detection as the `validate()` method, but without affecting the Codex Project at all.\n",
    "`detect()` returns nearly the same results dict as `validate()`, only the `expert_answer` key is missing (the Codex Project is ignored).\n",
    "\n",
    "Use `Validator.detect()` to test/tune detection configurations like score thresholds and [TrustworthyRAG](/tlm/use-cases/tlm_rag/) settings.\n",
    "`Validator.detect()` will not affect your Codex Project, whereas `Validator.validate()` will log queries whose response was detected as bad into the Codex Project and is thus for production use, not testing.\n",
    "Both methods run the same detection logic, so you can use `detect()` to first optimize detections and then switch to using `validate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_row_detection(df, row_index, validator, verbosity=0):\n",
    "    \"\"\"\n",
    "    Detect bad responses in a specific row from the dataframe\n",
    "    \n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The dataframe containing the query, context, and response to validate.\n",
    "        row_index (int): The index of the row in the dataframe to validate.\n",
    "        validator (Validator): The Validator object to use for detection of bad responses.\n",
    "        verbosity (int): Whether to print verbose output. Defaults to 0.\n",
    "            At verbosity level 0, only the query and final response are printed, along with the detection results.\n",
    "            At verbosity level 1, the retrieved context is also printed.\n",
    "    \"\"\"\n",
    "    # 1. Get user query\n",
    "    user_query = df.iloc[row_index][\"query\"]\n",
    "    print(f\"Query: {user_query}\\n\")\n",
    "    \n",
    "    # 2. Standard RAG pipeline\n",
    "    retrieved_context = rag_retrieve_context(user_query)\n",
    "    if verbosity >= 1:\n",
    "        print(f\"Retrieved context:\\n{retrieved_context}\\n\")\n",
    "    \n",
    "    # Format the RAG prompt\n",
    "    rag_prompt = rag_form_prompt(user_query, retrieved_context)\n",
    "    initial_response = rag_generate_response(rag_prompt)\n",
    "    print(f\"Initial RAG response: {initial_response}\\n\")\n",
    "    \n",
    "    # 3. Detect bad responses\n",
    "    scores, is_bad_response = validator.detect(\n",
    "        query=user_query,\n",
    "        context=retrieved_context,\n",
    "        response=initial_response,\n",
    "        form_prompt=rag_form_prompt,\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Validation Results:\")\n",
    "    for key, value in scores.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "    print(f\"\\n    is_bad_response: {is_bad_response}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take another look at the previous example from our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How much does the Simple Water Bottle cost?\n",
      "\n",
      "Initial RAG response: The Simple Water Bottle costs $24.99\n",
      "\n",
      "Validation Results:\n",
      "    trustworthiness: {'log': {'explanation': 'Did not find a reason to doubt trustworthiness.'}, 'score': 1.0, 'is_bad': False}\n",
      "    response_helpfulness: {'score': 0.9975124087312727, 'is_bad': False}\n",
      "    self_containedness: {'score': 0.9917940685074799, 'is_bad': False}\n",
      "\n",
      "    is_bad_response: False\n"
     ]
    }
   ],
   "source": [
    "df_row_detection(df, 2, validator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that Cleanlab is integrated with your RAG app, you and SMEs can [open the Codex Project and answer questions](/codex/web_tutorials/codex_as_sme/) logged there to continuously improve your AI.\n",
    "\n",
    "This tutorial demonstrated how to use Cleanlab to automatically detect and remediate bad responses in any RAG application. Cleanlab provides a robust way to evaluate response quality and automatically fetch expert answers when needed. For responses that don't meet quality thresholds, Codex automatically logs the queries for SME review.\n",
    "\n",
    "**Adding Cleanlab only improves your RAG app.** Once integrated, it automatically identifies problematic responses and either remediates them with expert answers or logs them for review. Using a [simple web interface](/codex/web_tutorials/codex_as_sme/), SMEs at your company can answer the highest priority questions in the Codex Project. As soon as an answer is entered in Codex, your RAG app will be able to properly handle all similar questions encountered in the future.\n",
    "\n",
    "Codex is **the fastest way for nontechnical SMEs to directly improve your RAG system**. As the Developer, you simply integrate Cleanlab once, and from then on, SMEs can continuously improve how your system handles common user queries without needing your help.\n",
    "\n",
    "Need help, more capabilities, or other deployment options?  \n",
    "Check the [FAQ](/codex/FAQ/) or email us at: support@cleanlab.ai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}