{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf38a9d7",
   "metadata": {},
   "source": [
    "# Detect and remediate bad responses from Tool Calling AI applications\n",
    "\n",
    "This notebok demonstrates how to automatically improve any Tool Calling AI application by integrating Cleanlab. \n",
    "Cleanlab will automatically detect if your AI response is bad (e.g. untrustworthy, unhelpful, or unsafe), returning real-time scores you can use to guardrail your AI and prevent wrong responses or tool calls. \n",
    "\n",
    "!['Cleanlab AI Platform'](../assets/codexasbackup.png)\n",
    "\n",
    "**Note:** While this tutorial uses OpenAI as an example Tool Calling AI Agent, Cleanlab works with *any* AI Agent and Tool Calling framework (simply translate your Agent outputs into OpenAI format as necessary).\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook shows how Cleanlab can detect and prevent wrong Tool Calls or bad AI responses from happening, and also serve expert answers in scenarios where your AI previously responded incorrectly or output a wrong Tool Call.\n",
    "\n",
    "## Setup\n",
    "\n",
    "This tutorial requires a Cleanlab API key. Get one [here](https://codex.cleanlab.ai/account)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0533299",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade cleanlab-codex pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Codex API key\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<API key>\"  # Get your free API key from: https://platform.openai.com/account/api-keys\n",
    "os.environ[\"CODEX_API_KEY\"] = \"<API key>\" # Get your free API key from: https://codex.cleanlab.ai/account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afb0cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from cleanlab_codex import Project\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import uuid\n",
    "from openai.types.chat import ChatCompletion, ChatCompletionMessage\n",
    "import json\n",
    "from cleanlab_tlm.utils.chat import form_response_string_chat_completions_api\n",
    "import pandas as pd\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a249a3c",
   "metadata": {},
   "source": [
    "## Example AI App: Bank Loan Customer Support\n",
    "\n",
    "As an example use-case, let's consider customer support AI for bank loans where the underlying Knowledge Base contains information on loans like the following:\n",
    "\n",
    "```bash\n",
    "**Knowledge Base Article: Application Review Process**\n",
    "\n",
    "- Once a customer submits their application, it enters the **Review Stage**.  \n",
    "- **Review Stage Timeline:** Typically 3\u20135 business days.  \n",
    "- **What Happens During Review:**  \n",
    "  - Verification of identity and personal details  \n",
    "  - Credit report evaluation  \n",
    "  - Fraud checks and risk assessment  \n",
    "```\n",
    "\n",
    "The details of this AI app are not important for this tutorial. What is important is that this RAG app generates a *response* based on a set of provided *tools*, *user query*, a retrieved *context*, and a prior *conversation history*, which are all made available for evaluation.\n",
    "\n",
    "For simplicity, our context and tool responses are hardcoded below. You should replace these with the outputs of your AI system, noting that Cleanlab can detect issues in these outputs in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34a1e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "CONTEXT = \"Knowledge Base Article: Application Review Process\\nOnce a customer submits their application, it enters the Review Stage.\\nReview Stage Timeline: Typically 3\u20135 business days.\\nWhat Happens During Review:\\n- Verification of identity and personal details\\n- Credit report evaluation\\n- Fraud checks and risk assessment\"\n",
    "\n",
    "def get_application_status():\n",
    "    \"\"\"A tool that simulates fetching the application status for a customer.\n",
    "    **Note:** This tool returns a hardcoded *realistic* application status for demonstration purposes.\"\"\"\n",
    "    return {\n",
    "        \"status\": \"RATE_ACCEPTED\",\n",
    "        \"bank_accounts\": [\n",
    "            {\"is_verified\": True, \"added_via\": \"PLAID\"}\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "def get_payment_schedule():\n",
    "    \"\"\"A tool that simulates fetching a payment schedule for a customer.\n",
    "    **Note:** This tool returns a hardcoded *unrealistic* payment schedule for demonstration purposes.\"\"\"\n",
    "    return {\n",
    "        \"currency\": \"USD\",\n",
    "        \"payments\": [\n",
    "            {\n",
    "                \"due_date\": str(date.today() + timedelta(days=30)),\n",
    "                \"amount_due\": 350000000000000.00,\n",
    "                \"status\": \"UPCOMING\"\n",
    "            },\n",
    "            {\n",
    "                \"due_date\": str(date.today() + timedelta(days=60)),\n",
    "                \"amount_due\": 350000000000000.00,\n",
    "                \"status\": \"UPCOMING\"\n",
    "            }\n",
    "        ],\n",
    "        \"next_payment_due\": str(date.today() + timedelta(days=30))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd63028",
   "metadata": {},
   "source": [
    "In practice, your AI system should already have functions to process tool calls, retrieve context, generate responses, and build a messages object to prompt the LLM with. \n",
    "\n",
    "For this tutorial, we'll simulate these functions using the above fields as well as define a simple `fallback_response`, `system_prompt`, and `prompt_template`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adb943b-97b3-4613-b5be-1bcb0fa7466a",
   "metadata": {},
   "source": [
    "**Optional: Toy methods you should replace with existing methods from your AI system**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c36e0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "SYSTEM_PROMPT = \"You are a customer service agent. Be polite and concise in your responses.\"\n",
    "FALLBACK_RESPONSE = \"I'm sorry, but I need to direct you to our customer service team for assistance with this inquiry. Please reach out to example_lenders@money.com for help.\"\n",
    "PROMPT_TEMPLATE = \"\"\"Answer the following customer question.\n",
    "\n",
    "Customer Question: {question}\n",
    "\"\"\"\n",
    "CONVERSATION_HISTORY = []\n",
    "\n",
    "mock_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_application_status\",\n",
    "            \"description\": \"Returns the current loan application status.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": []\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_payment_schedule\",\n",
    "            \"description\": \"Retrieves the upcoming payment schedule for the active loan application.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "#### AI helper methods\n",
    "\n",
    "def rag_form_prompt(conversation_history, user_query=None, context=None):\n",
    "    \"\"\"Form a prompt for your LLM response-generation step (from the user query, retrieved context, conversation history, system instructions, etc). We represent the `prompt` in OpenAI's `messages` format, which matches the input to Cleanlab's `validate()` method.\n",
    "    \n",
    "    **Note:** In `messages`, it is recommended to inject retrieved context into the system prompt rather than each user message.\n",
    "    \"\"\"\n",
    "\n",
    "    system_message = f\"System message: {SYSTEM_PROMPT}\\n\\nContext: {context}\\n\\n\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        *conversation_history,  # Include previous messages\n",
    "    ]\n",
    "    if user_query:\n",
    "        user_message = PROMPT_TEMPLATE.format(context=context, question=user_query)\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    return messages\n",
    "\n",
    "def rag_retreive_context(query):\n",
    "    \"\"\"Retrieve relevant context for the given query. In practice, this would involve querying a vector database or similar system.\"\"\"\n",
    "    # For this tutorial, we return the hardcoded context\n",
    "    return CONTEXT\n",
    "\n",
    "#### Tool calling helper methods\n",
    "mock_tool_registry = {\n",
    "    \"get_application_status\": get_application_status,\n",
    "    \"get_payment_schedule\": get_payment_schedule,\n",
    "}\n",
    "\n",
    "def mock_tool_handler(tool_name, arguments):\n",
    "    if tool_name in mock_tool_registry:\n",
    "        return json.dumps(mock_tool_registry[tool_name]())\n",
    "    return json.dumps({\"error\": \"Unknown tool\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71d098a-30f8-49b6-8d3c-217eb26be4a1",
   "metadata": {},
   "source": [
    "**Optional: Cleanlab helper methods for validation and managing conversation history**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d2583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_response_with_cleanlab(results, initial_response: ChatCompletion, FALLBACK_RESPONSE: str) -> ChatCompletion:\n",
    "    \"\"\"\n",
    "    Extracts the final response from the initial response and validation results using the following logic:\n",
    "    \n",
    "    - If the expert answer is provided and the query was escalated to an SME, return that.\n",
    "    - If a guardrail was triggered, return the fallback response.\n",
    "    - Otherwise, return the initial response from your own AI system.\n",
    "\n",
    "    Returns response in ChatCompletion as the initial response.\n",
    "    \"\"\"\n",
    "    \n",
    "    def make_cleanlab_response_into_minimal_chatcompletion(\n",
    "        content: str,\n",
    "    ) -> ChatCompletion:\n",
    "        \"\"\"\n",
    "        Create the smallest valid ChatCompletion object per schema with content.\n",
    "        \n",
    "        Args:\n",
    "            content: The text to set as the message content.\n",
    "\n",
    "        Returns:\n",
    "            ChatCompletion: Minimal valid ChatCompletion object.\n",
    "        \"\"\"\n",
    "        return ChatCompletion(\n",
    "            id=f\"chatcmpl-{uuid.uuid4().hex[:8]}\",\n",
    "            object=\"chat.completion\",\n",
    "            created=int(time.time()),\n",
    "            model=\"cleanlab\",\n",
    "            choices=[\n",
    "                {\n",
    "                    \"index\": 0,\n",
    "                    \"finish_reason\": \"stop\",\n",
    "                    \"message\": ChatCompletionMessage(\n",
    "                        role=\"assistant\",\n",
    "                        content=content,\n",
    "                    ),\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    if results.expert_answer and results.escalated_to_sme:\n",
    "        return make_cleanlab_response_into_minimal_chatcompletion(\n",
    "            results.expert_answer\n",
    "        )\n",
    "    elif results.should_guardrail:\n",
    "        return make_cleanlab_response_into_minimal_chatcompletion(\n",
    "            FALLBACK_RESPONSE\n",
    "        )\n",
    "    else:\n",
    "        return initial_response\n",
    "\n",
    "from openai.types.chat import ChatCompletionMessage\n",
    "\n",
    "def clean_conversation_history(conversation):\n",
    "    \"\"\"Removes bad tool calls in the current chat turn if final assistant has no tool calls.\"\"\"\n",
    "    \n",
    "    if len(conversation) == 0:\n",
    "        return conversation\n",
    "    \n",
    "    # Find start of current turn (last user message)\n",
    "    start_index = next(\n",
    "        i for i in range(len(conversation) - 1, -1, -1)\n",
    "        if (isinstance(conversation[i], ChatCompletionMessage) and conversation[i].role == \"user\") or (isinstance(conversation[i], dict) and conversation[i].get(\"role\") == \"user\")\n",
    "    )\n",
    "    chat_turn = conversation[start_index:]\n",
    "    final_assistant = chat_turn[-1]\n",
    "    \n",
    "    # Remove tool calls if final assistant has no tool_calls\n",
    "    if getattr(final_assistant, \"tool_calls\", None) is None:\n",
    "        skip_tool_ids = {tc.id for m in chat_turn if getattr(m, \"tool_calls\", None)\n",
    "                         for tc in getattr(m, \"tool_calls\", [])}\n",
    "        \n",
    "        # Replace slice in place\n",
    "        conversation[start_index:] = [\n",
    "            m for m in chat_turn if not (\n",
    "                (getattr(m, \"tool_calls\", None) and any(tc.id in skip_tool_ids for tc in m.tool_calls)) or\n",
    "                (isinstance(m, dict) and m.get(\"role\") == \"tool\" and m.get(\"tool_call_id\") in skip_tool_ids)\n",
    "            )\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0867ffcc",
   "metadata": {},
   "source": [
    "## Create Cleanlab Project\n",
    "\n",
    "To later use the Cleanlab AI Platform, we must first [create a Project](/codex/web_tutorials/create_project/).\n",
    "Here we assume no (question, answer) pairs have already been added to the Project yet.\n",
    "\n",
    "User queries where Cleanlab detected a bad response from your AI app will be logged in this Project for SMEs to later answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a28cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab_codex.client import Client\n",
    "\n",
    "codex_client = Client()\n",
    "\n",
    "# Create a project\n",
    "project = codex_client.create_project(\n",
    "    name=\"Mortgage lending AI Chatbot (with tools)\",\n",
    "    description=\"Customer facing chatbot for a mortgage lending company.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b7847",
   "metadata": {},
   "source": [
    "## Run detection and remediation\n",
    "\n",
    "Now that our Project is configured, we can use the `Project.validate()` method to detect bad responses from our AI app for each chat turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbeb54ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "# This is used to show consecutive messages from the same conversation in the Project's UI\n",
    "# but it is not used in the code logic.\n",
    "thread_id = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857e09e",
   "metadata": {},
   "source": [
    "Applying the `Project.validate()` method to any AI app is straightfoward. Here we showcase this with a toy AI app built with OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_with_cleanlab(\n",
    "    user_query: str,\n",
    "    context: str,\n",
    "    conversation_history: list[ChatCompletionMessage],\n",
    "    thread_id: str = None,\n",
    ") -> ChatCompletion:\n",
    "    \"\"\"Validate AI response using Cleanlab's `Project.validate()` method.\n",
    "    \n",
    "    Args:\n",
    "        user_query: The user's question.\n",
    "        context: The context retrieved for the query.\n",
    "        conversation_history: The history of the conversation as a list of ChatCompletionMessage objects.\n",
    "        thread_id: Optional thread ID for the conversation.\n",
    "\n",
    "    Returns:\n",
    "        List[ChatCompletion]: Conversation history after processing the user query and validation.\n",
    "    \"\"\"\n",
    "    conversation_history_turn = deepcopy(conversation_history)\n",
    "    messages = rag_form_prompt(conversation_history_turn, user_query, context)\n",
    "    conversation_history_turn.append({\"role\": \"user\", \"content\": user_query})\n",
    "\n",
    "    print(f'---User Question---\\n{user_query}')\n",
    "    while True:\n",
    "        initial_response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1\",\n",
    "            messages=messages,\n",
    "            tools=mock_tools,\n",
    "        )\n",
    "\n",
    "        ### New code to add for Cleanlab API ###\n",
    "        print(f'---Original LLM Response---\\n{form_response_string_chat_completions_api(initial_response.choices[0].message)}')\n",
    "        validation_result = project.validate(\n",
    "            response=initial_response,\n",
    "            query=user_query,\n",
    "            context=context,\n",
    "            messages=messages,\n",
    "            tools=mock_tools,\n",
    "            metadata={\"thread_id\": thread_id},  # Add thread id to track conversation in Project's UI\n",
    "        )\n",
    "        print(f\"---Cleanlab Validation---\")\n",
    "        print(f\"Escalated to SME: {validation_result.escalated_to_sme}\")\n",
    "        print(f\"Should Guardrail: {validation_result.should_guardrail}\")\n",
    "        print(f\"Expert Answer Available: {bool(validation_result.expert_answer)}\")\n",
    "        \n",
    "        response = get_final_response_with_cleanlab(validation_result, initial_response, FALLBACK_RESPONSE)\n",
    "        print(f'---Final LLM Response (after Cleanlab validation)---\\n{form_response_string_chat_completions_api(response.choices[0].message)}')\n",
    "        ### End of new code to add for Cleanlab API ###\n",
    "        \n",
    "        conversation_history_turn.append(response.choices[0].message)\n",
    "\n",
    "        if not response.choices[0].message.tool_calls:\n",
    "            if response != initial_response:  # If Cleanlab validation stepped in to change the response, remove bad tool calls from history\n",
    "                clean_conversation_history(conversation_history_turn)\n",
    "            break\n",
    "        else:\n",
    "            tools_for_print = []\n",
    "            for tool_call in response.choices[0].message.tool_calls:\n",
    "                args = json.loads(tool_call.function.arguments)\n",
    "                tool_response = mock_tool_handler(\n",
    "                    tool_call.function.name,\n",
    "                    tool_call.function.arguments\n",
    "                )\n",
    "                tool_dict = {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": str(tool_response),\n",
    "                }\n",
    "                conversation_history_turn.append(tool_dict)\n",
    "                tools_for_print.append(tool_dict)\n",
    "            # Update the messages with the new conversation history\n",
    "            print(f'---Tool Responses---\\n{tools_for_print}')\n",
    "            messages = rag_form_prompt(conversation_history_turn, None, None)\n",
    "        print('-'*40)\n",
    "    return conversation_history_turn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9c305a",
   "metadata": {},
   "source": [
    "### Chat Turn 1: \"What's the status of my application?\"\n",
    "\n",
    "This turn requires a single tool call to answer user query\n",
    "\n",
    "**Note:** The `validation_result` object below returned by `Project.validate()` contains all sorts of other useful information. See more details about it [here](https://help.cleanlab.ai/codex/tutorials/other_rag_frameworks/validator_conversational/#evaluation-metrics). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caad83c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---User Question---\n",
      "What's the status of my application?\n",
      "---Original LLM Response---\n",
      "<tool_call>\n",
      "{\n",
      "  \"name\": \"get_application_status\",\n",
      "  \"arguments\": {}\n",
      "}\n",
      "</tool_call>\n",
      "---Cleanlab Validation---\n",
      "Escalated to SME: False\n",
      "Should Guardrail: False\n",
      "Expert Answer Available: False\n",
      "---Final LLM Response (after Cleanlab validation)---\n",
      "<tool_call>\n",
      "{\n",
      "  \"name\": \"get_application_status\",\n",
      "  \"arguments\": {}\n",
      "}\n",
      "</tool_call>\n",
      "---Tool Responses---\n",
      "[{'role': 'tool', 'tool_call_id': 'call_hQeUNGM6CiFX7J7tlscWeUGx', 'content': '{\"status\": \"RATE_ACCEPTED\", \"bank_accounts\": [{\"is_verified\": true, \"added_via\": \"PLAID\"}]}'}]\n",
      "----------------------------------------\n",
      "---Original LLM Response---\n",
      "Your application status is \"Rate Accepted,\" and your bank account has been successfully verified. If you need further details or next steps, please let me know!\n",
      "---Cleanlab Validation---\n",
      "Escalated to SME: False\n",
      "Should Guardrail: False\n",
      "Expert Answer Available: False\n",
      "---Final LLM Response (after Cleanlab validation)---\n",
      "Your application status is \"Rate Accepted,\" and your bank account has been successfully verified. If you need further details or next steps, please let me know!\n"
     ]
    }
   ],
   "source": [
    "user_query1 = \"What's the status of my application?\"\n",
    "context1 = rag_retreive_context(user_query1)\n",
    "CONVERSATION_HISTORY = run_rag_with_cleanlab(\n",
    "    user_query1,\n",
    "    context1,\n",
    "    CONVERSATION_HISTORY,\n",
    "    thread_id=thread_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d311ab7f",
   "metadata": {},
   "source": [
    "### Chat Turn 2: \"what is my payment schedule?\"\n",
    "\n",
    "This turn also requires a single tool call to answer user query, however, the `get_payment_schedule()` tool is intentionally defined to have a *inaccurate or unrealistic* output.\n",
    "\n",
    "Cleanlab's validation software steps in and prevents such an output from being returned to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd6bf2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---User Question---\n",
      "what is my payment schedule?\n",
      "---Original LLM Response---\n",
      "<tool_call>\n",
      "{\n",
      "  \"name\": \"get_payment_schedule\",\n",
      "  \"arguments\": {}\n",
      "}\n",
      "</tool_call>\n",
      "---Cleanlab Validation---\n",
      "Escalated to SME: False\n",
      "Should Guardrail: False\n",
      "Expert Answer Available: False\n",
      "---Final LLM Response (after Cleanlab validation)---\n",
      "<tool_call>\n",
      "{\n",
      "  \"name\": \"get_payment_schedule\",\n",
      "  \"arguments\": {}\n",
      "}\n",
      "</tool_call>\n",
      "---Tool Responses---\n",
      "[{'role': 'tool', 'tool_call_id': 'call_cCb4lfSuBgj2smHfTcGM6AbZ', 'content': '{\"currency\": \"USD\", \"payments\": [{\"due_date\": \"2025-09-13\", \"amount_due\": 350000000000000.0, \"status\": \"UPCOMING\"}, {\"due_date\": \"2025-10-13\", \"amount_due\": 350000000000000.0, \"status\": \"UPCOMING\"}], \"next_payment_due\": \"2025-09-13\"}'}]\n",
      "----------------------------------------\n",
      "---Original LLM Response---\n",
      "Your upcoming payments are as follows:\n",
      "\n",
      "- Next payment due: September 13, 2025, amount: $350,000,000,000,000.00\n",
      "- Following payment due: October 13, 2025, amount: $350,000,000,000,000.00\n",
      "\n",
      "If you need more details or have any questions, please let me know!\n",
      "---Cleanlab Validation---\n",
      "Escalated to SME: True\n",
      "Should Guardrail: True\n",
      "Expert Answer Available: False\n",
      "---Final LLM Response (after Cleanlab validation)---\n",
      "I'm sorry, but I need to direct you to our customer service team for assistance with this inquiry. Please reach out to example_lenders@money.com for help.\n"
     ]
    }
   ],
   "source": [
    "user_query2 = \"what is my payment schedule?\"\n",
    "context2 = rag_retreive_context(user_query2)\n",
    "CONVERSATION_HISTORY = run_rag_with_cleanlab(\n",
    "    user_query2,\n",
    "    context2,\n",
    "    CONVERSATION_HISTORY,\n",
    "    thread_id=thread_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04df37de",
   "metadata": {},
   "source": [
    "### Chat Turn 3: \"how long does it take to review an application?\"\n",
    "\n",
    "This turn does not require any tool calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "528130b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---User Question---\n",
      "how long does it take to review an application?\n",
      "---Original LLM Response---\n",
      "The application review process typically takes 3\u20135 business days after you submit your application.\n",
      "---Cleanlab Validation---\n",
      "Escalated to SME: False\n",
      "Should Guardrail: False\n",
      "Expert Answer Available: False\n",
      "---Final LLM Response (after Cleanlab validation)---\n",
      "The application review process typically takes 3\u20135 business days after you submit your application.\n"
     ]
    }
   ],
   "source": [
    "user_query3 = \"how long does it take to review an application?\"\n",
    "context3 = rag_retreive_context(user_query3)\n",
    "CONVERSATION_HISTORY = run_rag_with_cleanlab(\n",
    "    user_query3,\n",
    "    context3,\n",
    "    CONVERSATION_HISTORY,\n",
    "    thread_id=thread_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1367231b",
   "metadata": {},
   "source": [
    "#### View entire conversation history\n",
    "\n",
    "Notice how the untrustworthy Initial LLM response to the user query \"what is my payment schedule?\" is guardrailed by Cleanlab and the fallback response is safely returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "642b8603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: What's the status of my application?\n",
      "ASSISTANT: <tool_call>\n",
      "{\n",
      "  \"name\": \"get_application_status\",\n",
      "  \"arguments\": {}\n",
      "}\n",
      "</tool_call>\n",
      "TOOL: {\"status\": \"RATE_ACCEPTED\", \"bank_accounts\": [{\"is_verified\": true, \"added_via\": \"PLAID\"}]}\n",
      "ASSISTANT: Your application status is \"Rate Accepted,\" and your bank account has been successfully verified. If you need further details or next steps, please let me know!\n",
      "USER: what is my payment schedule?\n",
      "ASSISTANT: I'm sorry, but I need to direct you to our customer service team for assistance with this inquiry. Please reach out to example_lenders@money.com for help.\n",
      "USER: how long does it take to review an application?\n",
      "ASSISTANT: The application review process typically takes 3\u20135 business days after you submit your application.\n"
     ]
    }
   ],
   "source": [
    "for c in CONVERSATION_HISTORY:\n",
    "    role = c[\"role\"] if isinstance(c, dict) and \"role\" in c else c.role\n",
    "    print(f\"{role.upper()}: {form_response_string_chat_completions_api(c)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a8b278",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that Cleanlab is integrated with your *Tool Calling AI App*, you and SMEs can [open the connected Cleanlab Project and answer questions](/codex/web_tutorials/codex_as_sme/) logged there to continuously improve your AI.\n",
    "\n",
    "This tutorial only demonstrated the basics of using Cleanlab to automatically detect and remediate bad responses from any Tool Calling AI application. Advanced Usage is covered in our [Detect and remediate bad responses from conversational RAG applications](/codex/tutorials/other_rag_frameworks/validator_conversational/) tutorial. We recommend connecting your Tool-Calling AI Agents to a *separate* Cleanlab Project from your Q&A / Chat AI Agents.\n",
    "\n",
    "Cleanlab provides a robust way to evaluate response quality and automatically fetch expert answers when needed. For responses that don't meet quality thresholds, the connected Cleanlab Project automatically logs the queries for SME review.\n",
    "\n",
    "**Adding Cleanlab only improves your Tool Calling AI app.** Once integrated, it automatically identifies problematic responses and either remediates them with expert answers or logs them for review. Using a [simple web interface](/codex/web_tutorials/codex_as_sme/), SMEs at your company can answer the highest priority questions in the Cleanab Project. As soon as an answer is entered in the Project, your AI app will be able to properly handle all similar questions encountered in the future.\n",
    "\n",
    "Need help, more capabilities, or other deployment options?  \n",
    "Check the [FAQ](/codex/FAQ/) or email us at: support@cleanlab.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c01c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}