{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with Tool Calls in smolagents\n",
    "\n",
    "This tutorial demonstrates how to build an [smolagents](https://github.com/huggingface/smolagents) agent that can call tools and answer user questions based on a Knowledge Base of files you provide. By implementing retrieval as a tool that can be called by the Agent, this approach differs from standard RAG where retrieval is typically hardcoded as a step in every user interaction.\n",
    "\n",
    "Building such an AI Agent is a prerequisite for our tutorial: [Integrate Codex as-a-tool with smolagents](/codex/tutorials/smolagents/smolagents_AddingCodexAsTool/), which shows how to greatly improve any existing Agent.\n",
    "\n",
    "The code provided in this notebook is for an Agentic RAG application, with single-turn conversations.\n",
    "\n",
    "![RAG Workflow](../assets/codexastool_retrievalastool_simple.png)\n",
    "\n",
    "\n",
    "Let's first install packages required for this tutorial. Most of these packages are the same as those used in [smolagents' RAG tutorial](https://huggingface.co/docs/smolagents/examples/rag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install smolagents pandas langchain langchain-community rank_bm25 --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install litellm  # Optional dependency of smolagents to use LiteLLM as a gateway to many LLMs, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR-KEY-HERE>\"  # Replace with your OpenAI API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Agent: Product Customer Support\n",
    "\n",
    "Consider a customer support / e-commerce RAG use-case where the Knowledge Base contains product listings like the following:\n",
    "\n",
    "![Simple water bottle product listing](../assets/simple_water_bottle.png)\n",
    "\n",
    "\n",
    "To keep our example minimal, our Agent's Knowledge Base here only contains a single document featuring this one product description. The document is split into smaller chunks to enable more precise retrieval.\n",
    "\n",
    "The processed documents get passed to a `retriever` tool that we define. It uses BM25, a simple but effective text retrieval algorithm, which returns relevant text chunks based on keyword matching when the tool is invoked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd5a29-69d1-4a9b-a9b0-5823c66780ee",
   "metadata": {},
   "source": [
    "**Optional: Define helper methods for Knowledge Base creation and retreival**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from smolagents import Tool\n",
    "\n",
    "\n",
    "source_docs = [\n",
    "    Document(\n",
    "        page_content=\"\"\"Simple Water Bottle - Amber (limited edition launched Jan 1st 2025)\n",
    "        \n",
    "        A water bottle designed with a perfect blend of functionality and aesthetics in mind. \n",
    "        Crafted from high-quality, durable plastic with a sleek honey-colored finish.\n",
    "\n",
    "        Price: $24.99\n",
    "        Dimensions: 10 inches height x 4 inches width\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"bottle.txt\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "docs_processed = text_splitter.split_documents(source_docs)\n",
    "\n",
    "\n",
    "fallback_answer = \"Based on the available information, I cannot provide a complete answer to this question.\"\n",
    "\n",
    "# First, we'll define a retriever tool similar to the one in smolagents' RAG tutorial\n",
    "# (https://huggingface.co/docs/smolagents/examples/rag). The key difference is that we've \n",
    "# enhanced the tool description to give the agent clear instructions about when and how to \n",
    "# use this search capability. This helps the agent make better decisions about tool usage \n",
    "# and handle cases where information isn't found.\n",
    "class RetrieverTool(Tool):\n",
    "    name = \"retriever\"\n",
    "    description = f\"\"\"Uses search to retrieve relevant parts of a knowledge base to answer a query.\n",
    "    Start with the original question for search. If no relevant information is found, prefer alternate tools or state \"{fallback_answer}\".\n",
    "    Avoid making assumptions.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The question to answer. Always use the original question, never rephrase it.\",\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, docs, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.retriever = BM25Retriever.from_documents(\n",
    "            docs, k=10\n",
    "        )\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "    \n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "\n",
    "        docs = self.retriever.invoke(\n",
    "            query,\n",
    "        )\n",
    "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
    "            [\n",
    "                f\"\\n\\n===== Document {str(i)} =====\\n\" + doc.page_content\n",
    "                for i, doc in enumerate(docs)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create agent that supports Tool Calls\n",
    "\n",
    "We instantiate smolagents's `CodeAgent` class, which uses the underlying LLM to formulate tool calls in code format, then parse them and execute them. As this class is optimized for single-turn interactions, we'll focus on those use cases here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example tool: get_todays_date\n",
    "\n",
    "Let's define an example tool `get_todays_date()` that our Agent can rely on. We use the `@tool` decorator from the `smolagents` library to define the tool, ready for use in the Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from smolagents import tool\n",
    "\n",
    "@tool\n",
    "def get_todays_date(date_format: str) -> str:\n",
    "  \"\"\"A tool that returns today's date in the date format requested. Use this tool when knowing today's date is necessary to answer the question, like checking if something is available now or calculating how long until a future or past date.\n",
    "  \n",
    "  Args:\n",
    "      date_format: The date format to return today's date in. Options are: '%Y-%m-%d', '%d', '%m', '%Y'. The default is '%Y-%m-%d'.\n",
    "    \n",
    "  Returns:\n",
    "      str: Today's date in the requested format.\n",
    "  \"\"\"\n",
    "  datetime_str = datetime.now().strftime(date_format)\n",
    "  return datetime_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update our tools with tool call instructions\n",
    "\n",
    "For the best performance with smolagents' coding Agent, **add instructions on when to use the tool into the tool description itself**. The smolagents framework will ensure these instructions are included in the system prompt that governs your LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize AI Agent\n",
    "\n",
    "Let's initialize an LLM with tool-calling capabilities, as well as the retriever tool, then build the agent. We add the `get_todays_date` tool into the Agent as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d0820-c4d0-4d4e-b2a1-e3bef3fcbc33",
   "metadata": {},
   "source": [
    "**Optional: Code to create the AI Agent**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from smolagents import CodeAgent, LiteLLMModel\n",
    "\n",
    "model = LiteLLMModel(\"gpt-4o-mini\") \n",
    "\n",
    "retriever_tool = RetrieverTool(docs_processed)\n",
    "\n",
    "agent = CodeAgent(\n",
    "    tools=[retriever_tool, get_todays_date],\n",
    "    model=model,\n",
    "    verbosity_level=0,  # Suppress internal logging\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG in action\n",
    "Let's ask our Agent common questions from users about the *Simple Water Bottle* in our example.\n",
    "\n",
    "\n",
    "\n",
    "### Scenario 1: RAG Agent can answer the question using its Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The water bottle has a height of 10 inches and a width of 4 inches.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"How big is the water bottle?\"\n",
    "response = agent.run(user_question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Agent was able to provide a good answer because its Knowledge Base contains the necessary information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: RAG Agent can answer the question using other tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the limited edition Amber water bottle has already launched.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Check today's date. Has the limited edition Amber water bottle already launched?\"\n",
    "response = agent.run(user_question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the Agent chose to call our `get_todays_date` tool to obtain information necessary for properly answering the user's query. Note that a proper answer to this question also requires considering information from the Knowledge Base as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3: RAG Agent can't answer the question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the available information, I cannot provide a complete answer to this question.\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Can I return my simple water bottle?\"\n",
    "response = agent.run(user_question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Agent's Knowledge Base does not contain information about the return policy, and the `get_todays_date` tool would not help here either. In this case, the best our Agent can do is to return our fallback response to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Once you have an Agent that can call tools, adding **Codex as a Tool** takes only a few lines of code.\n",
    "Codex enables your AI Agent to answer questions it previously could not (like Scenario 3 above). Learn how via our tutorial: [Integrate Codex-as-a-tool with smolagents](/codex/tutorials/smolagents/smolagents_AddingCodexAsTool/)\n",
    "\n",
    "Need help? Check the [FAQ](/codex/FAQ/) or email us at: support@cleanlab.ai"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}