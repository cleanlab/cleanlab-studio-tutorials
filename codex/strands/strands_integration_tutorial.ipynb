{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Cleanlab with AWS Strands Agents\n",
    "\n",
    "This tutorial demonstrates the easiest way to validate and improve the trustworthiness of AI Agents built with the [Strands SDK](https://github.com/strands-agents/sdk-python). With *minimal* changes to your existing Strands Agent code, you can detect bad responses and automatically remediate them in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The Python packages required for this tutorial can be installed using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade cleanlab-codex strands-agents \"strands-agents[openai]\" tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial requires a Cleanlab API key. Get one [here](https://codex.cleanlab.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CODEX_API_KEY\"] = \"<Cleanlab Codex API key>\"  # Get your API key from: https://codex.cleanlab.ai/\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<OpenAI API key>\"  # for using OpenAI models with Strands\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"<TAVILY API KEY>\"  # for using a web search tool (get your free API key from Tavily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab_codex.client import Client\n",
    "from tavily import TavilyClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of this tutorial\n",
    "\n",
    "This tutorial showcases using Cleanlab's CleanlabModel wrapper to add real-time validation to Strands Agents. \n",
    "\n",
    "We'll demonstrate four key scenarios:\n",
    "\n",
    "1. **Conversational Chat Response** - Basic agent interaction with validation\n",
    "2. **Tool Call Response** - Agent response using tools with validation\n",
    "3. **Bad AI Response** - How Cleanlab prevents problematic responses and cleans message history\n",
    "4. **Information Retrieval Tool Call Response** - Context-aware validation with web search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Use Case: Bank Loan Customer Support\n",
    "\n",
    "We'll build a customer support agent for bank loans to demonstrate validation scenarios.\n",
    "\n",
    "Let's define tools representing different response quality levels:\n",
    "- a *good* tool that returns reasonable information\n",
    "- a *bad* tool that returns problematic information\n",
    "- a web search tool that provides additional *context* to the Agent\n",
    "\n",
    "**Note:** The web search tool follows the example information retrieval function defined in the [Strands Web Search tutorial](https://aws.amazon.com/blogs/machine-learning/build-dynamic-web-research-agents-with-the-strands-agents-sdk-and-tavily/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool definitions for demonstration scenarios\n",
    "from strands.tools.decorator import tool\n",
    "\n",
    "# ============ Good Tool: Returns reasonable information ============\n",
    "@tool\n",
    "def get_payment_schedule(account_id: str) -> str:\n",
    "    \"\"\"Get payment schedule for an account.\"\"\"\n",
    "    payment_schedule = f\"\"\"Account {account_id} has: \n",
    "    - Bi-weekly payment plan\n",
    "    - Upcoming payment scheduled for next Friday\n",
    "    \"\"\"\n",
    "    return payment_schedule\n",
    "\n",
    "# ============ Bad Tool: Returns problematic information ============\n",
    "@tool\n",
    "def get_total_amount_owed(account_id: str) -> dict:\n",
    "    \"\"\"A tool that simulates fetching the total amount owed for a loan.\n",
    "    **Note:** This tool returns a hardcoded *unrealistic* total amount for demonstration purposes.\"\"\"\n",
    "    return {\n",
    "        \"account_id\": account_id,\n",
    "        \"currency\": \"USD\",\n",
    "        \"total\": 7000000000000000000000000000000000000.00,\n",
    "    }\n",
    "\n",
    "# ============ Web Search Tool: Provides context for the Agent ============\n",
    "@tool\n",
    "def web_search(\n",
    "    query: str, time_range: str | None = None, include_domains: str | None = None\n",
    ") -> str:\n",
    "    \"\"\"Perform a web search. Returns the search results as a string, with the title, url, and content of each result ranked by relevance.\n",
    "    Args:\n",
    "        query (str): The search query to be sent for the web search.\n",
    "        time_range (str | None, optional): Limits results to content published within a specific timeframe.\n",
    "            Valid values: 'd' (day - 24h), 'w' (week - 7d), 'm' (month - 30d), 'y' (year - 365d).\n",
    "            Defaults to None.\n",
    "        include_domains (list[str] | None, optional): A list of domains to restrict search results to.\n",
    "            Only results from these domains will be returned. Defaults to None.\n",
    "    Returns:\n",
    "        formatted_results (str): The web search results\n",
    "    \"\"\"\n",
    "    \n",
    "    def format_search_results_for_agent(search_results: list[dict]) -> str:\n",
    "        \"\"\"Format search results into a numbered context string for the agent.\"\"\"\n",
    "        results = search_results[\"results\"]\n",
    "        parts = []\n",
    "        for i, r in enumerate(results, start=1):\n",
    "            title = r.get(\"title\", \"\").strip()\n",
    "            content = r.get(\"content\", \"\").strip()\n",
    "            if title or content:\n",
    "                block = (\n",
    "                    f\"Context {i}:\\n\"\n",
    "                    f\"title: {title}\\n\"\n",
    "                    f\"content: {content}\"\n",
    "                )\n",
    "                parts.append(block)\n",
    "        return \"\\n\\n\".join(parts)\n",
    "    \n",
    "    client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "    formatted_results = format_search_results_for_agent(\n",
    "        client.search(\n",
    "            query=query,\n",
    "            max_results=2,\n",
    "            time_range=time_range,\n",
    "            include_domains=include_domains\n",
    "        )\n",
    "    )\n",
    "    return formatted_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Cleanlab Project\n",
    "\n",
    "To use the Cleanlab AI Platform for validation, we must first [create a Project](/codex/web_tutorials/create_project/).\n",
    "Here we assume no (question, answer) pairs have already been added to the Project yet.\n",
    "\n",
    "User queries where Cleanlab detected a bad response from your AI app will be logged in this Project for SMEs to later answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Cleanlab project\n",
    "client = Client()\n",
    "\n",
    "project = client.create_project(\n",
    "    name=\"Strands Agent with Cleanlab Validation Tutorial\",\n",
    "    description=\"Tutorial demonstrating validation of a Strands Agent with CleanlabModel wrapper\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strands Integration\n",
    "\n",
    "To add validation to your Strands agents, wrap any existing Strands model with a CleanlabModel for real-time validation during Agent execution.\n",
    "\n",
    "Cleanlab's wrapper intercepts responses during generation and validates them in real-time, and provides automatic expert answer substitution and guardrail enforcement.\n",
    "\n",
    "**Integration steps:**\n",
    "1. Wrap your Model with CleanlabModel \n",
    "2. Create your Agent with the wrapped Model\n",
    "3. Call `cleanlab_model.set_agent_reference(agent)` for full functionality\n",
    "\n",
    "#### Context-Aware Validation for Information Retrieval\n",
    "\n",
    "For agents with tools that retrieve information (e.g., RAG, web search, database queries), Cleanlab can use this retrieved content as **context** during validation. This enables more accurate evaluation by:\n",
    "\n",
    "- Checking if the AI response is grounded in the retrieved information\n",
    "- Measuring context sufficiency (whether enough information was retrieved)\n",
    "- Detecting hallucinations by comparing the response against actual context\n",
    "\n",
    "To enable this, specify the names of your context-providing tools in the `context_retrieval_tools` parameter during CleanlabModel initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from strands.agent.agent import Agent\n",
    "from strands.models.openai import OpenAIModel\n",
    "from strands.session.file_session_manager import FileSessionManager\n",
    "\n",
    "from cleanlab_codex.experimental.strands import CleanlabModel\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a customer service agent. Be polite and concise in your responses.\"\n",
    "FALLBACK_RESPONSE = \"Sorry I am unsure. You can try rephrasing your request.\"\n",
    "\n",
    "# Create base model\n",
    "base_model = OpenAIModel(\n",
    "    model_id=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "### New code to add for Cleanlab API ###\n",
    "cleanlab_model = CleanlabModel( # Wrap with Cleanlab validation\n",
    "    underlying_model=base_model,\n",
    "    cleanlab_project=project,\n",
    "    fallback_response=FALLBACK_RESPONSE,\n",
    "    context_retrieval_tools=[\"web_search\", \"get_payment_schedule\", \"get_total_amount_owed\"]  # Specify tool(s) that provide context\n",
    ")\n",
    "### End of new code to add for Cleanlab API ###\n",
    "\n",
    "# Create agent with validated model for normal conversation\n",
    "agent = Agent(\n",
    "    model=cleanlab_model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_payment_schedule, get_total_amount_owed, web_search],\n",
    "    session_manager=FileSessionManager(session_id=uuid.uuid4().hex),  # Persist chat history\n",
    ")\n",
    "\n",
    "### New code to add for Cleanlab API ###\n",
    "cleanlab_model.set_agent_reference(agent)\n",
    "### End of new code to add for Cleanlab API ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 1: Conversational Chat Response\n",
    "\n",
    "Let's start with a basic agent interaction without tools. \n",
    "\n",
    "The CleanlabModel wrapper validates the response in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c659b98c-d50b-42ef-a369-9ac176c15a18",
   "metadata": {},
   "source": [
    "**Optional: Helper method to prompt the agent and print validation results**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run(agent: Agent, query: str):\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(\"Response: \", end=\"\")\n",
    "\n",
    "    # Prompt the agent and get response\n",
    "    result = agent(query)\n",
    "    print()\n",
    "\n",
    "    # Show tool usage metrics\n",
    "    if hasattr(result, 'metrics') and hasattr(result.metrics, 'tool_metrics'):\n",
    "        if len(result.metrics.tool_metrics) > 0:\n",
    "            print(f\"\\n--- Historical Tool Usage ---\")\n",
    "            for tool_name, metrics in result.metrics.tool_metrics.items():\n",
    "                print(f\"Tool '{tool_name}': called {metrics.call_count} time(s), {metrics.success_count} successful\")\n",
    "\n",
    "    # Access validation results\n",
    "    validation_results = agent.state.get('cleanlab_validation_results')\n",
    "    print(f\"\\n--- Cleanlab Validation Results ---\")\n",
    "    print(f\"Should Guardrail: {validation_results.get('should_guardrail', 'N/A')}\")\n",
    "    print(f\"Escalated to SME: {validation_results.get('escalated_to_sme', 'N/A')}\")\n",
    "    print(f\"Expert Answer Available: {bool(validation_results.get('expert_answer'))}\")\n",
    "    print(f\"Is Bad Response: {validation_results.get('is_bad_response', 'N/A')}\")\n",
    "            \n",
    "    # Show eval scores if available\n",
    "    if 'eval_scores' in validation_results:\n",
    "        print(f\"\\n--- Key Evaluation Scores ---\")\n",
    "        eval_scores = validation_results['eval_scores']\n",
    "        if 'trustworthiness' in eval_scores:\n",
    "            trust_score = eval_scores['trustworthiness'].get('score', 'N/A')\n",
    "            print(f\"Trustworthiness: {trust_score}\")\n",
    "        if 'response_helpfulness' in eval_scores:\n",
    "            help_score = eval_scores['response_helpfulness'].get('score', 'N/A')\n",
    "            print(f\"Response Helpfulness: {help_score}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Scenario 1: General Knowledge Prompt Response ===\n",
      "Query: 'What is a credit score?'\n",
      "Response: A credit score is a numerical representation of an individual's creditworthiness, which reflects their ability to repay borrowed money. It typically ranges from 300 to 850, with higher scores indicating better creditworthiness. Credit scores are calculated based on credit history, including payment history, the amount of debt owed, length of credit history, types of credit used, and new credit inquiries. Lenders use credit scores to assess the risk of lending money or extending credit to individuals.\n",
      "\n",
      "--- Cleanlab Validation Results ---\n",
      "Should Guardrail: False\n",
      "Escalated to SME: False\n",
      "Expert Answer Available: False\n",
      "Is Bad Response: False\n",
      "\n",
      "--- Key Evaluation Scores ---\n",
      "Trustworthiness: 0.9847615785344598\n",
      "Response Helpfulness: 0.9975124378110127\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Scenario 1: General Knowledge Prompt Response ===\")\n",
    "run(agent, \"What is a credit score?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 2: Tool Call Response\n",
    "\n",
    "Now let's test an agent interaction that uses tools. Cleanlab validation checks both tool usage and the final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Scenario 2: Tool Call Prompt (Successful) ===\n",
      "Query: 'What is the payment schedule for account ID 12345?'\n",
      "Response: \n",
      "Tool #1: get_payment_schedule\n",
      "The payment schedule for account ID 12345 is as follows:\n",
      "\n",
      "- **Payment Plan:** Bi-weekly\n",
      "- **Next Payment:** Scheduled for next Friday.\n",
      "\n",
      "--- Historical Tool Usage ---\n",
      "Tool 'get_payment_schedule': called 1 time(s), 1 successful\n",
      "\n",
      "--- Cleanlab Validation Results ---\n",
      "Should Guardrail: False\n",
      "Escalated to SME: False\n",
      "Expert Answer Available: False\n",
      "Is Bad Response: False\n",
      "\n",
      "--- Key Evaluation Scores ---\n",
      "Trustworthiness: 0.9997877497484022\n",
      "Response Helpfulness: 0.9974053294473002\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Scenario 2: Tool Call Prompt (Successful) ===\")\n",
    "run(agent, \"What is the payment schedule for account ID 12345?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this interaction, we can see the tool calls and response show up in the message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': [{'text': 'What is a credit score?'}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'text': \"A credit score is a numerical representation of an individual's creditworthiness, which reflects their ability to repay borrowed money. It typically ranges from 300 to 850, with higher scores indicating better creditworthiness. Credit scores are calculated based on credit history, including payment history, the amount of debt owed, length of credit history, types of credit used, and new credit inquiries. Lenders use credit scores to assess the risk of lending money or extending credit to individuals.\"}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'text': 'What is the payment schedule for account ID 12345?'}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'toolUse': {'toolUseId': 'call_DVj7AXteouBjk9SNnyjnziDS',\n",
       "     'name': 'get_payment_schedule',\n",
       "     'input': {'account_id': '12345'}}}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'toolResult': {'toolUseId': 'call_DVj7AXteouBjk9SNnyjnziDS',\n",
       "     'status': 'success',\n",
       "     'content': [{'text': 'Account 12345 has: \\n    - Bi-weekly payment plan\\n    - Upcoming payment scheduled for next Friday\\n    '}]}}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'text': 'The payment schedule for account ID 12345 is as follows:\\n\\n- **Payment Plan:** Bi-weekly\\n- **Next Payment:** Scheduled for next Friday.'}]}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 3: Bad AI Response\n",
    "\n",
    "When an Agent calls an incorrect tool or summarizes problematic information returned from the tool call, Cleanlab automatically:\n",
    "\n",
    "1. **Detects** the problematic response \n",
    "2. **Blocks** it from reaching the user\n",
    "3. **Substitutes** a safe fallback response\n",
    "4. **Cleans** message history to remove problematic tool calls\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Scenario 3: Bad AI Response ===\n",
      "Query: 'How much do I owe on my loan for account ID 12345?'\n",
      "Response: \n",
      "Tool #2: get_total_amount_owed\n",
      "Sorry I am unsure. You can try rephrasing your request.\n",
      "\n",
      "--- Historical Tool Usage ---\n",
      "Tool 'get_payment_schedule': called 1 time(s), 1 successful\n",
      "Tool 'get_total_amount_owed': called 1 time(s), 1 successful\n",
      "\n",
      "--- Cleanlab Validation Results ---\n",
      "Should Guardrail: True\n",
      "Escalated to SME: True\n",
      "Expert Answer Available: False\n",
      "Is Bad Response: True\n",
      "\n",
      "--- Key Evaluation Scores ---\n",
      "Trustworthiness: 0.11115133435531592\n",
      "Response Helpfulness: 0.9516016982255979\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Scenario 3: Bad AI Response ===\")\n",
    "run(agent, \"How much do I owe on my loan for account ID 12345?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this chat turn, we see the message history is updated only with the *user query* and *final agent response*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': [{'text': 'What is a credit score?'}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'text': \"A credit score is a numerical representation of an individual's creditworthiness, which reflects their ability to repay borrowed money. It typically ranges from 300 to 850, with higher scores indicating better creditworthiness. Credit scores are calculated based on credit history, including payment history, the amount of debt owed, length of credit history, types of credit used, and new credit inquiries. Lenders use credit scores to assess the risk of lending money or extending credit to individuals.\"}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'text': 'What is the payment schedule for account ID 12345?'}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'toolUse': {'toolUseId': 'call_DVj7AXteouBjk9SNnyjnziDS',\n",
       "     'name': 'get_payment_schedule',\n",
       "     'input': {'account_id': '12345'}}}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'toolResult': {'toolUseId': 'call_DVj7AXteouBjk9SNnyjnziDS',\n",
       "     'status': 'success',\n",
       "     'content': [{'text': 'Account 12345 has: \\n    - Bi-weekly payment plan\\n    - Upcoming payment scheduled for next Friday\\n    '}]}}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'text': 'The payment schedule for account ID 12345 is as follows:\\n\\n- **Payment Plan:** Bi-weekly\\n- **Next Payment:** Scheduled for next Friday.'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'text': 'How much do I owe on my loan for account ID 12345?'}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'text': 'Sorry I am unsure. You can try rephrasing your request.'}]}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario 4: Information Retrieval Tool Call Response\n",
    "\n",
    "Now let's ask a question that requires our Agent to use web search, which we specified in our `context_retrieval_tools` list.\n",
    "\n",
    "**What happens with context-aware validation:**\n",
    "- Tool results are automatically passed to Cleanlab as context\n",
    "- Cleanlab can evaluate whether the AI response is grounded in the retrieved information, represented with the Context Sufficiency score\n",
    "- You'll see a \"Retrieved Context\" section in the Cleanlab Project UI showing what information was available for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Scenario 4: Information Retrieval Tool Call Response ===\n",
      "Query: 'What is an upcoming event in San Francisco?'\n",
      "Response: \n",
      "Tool #3: web_search\n",
      "Here are some upcoming events in San Francisco:\n",
      "\n",
      "1. **San Francisco Post Member Appreciation Event** - 2025\n",
      "2. **San Francisco Post Annual Holiday Gala** - 2025\n",
      "3. **Shucked** - September 9 \u2013 October 5, 2025, at Curran Theatre\n",
      "4. **Gabby's Dollhouse Live!** - September 21, 2025\n",
      "\n",
      "For more details, you may want to check the official sites or ticketing platforms.\n",
      "\n",
      "--- Historical Tool Usage ---\n",
      "Tool 'get_payment_schedule': called 1 time(s), 1 successful\n",
      "Tool 'get_total_amount_owed': called 1 time(s), 1 successful\n",
      "Tool 'web_search': called 1 time(s), 1 successful\n",
      "\n",
      "--- Cleanlab Validation Results ---\n",
      "Should Guardrail: False\n",
      "Escalated to SME: False\n",
      "Expert Answer Available: False\n",
      "Is Bad Response: False\n",
      "\n",
      "--- Key Evaluation Scores ---\n",
      "Trustworthiness: 0.9365397071921228\n",
      "Response Helpfulness: 0.9975071030420052\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Scenario 4: Information Retrieval Tool Call Response ===\")\n",
    "run(agent, \"What is an upcoming event in San Francisco?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context is now automatically extracted from web search tool result and passed to Cleanlab validation, improving evaluation accuracy for information retrieval scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'assistant',\n",
       "  'content': [{'toolUse': {'toolUseId': 'call_PqeMYxP5Lltzl5TeSvtfrX7O',\n",
       "     'name': 'web_search',\n",
       "     'input': {'query': 'upcoming events in San Francisco',\n",
       "      'time_range': 'w'}}}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'toolResult': {'toolUseId': 'call_PqeMYxP5Lltzl5TeSvtfrX7O',\n",
       "     'status': 'success',\n",
       "     'content': [{'text': \"Context 1:\\ntitle: San Francisco Post Upcoming Events - SAME\\ncontent: San Francisco Post Upcoming Events \u00b7 San Francisco Post Member Appreciation Event (2025) \u00b7 San Francisco Post Annual Holiday Gala (2025). Please join the San\\n\\nContext 2:\\ntitle: BroadwaySF | Official Ticketing Site of Golden Gate, Orpheum, and ...\\ncontent: Upcoming Events ; Shucked \u00b7 September 9\u2013October 5, 2025. Curran Theatre. Buy tickets for Shucked ; Gabby's Dollhouse Live! Presented by Walmart \u00b7 September 21, 2025.\"}]}}]},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'text': \"Here are some upcoming events in San Francisco:\\n\\n1. **San Francisco Post Member Appreciation Event** - 2025\\n2. **San Francisco Post Annual Holiday Gala** - 2025\\n3. **Shucked** - September 9 \u2013 October 5, 2025, at Curran Theatre\\n4. **Gabby's Dollhouse Live!** - September 21, 2025\\n\\nFor more details, you may want to check the official sites or ticketing platforms.\"}]}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.messages[-3:] # Last 3 messages to see web search tool call and context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Cleanlab Validation Works\n",
    "\n",
    "Cleanlab evaluates AI responses across multiple dimensions (trustworthiness, helpfulness, reasoning quality, etc.) and provides scores, guardrail decisions, and expert remediation.\n",
    "\n",
    "For detailed information on Cleanlab's validation methodology, see:\n",
    "- [Cleanlab Validation Overview](/codex/tutorials/other_rag_frameworks/validator/)\n",
    "- [Understanding Evaluation Metrics](/codex/tutorials/other_rag_frameworks/validator_conversational/#evaluation-metrics)\n",
    "- [Configuring Validation Thresholds](/codex/web_tutorials/create_project/)\n",
    "\n",
    "### Message History Management\n",
    "\n",
    "When Cleanlab detects a problematic response that involved tool calls, it performs the following cleanup:\n",
    "\n",
    "1. **Identifies the problematic turn**: Finds the conversation turn that produced the bad response\n",
    "2. **Removes tool calls**: Eliminates the assistant message containing tool calls from history\n",
    "3. **Removes tool results**: Eliminates the corresponding tool result messages from history\n",
    "4. **Preserves user messages**: Keeps user queries to maintain conversation context\n",
    "5. **Adds clean response**: Adds the safe fallback or expert answer to history\n",
    "\n",
    "This prevents the problematic tool information from contaminating future conversation turns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying Context Handling in More Detail\n",
    "\n",
    "If you want more control over how context is passed to Cleanlab, it's recommended to create a custom CleanlabModel subclass and override the `cleanlab_get_validate_fields` method with custom logic to extract context from tool results and include in validation.\n",
    "\n",
    "```python\n",
    "from typing import Any\n",
    "from strands.types.content import Messages\n",
    "from cleanlab_codex.experimental.strands import CleanlabModel\n",
    "from cleanlab_codex.experimental.strands.cleanlab_model import get_latest_user_message_content\n",
    "\n",
    "def custom_get_context_function(messages: Messages) -> str:\n",
    "    # Define your custom context extraction logic here\n",
    "    return \"your context extraction logic\"\n",
    "\n",
    "class CleanlabModelWithContext(CleanlabModel):\n",
    "    def __init__(self, **init_args) -> None:\n",
    "        super().__init__(**init_args)\n",
    "    \n",
    "    def cleanlab_get_validate_fields(self, messages: Messages) -> dict[str, Any]:\n",
    "        \"\"\"Extract fields from messages for cleanlab validation (overridden to also return context).\"\"\"\n",
    "        user_message_content = get_latest_user_message_content(messages)\n",
    "        context = custom_get_context_function(messages)  # User defined function to extract context\n",
    "        return {\n",
    "            \"query\": user_message_content,\n",
    "            \"context\": context,\n",
    "        }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's different if I'm using Amazon Bedrock models with Strands?\n",
    "\n",
    "The CleanlabModel wrapper works with any Strands-compatible model provider. To use Amazon Bedrock:\n",
    "\n",
    "```python\n",
    "from strands.models.bedrock import BedrockModel\n",
    "\n",
    "# Create Bedrock model\n",
    "base_model = BedrockModel(\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    params={\"temperature\": 0.1}\n",
    ")\n",
    "\n",
    "# Wrap with CleanlabModel\n",
    "cleanlab_model = CleanlabModel(\n",
    "    underlying_model=base_model,\n",
    "    cleanlab_project=project,\n",
    ")\n",
    "\n",
    "# Use exactly as shown in the examples above\n",
    "agent = Agent(model=cleanlab_model, tools=[...])\n",
    "cleanlab_model.set_agent_reference(agent)\n",
    "```\n",
    "\n",
    "The validation behavior and message history management work identically across all model providers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated integrating Cleanlab validation with AWS Strands Agents using the CleanlabModel wrapper. \n",
    "\n",
    "Key benefits:\n",
    "\n",
    "- **Real-time validation** during response generation\n",
    "- **Automatic remediation** with expert answers and fallbacks\n",
    "- **Message history cleanup** to prevent contamination\n",
    "- **Context-aware validation** for retrieval-based agents\n",
    "- **Multi-model support** (OpenAI, Anthropic, Amazon Bedrock, etc.)\n",
    "\n",
    "The CleanlabModel wrapper provides enterprise-grade safety with minimal code changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codex (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}