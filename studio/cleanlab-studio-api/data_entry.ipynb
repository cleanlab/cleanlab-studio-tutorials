{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTabL3Qsj0PH"
   },
   "source": [
    "# Detect Data Entry Errors (and Impute Missing Values) in any Tabular Dataset\n",
    "\n",
    "<head>\n",
    "  <meta name=\"title\" content=\"AI to Detect Data Entry Errors (and Impute Missing Values) in any Tabular Dataset\"/>\n",
    "  <meta property=\"og:title\" content=\"AI to Detect Data Entry Errors (and Impute Missing Values) in any Tabular Dataset\"/>\n",
    "  <meta name=\"twitter:title\" content=\"AI to Detect Data Entry Errors (and Impute Missing Values) in any Tabular Dataset\" />\n",
    "  <meta name=\"image\" content=\"/img/data-entry-issues.png\" />\n",
    "  <meta property=\"og:image\" content=\"/img/data-entry-issues.png\" />\n",
    "  <meta name=\"description\" content=\"Catch erroneous values (and impute missing values) in structured datasets automatically via AI that accounts for all of the available information.\"  />\n",
    "  <meta property=\"og:description\" content=\"Catch erroneous values (and impute missing values) in structured datasets automatically via AI that accounts for all of the available information.\" />\n",
    "  <meta name=\"twitter:description\" content=\"Catch erroneous values (and impute missing values) in structured datasets automatically via AI that accounts for all of the available information.\" />\n",
    "</head>\n",
    "\n",
    "This is the recommended tutorial for programmatically identifying erroneous values (or imputing missing values) in a structured dataset via the Cleanlab Studio [Python API](/studio/quickstart/api/).\n",
    "Cleanlab's AI automatically detects entries in any data table (e.g. CSV/Excel file or Database) that are likely incorrect, perhaps due to: data entry or measurement error (e.g. sensor noise).\n",
    "\n",
    "Simply provide any data table (including columns that are: text, numeric, or categorical \u2014 even with missing values), and state-of-the-art ML models will be trained to score the quality of each datapoint (row) and flag any entry (cell value) that is likely erroneous. These same ML models can produce predictions to accurately impute missing entries in the table.\n",
    "\n",
    "Unlike traditional data validation or data quality tools, Cleanlab is not simply based on manual rules (e.g. 'this column only contains positive values in a certain range'). Instead Cleanlab uses AI that accounts for all of the available information in your dataset to flag suspicious entries which may be erroneous. Thus Cleanlab can automatically detect not only atypical values in a column (like traditional data quality tools), but also **atypical combinations of values across columns** (e.g. multiple values that are jointly incompatible).\n",
    "\n",
    "![Data entry issues](./assets/data-entry-tutorial/data-entry-issues.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caOwD-Fsj0PO"
   },
   "source": [
    "## Install and import dependencies\n",
    "\n",
    "You can use `pip` to install all other packages required for this tutorial as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bo4d-uiZj0PQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install cleanlab-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8p24kW4kj0PS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-IQne0mj0PT"
   },
   "source": [
    "## Fetch and view dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nv3hZf35j0PT"
   },
   "source": [
    "This tutorial considers a structured dataset of medical records. To fetch this dataset, make sure you have `wget` installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rT-UReATj0PU"
   },
   "outputs": [],
   "source": [
    "!wget -nc https://cleanlab-public.s3.amazonaws.com/Datasets/data_entry.csv -P data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZLJe1ZGMj0PW"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>medication</th>\n",
       "      <th>dosage</th>\n",
       "      <th>note</th>\n",
       "      <th>visiting_hours</th>\n",
       "      <th>invoice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90235</td>\n",
       "      <td>Bronchitis</td>\n",
       "      <td>Dextromethorphan</td>\n",
       "      <td>10mg</td>\n",
       "      <td>Adjusting dosage of Dextromethorphan for Bronchitis.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34227</td>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>Amoxicillin</td>\n",
       "      <td>500mg</td>\n",
       "      <td>Reviewing patient's response to Amoxicillin therapy for Pneumonia.</td>\n",
       "      <td>35.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21253</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Hydrochlorothiazide</td>\n",
       "      <td>25mg</td>\n",
       "      <td>Recommending additional tests to monitor efficacy of Hydrochlorothiazide for Hypertension.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44136</td>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>Levofloxacin</td>\n",
       "      <td>10 IU</td>\n",
       "      <td>Advised patient on importance of adherence to Levofloxacin regimen for Pneumonia.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76265</td>\n",
       "      <td>Bronchitis</td>\n",
       "      <td>Guaifenesin</td>\n",
       "      <td>200mg</td>\n",
       "      <td>Patient treated for Bronchitis using Guaifenesin.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id     diagnosis           medication dosage   \n",
       "0       90235    Bronchitis     Dextromethorphan   10mg  \\\n",
       "1       34227     Pneumonia          Amoxicillin  500mg   \n",
       "2       21253  Hypertension  Hydrochlorothiazide   25mg   \n",
       "3       44136     Pneumonia         Levofloxacin  10 IU   \n",
       "4       76265    Bronchitis          Guaifenesin  200mg   \n",
       "\n",
       "                                                                                         note   \n",
       "0                                        Adjusting dosage of Dextromethorphan for Bronchitis.  \\\n",
       "1                          Reviewing patient's response to Amoxicillin therapy for Pneumonia.   \n",
       "2  Recommending additional tests to monitor efficacy of Hydrochlorothiazide for Hypertension.   \n",
       "3           Advised patient on importance of adherence to Levofloxacin regimen for Pneumonia.   \n",
       "4                                           Patient treated for Bronchitis using Guaifenesin.   \n",
       "\n",
       "   visiting_hours  invoice  \n",
       "0             2.0     40.0  \n",
       "1            35.0    300.0  \n",
       "2             3.0    300.0  \n",
       "3             5.0    300.0  \n",
       "4             4.0     80.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH = os.getcwd()\n",
    "dataset_path = os.path.join(BASE_PATH, \"data/\")\n",
    "\n",
    "data = pd.read_csv(os.path.join(dataset_path, 'data_entry.csv'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if the dataset is complete or if there are missing entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>medication</th>\n",
       "      <th>dosage</th>\n",
       "      <th>note</th>\n",
       "      <th>visiting_hours</th>\n",
       "      <th>invoice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>10322</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Losartan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patient presenting with Hypertension symptoms despite Losartan therapy.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>53909</td>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>Azithromycin</td>\n",
       "      <td>250mg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>68289</td>\n",
       "      <td>Bronchitis</td>\n",
       "      <td>Guaifenesin</td>\n",
       "      <td>200mg</td>\n",
       "      <td>Patient responding well to Guaifenesin for Bronchitis.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>81520</td>\n",
       "      <td>Diabetes mellitus</td>\n",
       "      <td>Insulin</td>\n",
       "      <td>10 IU</td>\n",
       "      <td>Considering alternative treatments for Diabetes mellitus due to patient's intolerance to Insulin.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>61117</td>\n",
       "      <td>Diabetes mellitus</td>\n",
       "      <td>Insulin</td>\n",
       "      <td>10 IU</td>\n",
       "      <td>Instructed patient on proper administration of Insulin for Diabetes mellitus.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>64952</td>\n",
       "      <td>Influenza</td>\n",
       "      <td>Rimantadine</td>\n",
       "      <td>100mg</td>\n",
       "      <td>Patient presenting with Influenza symptoms despite Rimantadine therapy.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>15877</td>\n",
       "      <td>Bronchitis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10mg</td>\n",
       "      <td>Scheduled follow-up appointment to evaluate Bronchitis.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>49846</td>\n",
       "      <td>Bronchitis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10mg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id          diagnosis    medication dosage   \n",
       "102       10322       Hypertension      Losartan    NaN  \\\n",
       "129       53909          Pneumonia  Azithromycin  250mg   \n",
       "256       68289         Bronchitis   Guaifenesin  200mg   \n",
       "397       81520  Diabetes mellitus       Insulin  10 IU   \n",
       "473       61117  Diabetes mellitus       Insulin  10 IU   \n",
       "655       64952          Influenza   Rimantadine  100mg   \n",
       "816       15877         Bronchitis           NaN   10mg   \n",
       "966       49846         Bronchitis           NaN   10mg   \n",
       "\n",
       "                                                                                                  note   \n",
       "102                            Patient presenting with Hypertension symptoms despite Losartan therapy.  \\\n",
       "129                                                                                                NaN   \n",
       "256                                             Patient responding well to Guaifenesin for Bronchitis.   \n",
       "397  Considering alternative treatments for Diabetes mellitus due to patient's intolerance to Insulin.   \n",
       "473                      Instructed patient on proper administration of Insulin for Diabetes mellitus.   \n",
       "655                            Patient presenting with Influenza symptoms despite Rimantadine therapy.   \n",
       "816                                            Scheduled follow-up appointment to evaluate Bronchitis.   \n",
       "966                                                                                                NaN   \n",
       "\n",
       "     visiting_hours  invoice  \n",
       "102             4.0    400.0  \n",
       "129             5.0    300.0  \n",
       "256             5.0      NaN  \n",
       "397             2.0      NaN  \n",
       "473             NaN     80.0  \n",
       "655             NaN     80.0  \n",
       "816             1.0     20.0  \n",
       "966             1.0     20.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data = data[data.isnull().any(axis=1)]\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanlab Studio automatically deals with missing values, so we don't have to specially handle them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into Cleanlab Studio\n",
    "\n",
    "Our data analysis starts by loading the data, which may take a while for big datasets. First use your API key to instantiate a `Studio` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab_studio import Studio\n",
    "\n",
    "# You can find your Cleanlab Studio API key by going to studio.cleanlab.ai/upload,\n",
    "# clicking \"Upload via Python API\", and copying the API key there\n",
    "API_KEY = \"<insert your API key>\"\n",
    "\n",
    "# Initialize studio object\n",
    "studio = Studio(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A unique ID column allows us to better track and visualize results. If such a column is not present in your dataset, you can uncomment the following code to create one. <br />\n",
    "Here we'll use the 'patient_id' column which has unique values for all entries in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively you can create an ID column of sequential integers\n",
    "# identifier_col = 'unique_id'\n",
    "# data[identifier_col] = range(0, len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identifier_col = 'patient_id'  # unique ID column\n",
    "data[identifier_col].is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading data into Cleanlab Studio, the application will automatically infer the schema of your dataset.\n",
    "However in order to analyze specific numeric columns later on, we'll override the default schema here to explicitly declare these as numeric columns. You don't need to do this for all numeric columns, only certain columns you wish to specifically analyze/predict within a later Cleanlab Studio Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = studio.upload_dataset(\n",
    "    data,\n",
    "    dataset_name=\"tabular-data-entry\",\n",
    "    schema_overrides=[\n",
    "        {\"name\": \"visiting_hours\", \"column_type\": \"float\"},\n",
    "        {\"name\": \"invoice\", \"column_type\": \"float\"},\n",
    "    ],\n",
    ")\n",
    "print(f\"Dataset ID: {dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After it's loaded, we can use the dataset's `id` to create a *Project* in Cleanlab Studio, which automatically trains ML models to provide AI-based analysis of your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch projects\n",
    "\n",
    "To find erroneous values in this dataset, we launch Cleanlab Studio project for each numeric/categorical column which may contain errors.\n",
    "Each project uses ML to\u00a0analyze a particular column of the dataset by treating that column as the label (dependent variable), and the rest as predictive features (independent variables).  The predictions for each entry in the label column are thus based on all of the other available information in the same row, and can be used to impute missing entries and detect erroneous entries.\n",
    "\n",
    "We first define helper functions to determine the type of each column and launch Cleanlab Studio projects for a column (based on its determined type)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f5f605-4e19-487a-9579-1ff2c6121107",
   "metadata": {},
   "source": [
    "**Optional: Helper functions to determine the type of a column, in terms of the Cleanlab project to find erroneous values in it.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_categorical_column(col, unique_threshold = 0.05, min_na_values = 100):\n",
    "    \"\"\"\n",
    "    Check if a column is categorical and can be used as the labels for a Cleanlab Studio's classification project.\n",
    "\n",
    "    Parameters:\n",
    "    col (pd.Series or pd.DataFrame): Values in this column (extracted from the original DataFrame).\n",
    "    unique_threshold (float): Threshold to check uniqueness of categories in the column. If the ratio of (unique categories in the column / total number of data samples) is too high, return False. \n",
    "    min_na_values (int): Minimum number of non-null values in this column in order to train a reliable AI model (must be above this to return True). \n",
    "\n",
    "    Returns:\n",
    "    bool: Whether the column is categorical and can be used as label in Cleanlab Studio project.\n",
    "    \"\"\"\n",
    "\n",
    "    num_unique_vals = col.nunique()\n",
    "\n",
    "    # Check if column have all identical values\n",
    "    if num_unique_vals == 1:\n",
    "        return False\n",
    "\n",
    "    # Check if column can be considered to be categorical\n",
    "    unique_ratio = num_unique_vals / len(col)\n",
    "    if unique_ratio > unique_threshold:\n",
    "        return False\n",
    "\n",
    "    # Check the minimum class count for any class to be at least 5\n",
    "    if any(col.value_counts() < 5):\n",
    "        return False\n",
    "\n",
    "    # Check if too many NaN values to be worth training a model to predict\n",
    "    if sum(col.notna()) < min_na_values:\n",
    "        return False\n",
    "    if len(col) < 101 and sum(col.isna()) > 0:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def is_numeric_column(col, min_na_values = 100):\n",
    "    \"\"\"\n",
    "    Check if a column is numeric and if it can be used as the labels for a Cleanlab Studio regression project.\n",
    "\n",
    "    Parameters:\n",
    "    col (pd.Series or pd.DataFrame): Values in this column (extracted from the original DataFrame).\n",
    "    min_na_values (int): Minimum number of non-null values in this column in order to train a reliable AI model (must be above this to return True).\n",
    "\n",
    "    Returns:\n",
    "    bool: Whether the column is numeric and can be used as label in Cleanlab Studio project.\n",
    "    \"\"\"\n",
    "    if col.dtype not in (float, int):\n",
    "        return False\n",
    "\n",
    "    # Check if too many NaN values to be worth training a model to predict\n",
    "    if sum(col.notna()) < min_na_values:\n",
    "        return False\n",
    "    if len(col) < 101 and sum(col.isna()) > 0:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def filter_column_types(data, identifier_col, columns_to_exclude = []):\n",
    "    \"\"\"\n",
    "    Determine each column's type: categorical or numerical, to determine which type of Cleanlab Studio project to run for this column.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): Original dataset.\n",
    "    identifier_col (str): Unique identifier column (will not be considered).\n",
    "    columns_to_exclude (list[str]): List of names of columns to not consider.\n",
    "\n",
    "    Returns:\n",
    "    categorical_columns (list): List of names of columns identified as categorical \n",
    "    numeric_columns (list): List of names of columns identified as numeric \n",
    "    skip_columns (list): List of names of columns that are neither categorical nor numerical (e.g. contain arbitrary text or strings).\n",
    "    \"\"\"\n",
    "    categorical_columns = []\n",
    "    numeric_columns = []\n",
    "    skip_columns = []\n",
    "\n",
    "    all_columns = data.columns.to_list()\n",
    "    # List of columns to analyse\n",
    "    columns_to_analyze = [column for column in all_columns if column not in columns_to_exclude]\n",
    "    # Remove identifier_col as it doesn't require any analysis\n",
    "    columns_to_analyze.remove(identifier_col)\n",
    "\n",
    "    for col_name in columns_to_analyze:\n",
    "        col = data[col_name]\n",
    "        if is_categorical_column(col):\n",
    "            categorical_columns.append(col_name)\n",
    "        elif is_numeric_column(col):\n",
    "            numeric_columns.append(col_name)\n",
    "        else:\n",
    "            skip_columns.append(col_name)\n",
    "\n",
    "    if len(categorical_columns + numeric_columns) == 0:\n",
    "        print(\"No columns to find errors in.\")\n",
    "\n",
    "    return categorical_columns, numeric_columns, skip_columns\n",
    "\n",
    "# Helper function to launch Cleanlab project to detect errors in a column\n",
    "def create_column_project(dataset_id, project_name, input_columns, audit_column, task_type, model_type=\"regular\"):\n",
    "    \"\"\"\n",
    "    Launch Cleanlab Studio project based on the type of the column to be audited.\n",
    "\n",
    "    Parameters:\n",
    "    dataset_id (str): Cleanlab Studio dataset ID.\n",
    "    project_name (str): Name of the Cleanlab Studio project.\n",
    "    input_columns (list[str]): List of names of columns to use as predictive features for training Cleanlab AI model to analyze the `audit_column`.\n",
    "    audit_column (str): Name of the column to audit i.e. use as label for training Cleanlab AI model.\n",
    "    task_type (str): Type of ML task - 'multi-class' for classification or 'regression' for regression.\n",
    "    model_type (str): Type of ML model - 'regular' or 'fast' mode.\n",
    "\n",
    "    Returns:\n",
    "    project_id (str): Unique ID of this Cleanlab Studio project that can be used to programmatically fetch results.\n",
    "    \"\"\"\n",
    "    predictive_columns = input_columns.copy()\n",
    "    # Remove audit_column from the list of input predictive features\n",
    "    predictive_columns.remove(audit_column)\n",
    "    \n",
    "    project_id = studio.create_project(\n",
    "        dataset_id=dataset_id,\n",
    "        project_name=f\"{project_name}-{audit_column}\",\n",
    "        modality=\"tabular\",\n",
    "        task_type=task_type,\n",
    "        model_type=model_type,\n",
    "        label_column=audit_column,\n",
    "        feature_columns=predictive_columns\n",
    "    )\n",
    "    print(f\"Project for auditing '{audit_column}' created and training has begun! project_id: {project_id}\")\n",
    "    return project_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all columns may be susceptible to data entry errors. To save time, you can specify `columns_to_exclude` to skip these columns in the error checks (these columns may still be used as predictive features for inferring whether other columns have erroneous values).\n",
    "\n",
    "In our dataset, we'll skip the 'diagnosis' column.\n",
    "Note that any identifier column you previously declared for the dataset (in our case 'patient_id') will be ignored (neither being checked for errors nor used as a predictive feature).\n",
    "\n",
    "The following code determines which categorical and numeric columns we will check for errors (i.e. run a project for)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns to audit: ['medication', 'dosage'] \n",
      "Numeric columns to audit: ['visiting_hours', 'invoice'] \n",
      "Not categorical or numeric (not audited): ['note']\n"
     ]
    }
   ],
   "source": [
    "# List of columns to exclude\n",
    "columns_to_exclude = ['diagnosis']\n",
    "\n",
    "categorical_columns, numeric_columns, skip_columns = filter_column_types(data, identifier_col, columns_to_exclude)\n",
    "print(\"Categorical columns to audit:\", categorical_columns, \"\\nNumeric columns to audit:\", numeric_columns, \"\\nNot categorical or numeric (not audited):\", skip_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only audit numeric or categorical columns for errors (the 'note' column in our dataset contains free-form text and is automatically not checked for errors). For each column to audit, an appropriate Cleanlab project is launched (classification project for categorical columns, regression project for numeric columns). Let's launch these projects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"tutorial\"  # You can change this prefix used to name the per-column projects\n",
    "model_type = \"regular\"  # You can set this to \"fast\" to get quicker but less accurate results\n",
    "\n",
    "# All the columns (except identifier) can be predictive features\n",
    "input_columns = data.columns.to_list()  # You can reduce this to use less predictive features\n",
    "input_columns.remove(identifier_col)\n",
    "project_ids = {}  # will store IDs of all the projects for different columns \n",
    "\n",
    "# Run classification projects for categorical columns\n",
    "for audit_column in categorical_columns:\n",
    "    project_ids[audit_column] = create_column_project(dataset_id, project_name, input_columns, audit_column, 'multi-class', model_type)\n",
    "\n",
    "# Run regression projects for numeric columns\n",
    "for audit_column in numeric_columns:\n",
    "    project_ids[audit_column] = create_column_project(dataset_id, project_name, input_columns, audit_column, 'regression', model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all of the projects have been launched successfully and their `project_id`'s are visible, feel free to close this notebook. It will take time for Cleanlab\u2019s AI to train and analyze your data. Come back after training is complete (you will receive emails) and continue with the notebook to review your results. Each project produces a *cleanset* (cleaned dataset). For this tutorial, all projects launched here should complete within around 10 minutes.\n",
    "\n",
    "**You should only execute the above cells once!** Do not call `create_project` again.\n",
    "\n",
    "Before we proceed with the rest of the tutorial, we will wait for all the projects to complete. \n",
    "You can poll for project's status to programmatically wait until the results are ready for review (this next code cell will take some time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XBSJdRLj0Pb"
   },
   "outputs": [],
   "source": [
    "cleanset_ids = {}\n",
    "\n",
    "for audit_column in project_ids:\n",
    "    cleanset_ids[audit_column] = studio.get_latest_cleanset_id(project_ids[audit_column])\n",
    "    print(f\"Project for auditing '{audit_column}' is running! cleanset_id: {cleanset_ids[audit_column]}\")\n",
    "    project_status = studio.wait_until_cleanset_ready(cleanset_ids[audit_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get project results\n",
    "\n",
    "Each project generates smart metadata about each data point, which is stored as [Cleanlab columns](/studio/concepts/cleanlab_columns/) we can fetch.\n",
    "\n",
    "If at any point you want to re-run the remaining parts of this notebook (without creating another project), simply call `studio.download_cleanlab_columns(cleanset_id)` with the `cleanset_id` printed from the previous cells.\n",
    "\n",
    "We define a helper function that fetches Cleanlab generated metadata columns for each project and stores: which entries are estimated to be erroneous, confidence scores for these estimates, and AI model predictions in 3 CSV files (as well as returning corresponding DataFrames).\n",
    "Other helper functions are defined to help inspect/highlight Cleanlab results for each column using these 3 DataFrames/CSVs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331cc0b-ee7e-4670-9c6a-260b02608d49",
   "metadata": {},
   "source": [
    "**Optional: Helper function to extract and re-arrange data entries detected as possibly erroneous**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_and_write_cleanlab_results(data, cleanset_ids, identifier_col):\n",
    "    \"\"\"\n",
    "    Fetch Cleanlab columns to store erroneous entries, respective confidence scores, and AI model predictions in 3 different CSVs\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): Original data's DataFrame\n",
    "    cleanset_ids (dict): Dictionary with column name as key, and its respective cleanset_id as value\n",
    "    identifier_col (str): Unique identifier column\n",
    "\n",
    "    Returns:\n",
    "    is_issue_df (pd.DataFrame): DataFrame of booleans, for all audited columns, denoting whether the value is erroneous or not\n",
    "    issue_score_df (pd.DataFrame): DataFrame of confidence scores (0-1), for all audited columns, denoting probability of value being erroneous\n",
    "    prediction_df (pd.DataFrame): DataFrame of AI predictions, for all audited columns, that would be used to impute missing values\n",
    "    \"\"\"\n",
    "    # Instantiate DataFrames with identifier column\n",
    "    is_issue_df, issue_score_df, prediction_df = (pd.DataFrame(data[identifier_col]) for _ in range(3))\n",
    "\n",
    "    for audit_column in cleanset_ids:\n",
    "        # Download Cleanlab columns from this column's project\n",
    "        cleanlab_columns_df = studio.download_cleanlab_columns(cleanset_ids[audit_column])\n",
    "        data_cleanlab_df = data.merge(cleanlab_columns_df, left_index=True, right_index=True)\n",
    "\n",
    "        # DataFrame to store True/False flag whether the entry seems erroneous\n",
    "        is_issue_df[audit_column] = data_cleanlab_df['is_label_issue']\n",
    "\n",
    "        # DataFrame to store AI's confidence score on whether the entry is erroneous\n",
    "        issue_score_df[audit_column] = data_cleanlab_df['label_issue_score']\n",
    "\n",
    "        # DataFrame to store predicted values\n",
    "        prediction_df[audit_column] = np.where(data_cleanlab_df[\"is_label_issue\"] | data_cleanlab_df[audit_column].isna(), \n",
    "                                      data_cleanlab_df[\"suggested_label\"], \n",
    "                                      data_cleanlab_df[audit_column])\n",
    "\n",
    "    # Save DataFrames to CSV files (comment these lines if you prefer not to)\n",
    "    is_issue_df.to_csv(\"is_issue.csv\", index=False)\n",
    "    issue_score_df.to_csv(\"issue_score.csv\", index=False)\n",
    "    prediction_df.to_csv(\"imputed_values.csv\", index=False)\n",
    "    return is_issue_df, issue_score_df, prediction_df\n",
    "\n",
    "# Helper function to view the Cleanlab analysis results for a particular column\n",
    "def inspect_column(audit_column):\n",
    "    \"\"\"\n",
    "    Create a DataFrame with original data, column to inspect and its respective Cleanlab columns\n",
    "\n",
    "    Parameters:\n",
    "    audit_column (str): Name of the column to inspect\n",
    "\n",
    "    Returns:\n",
    "    merged_df (pd.DataFrame): DataFrame of original data, inspected column and its respective Cleanlab columns\n",
    "    \"\"\"\n",
    "    is_issue_col = is_issue_df[audit_column].rename(f\"{audit_column}_is_issue\")\n",
    "    issue_score_col = issue_score_df[audit_column].rename(f\"{audit_column}_issue_score\")\n",
    "    predicted_values_col = predicted_value_df[audit_column].rename(f\"{audit_column}_predicted_value\")\n",
    "    \n",
    "    # Moving the column for ease of comparison\n",
    "    data_columns = data.columns.to_list()\n",
    "    data_columns.remove(audit_column)\n",
    "    data_columns.append(audit_column)\n",
    "\n",
    "    merged_df = pd.concat([data[data_columns], is_issue_col, issue_score_col, predicted_values_col], axis=1)\n",
    "    return merged_df\n",
    "\n",
    "# Helper function to highlight particular values for ease of visualization\n",
    "def apply_highlight(row, col, mask):\n",
    "    '''\n",
    "    Highlight the (row,col) entry if mask[row,col] is True\n",
    "    \n",
    "    Parameters:\n",
    "    mask (pd.DataFrame): Contains boolean indicating whether the entry is to be highlighted\n",
    "\n",
    "    Returns:\n",
    "    CSS-style (str): Style to apply to (row, col) entry\n",
    "    '''\n",
    "    # Check if the mask is True for this particular entry\n",
    "    if mask.at[row.name, col]:\n",
    "        return 'background-color: red'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Helper function to highlight entries in Excel basis a boolean table\n",
    "def highlight_errors_in_excel(excel_path, issue_csv_path):\n",
    "    \"\"\"\n",
    "    Highlights entries in an Excel file based on boolean values in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    excel_path (path in str): Path of Excel file to manipulate\n",
    "    issue_csv_path (path in str): Path of `is_issue.csv` containing boolean table\n",
    "\n",
    "    Returns:\n",
    "    None: Save the modified Excel file\n",
    "    \"\"\"\n",
    "    # Export original data to Excel format\n",
    "    data.to_excel(excel_path, index=False)\n",
    "\n",
    "    # Read Excel data and is_issue.csv\n",
    "    excel_workbook = load_workbook(excel_path)\n",
    "    excel_worksheet = excel_workbook.active\n",
    "    is_issue_df = pd.read_csv(issue_csv_path)\n",
    "\n",
    "    # Columns to consider for highlighting\n",
    "    # is_issue_df contains the columns we audited\n",
    "    columns_to_highlight = is_issue_df.columns.to_list() # You can reduce this to a list of specific columns\n",
    "    columns_to_highlight.remove(identifier_col)\n",
    "\n",
    "    # Define pattern to apply to a cell\n",
    "    yellow_fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')\n",
    "\n",
    "    # Columns with their respective indice in Excel\n",
    "    excel_column_with_indice = {cell.value:cell.column for cell in excel_worksheet[1]}\n",
    "\n",
    "    # Iterate over columns_to_highlight\n",
    "    for column in columns_to_highlight:\n",
    "        excel_column_idx = excel_column_with_indice[column]\n",
    "        # Apply highlight if the value in `is_issue_df` is True\n",
    "        for row_idx, value in enumerate(is_issue_df[column]):\n",
    "            excel_row_idx = row_idx + 2 # Excel rows indice starts from 1 and first row contains the column headers itself, hence add 2\n",
    "            if value == True: excel_worksheet.cell(row=excel_row_idx, column=excel_column_idx).fill = yellow_fill           \n",
    "\n",
    "    excel_workbook.save(excel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helper function outputs 3 CSV files:\n",
    "\n",
    "* `is_issue.csv` contains True/False values specifying whether each entry value in the input dataset is estimated to be likely erroneous (True) or not (False). You can filter based on the True values to determine which subset of data appears suspicious/corrupted in your dataset (inferred based on the other available information in the dataset).\n",
    "\n",
    "* `issue_scores.csv` contains scores between 0 and 1 estimating the likelihood that each entry value is corrupted (higher scores indicate values that appear more suspicious/erroneous). You can sort a column's values by these scores (in descending order) to prioritize which values to review (i.e. which entries are most suspicious).\n",
    "\n",
    "* `imputed_values.csv` contains a value for each entry predicted by Cleanlab's AI model. The prediction represents the expected value of this entry based on all of the other information in dataset (in particular this row), and can be used as an imputed value if the original value were missing.\n",
    "\n",
    "All 3 CSV files returned contain the same number of rows as the original dataset, and the columns that we ran through Cleanlab projects. Each erroneous flag (boolean), suspicion score, and imputed value corresponds to the data entry at that same row/column in your original dataset.\n",
    "\n",
    "The entries flagged with the highest issue scores are those you should inspect first. After that, consider having your team review the entries that Cleanlab has flagged as seeming erronous (based on boolean `is_issue.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the above 3 DataFrames\n",
    "is_issue_df, issue_score_df, predicted_value_df = extract_and_write_cleanlab_results(data, cleanset_ids, identifier_col)\n",
    "# Display the 3 CSV files saved to the disk\n",
    "!ls -l i*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the values in each of these DataFrames/CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>medication</th>\n",
       "      <th>dosage</th>\n",
       "      <th>visiting_hours</th>\n",
       "      <th>invoice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90235</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34227</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21253</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  medication  dosage  visiting_hours  invoice\n",
       "0       90235       False   False           False    False\n",
       "1       34227       False   False            True    False\n",
       "2       21253       False   False           False    False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_issue_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>medication</th>\n",
       "      <th>dosage</th>\n",
       "      <th>visiting_hours</th>\n",
       "      <th>invoice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90235</td>\n",
       "      <td>0.106462</td>\n",
       "      <td>0.468849</td>\n",
       "      <td>0.288734</td>\n",
       "      <td>0.032805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34227</td>\n",
       "      <td>0.495846</td>\n",
       "      <td>0.471051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.124499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21253</td>\n",
       "      <td>0.105022</td>\n",
       "      <td>0.469134</td>\n",
       "      <td>0.406527</td>\n",
       "      <td>0.039586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  medication    dosage  visiting_hours   invoice\n",
       "0       90235    0.106462  0.468849        0.288734  0.032805\n",
       "1       34227    0.495846  0.471051        1.000000  0.124499\n",
       "2       21253    0.105022  0.469134        0.406527  0.039586"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_score_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>medication</th>\n",
       "      <th>dosage</th>\n",
       "      <th>visiting_hours</th>\n",
       "      <th>invoice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90235</td>\n",
       "      <td>Dextromethorphan</td>\n",
       "      <td>10mg</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34227</td>\n",
       "      <td>Amoxicillin</td>\n",
       "      <td>500mg</td>\n",
       "      <td>5.301408</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21253</td>\n",
       "      <td>Hydrochlorothiazide</td>\n",
       "      <td>25mg</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id           medication dosage  visiting_hours  invoice\n",
       "0       90235     Dextromethorphan   10mg        2.000000     40.0\n",
       "1       34227          Amoxicillin  500mg        5.301408    300.0\n",
       "2       21253  Hydrochlorothiazide   25mg        3.000000    300.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Optional***: *Analyze erroneous entries in a spreadsheet*\n",
    "\n",
    "Tabular data is frequently analyzed in Microsoft Excel for its ease of use. We can make use of the `is_issue.csv` and the original data to create a new Excel file (.xlsx) with erroneous cells highlighted in yellow. <br />\n",
    "The file `highlighted_data_entry.xlsx` is saved to the current working directory and can be opened using a spreadsheet software.\n",
    "\n",
    "**Note:**\n",
    "You have the flexibility to flag additional or fewer entries in your Data Table by setting higher or lower thresholds on the entries in `issue_scores.csv`, allowing you to create your customized boolean table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library for manipulating Excel table\n",
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary methods\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "# Path of output Excel file and is_issue.csv\n",
    "excel_path = 'highlighted_data_entry.xlsx'\n",
    "issue_csv_path = 'is_issue.csv' # Boolean table that we generated above\n",
    "\n",
    "# Save the highlighted Excel data\n",
    "highlight_errors_in_excel(excel_path, issue_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing values\n",
    "\n",
    "Before detecting data entry errors, let's first see how to impute the missing entries in the original dataset using Cleanlab's predicted value in `predicted_value_df`. These predictions come from state-of-the-art machine learning models trained (on your dataset) to predict this missing entry based on the other information available for this row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_51986_row0_col3, #T_51986_row2_col6, #T_51986_row3_col6, #T_51986_row4_col5, #T_51986_row5_col5, #T_51986_row6_col2, #T_51986_row7_col2 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_51986\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_51986_level0_col0\" class=\"col_heading level0 col0\" >patient_id</th>\n",
       "      <th id=\"T_51986_level0_col1\" class=\"col_heading level0 col1\" >diagnosis</th>\n",
       "      <th id=\"T_51986_level0_col2\" class=\"col_heading level0 col2\" >medication</th>\n",
       "      <th id=\"T_51986_level0_col3\" class=\"col_heading level0 col3\" >dosage</th>\n",
       "      <th id=\"T_51986_level0_col4\" class=\"col_heading level0 col4\" >note</th>\n",
       "      <th id=\"T_51986_level0_col5\" class=\"col_heading level0 col5\" >visiting_hours</th>\n",
       "      <th id=\"T_51986_level0_col6\" class=\"col_heading level0 col6\" >invoice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_51986_level0_row0\" class=\"row_heading level0 row0\" >102</th>\n",
       "      <td id=\"T_51986_row0_col0\" class=\"data row0 col0\" >10322</td>\n",
       "      <td id=\"T_51986_row0_col1\" class=\"data row0 col1\" >Hypertension</td>\n",
       "      <td id=\"T_51986_row0_col2\" class=\"data row0 col2\" >Losartan</td>\n",
       "      <td id=\"T_51986_row0_col3\" class=\"data row0 col3\" >50mg</td>\n",
       "      <td id=\"T_51986_row0_col4\" class=\"data row0 col4\" >Patient presenting with Hypertension symptoms despite Losartan therapy.</td>\n",
       "      <td id=\"T_51986_row0_col5\" class=\"data row0 col5\" >4.000000</td>\n",
       "      <td id=\"T_51986_row0_col6\" class=\"data row0 col6\" >400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_51986_level0_row1\" class=\"row_heading level0 row1\" >129</th>\n",
       "      <td id=\"T_51986_row1_col0\" class=\"data row1 col0\" >53909</td>\n",
       "      <td id=\"T_51986_row1_col1\" class=\"data row1 col1\" >Pneumonia</td>\n",
       "      <td id=\"T_51986_row1_col2\" class=\"data row1 col2\" >Azithromycin</td>\n",
       "      <td id=\"T_51986_row1_col3\" class=\"data row1 col3\" >250mg</td>\n",
       "      <td id=\"T_51986_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "      <td id=\"T_51986_row1_col5\" class=\"data row1 col5\" >5.000000</td>\n",
       "      <td id=\"T_51986_row1_col6\" class=\"data row1 col6\" >300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_51986_level0_row2\" class=\"row_heading level0 row2\" >256</th>\n",
       "      <td id=\"T_51986_row2_col0\" class=\"data row2 col0\" >68289</td>\n",
       "      <td id=\"T_51986_row2_col1\" class=\"data row2 col1\" >Bronchitis</td>\n",
       "      <td id=\"T_51986_row2_col2\" class=\"data row2 col2\" >Guaifenesin</td>\n",
       "      <td id=\"T_51986_row2_col3\" class=\"data row2 col3\" >200mg</td>\n",
       "      <td id=\"T_51986_row2_col4\" class=\"data row2 col4\" >Patient responding well to Guaifenesin for Bronchitis.</td>\n",
       "      <td id=\"T_51986_row2_col5\" class=\"data row2 col5\" >5.000000</td>\n",
       "      <td id=\"T_51986_row2_col6\" class=\"data row2 col6\" >202.368744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_51986_level0_row3\" class=\"row_heading level0 row3\" >397</th>\n",
       "      <td id=\"T_51986_row3_col0\" class=\"data row3 col0\" >81520</td>\n",
       "      <td id=\"T_51986_row3_col1\" class=\"data row3 col1\" >Diabetes mellitus</td>\n",
       "      <td id=\"T_51986_row3_col2\" class=\"data row3 col2\" >Insulin</td>\n",
       "      <td id=\"T_51986_row3_col3\" class=\"data row3 col3\" >10 IU</td>\n",
       "      <td id=\"T_51986_row3_col4\" class=\"data row3 col4\" >Considering alternative treatments for Diabetes mellitus due to patient's intolerance to Insulin.</td>\n",
       "      <td id=\"T_51986_row3_col5\" class=\"data row3 col5\" >2.000000</td>\n",
       "      <td id=\"T_51986_row3_col6\" class=\"data row3 col6\" >174.182175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_51986_level0_row4\" class=\"row_heading level0 row4\" >473</th>\n",
       "      <td id=\"T_51986_row4_col0\" class=\"data row4 col0\" >61117</td>\n",
       "      <td id=\"T_51986_row4_col1\" class=\"data row4 col1\" >Diabetes mellitus</td>\n",
       "      <td id=\"T_51986_row4_col2\" class=\"data row4 col2\" >Insulin</td>\n",
       "      <td id=\"T_51986_row4_col3\" class=\"data row4 col3\" >10 IU</td>\n",
       "      <td id=\"T_51986_row4_col4\" class=\"data row4 col4\" >Instructed patient on proper administration of Insulin for Diabetes mellitus.</td>\n",
       "      <td id=\"T_51986_row4_col5\" class=\"data row4 col5\" >1.003176</td>\n",
       "      <td id=\"T_51986_row4_col6\" class=\"data row4 col6\" >80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_51986_level0_row5\" class=\"row_heading level0 row5\" >655</th>\n",
       "      <td id=\"T_51986_row5_col0\" class=\"data row5 col0\" >64952</td>\n",
       "      <td id=\"T_51986_row5_col1\" class=\"data row5 col1\" >Influenza</td>\n",
       "      <td id=\"T_51986_row5_col2\" class=\"data row5 col2\" >Rimantadine</td>\n",
       "      <td id=\"T_51986_row5_col3\" class=\"data row5 col3\" >100mg</td>\n",
       "      <td id=\"T_51986_row5_col4\" class=\"data row5 col4\" >Patient presenting with Influenza symptoms despite Rimantadine therapy.</td>\n",
       "      <td id=\"T_51986_row5_col5\" class=\"data row5 col5\" >2.114235</td>\n",
       "      <td id=\"T_51986_row5_col6\" class=\"data row5 col6\" >80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_51986_level0_row6\" class=\"row_heading level0 row6\" >816</th>\n",
       "      <td id=\"T_51986_row6_col0\" class=\"data row6 col0\" >15877</td>\n",
       "      <td id=\"T_51986_row6_col1\" class=\"data row6 col1\" >Bronchitis</td>\n",
       "      <td id=\"T_51986_row6_col2\" class=\"data row6 col2\" >Dextromethorphan</td>\n",
       "      <td id=\"T_51986_row6_col3\" class=\"data row6 col3\" >10mg</td>\n",
       "      <td id=\"T_51986_row6_col4\" class=\"data row6 col4\" >Scheduled follow-up appointment to evaluate Bronchitis.</td>\n",
       "      <td id=\"T_51986_row6_col5\" class=\"data row6 col5\" >1.000000</td>\n",
       "      <td id=\"T_51986_row6_col6\" class=\"data row6 col6\" >20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_51986_level0_row7\" class=\"row_heading level0 row7\" >966</th>\n",
       "      <td id=\"T_51986_row7_col0\" class=\"data row7 col0\" >49846</td>\n",
       "      <td id=\"T_51986_row7_col1\" class=\"data row7 col1\" >Bronchitis</td>\n",
       "      <td id=\"T_51986_row7_col2\" class=\"data row7 col2\" >Dextromethorphan</td>\n",
       "      <td id=\"T_51986_row7_col3\" class=\"data row7 col3\" >10mg</td>\n",
       "      <td id=\"T_51986_row7_col4\" class=\"data row7 col4\" >nan</td>\n",
       "      <td id=\"T_51986_row7_col5\" class=\"data row7 col5\" >1.000000</td>\n",
       "      <td id=\"T_51986_row7_col6\" class=\"data row7 col6\" >20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x12ae5e4f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight_imputed_values = True  # Change to False if you don't want to highlight imputed values\n",
    "missing_data_imputed = missing_data.copy()\n",
    "\n",
    "impute_columns = categorical_columns + numeric_columns # You can reduce this to a list of specific columns\n",
    "for col in impute_columns:\n",
    "    missing_data_imputed[col] = missing_data_imputed[col].fillna(predicted_value_df[col])\n",
    "\n",
    "if highlight_imputed_values:\n",
    "    # Boolean mask indicating whether the entry is missing or not\n",
    "    mask_impute = missing_data.isna()\n",
    "    # Apply highlight style\n",
    "    missing_data_imputed = missing_data_imputed.style.apply(lambda x: [apply_highlight(x, col, mask_impute) for col in x.index], axis=1, subset=impute_columns)\n",
    "\n",
    "missing_data_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the data entry error audit for each column\n",
    "\n",
    "Let's take a closer look at the 'medication' column. Here we obtain a merged DataFrame using the `inspect_column` helper function defined above, then filter for the data points where `is_issue` is True and sort the values by `issue_score` to view the top most suspicious entries detected in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>dosage</th>\n",
       "      <th>note</th>\n",
       "      <th>visiting_hours</th>\n",
       "      <th>invoice</th>\n",
       "      <th>medication</th>\n",
       "      <th>medication_is_issue</th>\n",
       "      <th>medication_issue_score</th>\n",
       "      <th>medication_predicted_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>73051</td>\n",
       "      <td>Influenza</td>\n",
       "      <td>10mg</td>\n",
       "      <td>Patient treated for Influenza using Rimantadine.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Rimantadine</td>\n",
       "      <td>True</td>\n",
       "      <td>0.920749</td>\n",
       "      <td>Zanamivir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>11433</td>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>500mg</td>\n",
       "      <td>Educated patient on potential side effects of Amoxicillin for Pneumonia.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Insulin</td>\n",
       "      <td>True</td>\n",
       "      <td>0.709063</td>\n",
       "      <td>Amoxicillin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id  diagnosis dosage   \n",
       "484       73051  Influenza   10mg  \\\n",
       "771       11433  Pneumonia  500mg   \n",
       "\n",
       "                                                                         note   \n",
       "484                          Patient treated for Influenza using Rimantadine.  \\\n",
       "771  Educated patient on potential side effects of Amoxicillin for Pneumonia.   \n",
       "\n",
       "     visiting_hours  invoice   medication  medication_is_issue   \n",
       "484             1.0     40.0  Rimantadine                 True  \\\n",
       "771             2.0    120.0      Insulin                 True   \n",
       "\n",
       "     medication_issue_score medication_predicted_value  \n",
       "484                0.920749                  Zanamivir  \n",
       "771                0.709063                Amoxicillin  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_column = 'medication'\n",
    "\n",
    "medication_df = inspect_column(audit_column)\n",
    "medication_issues = medication_df[medication_df[f\"{audit_column}_is_issue\"] == True].sort_values(f\"{audit_column}_issue_score\", ascending=False)\n",
    "medication_issues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per [drugs.com](https://www.drugs.com/dosage/rimantadine.html), Rimantadine is typically prescribed at a dosage of 100mg, not 10mg which is the dosage for Zanamavir (predicted value). Also, Insulin is the medication for Diabetes mellitus, not Pneumonia.\n",
    "Such entries can be referred to subject matter expert for review.\n",
    "\n",
    "Next let's check the `visiting_hours` column and similarly view the top most suspicious values detected in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>medication</th>\n",
       "      <th>dosage</th>\n",
       "      <th>note</th>\n",
       "      <th>invoice</th>\n",
       "      <th>visiting_hours</th>\n",
       "      <th>visiting_hours_is_issue</th>\n",
       "      <th>visiting_hours_issue_score</th>\n",
       "      <th>visiting_hours_predicted_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34227</td>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>Amoxicillin</td>\n",
       "      <td>500mg</td>\n",
       "      <td>Reviewing patient's response to Amoxicillin therapy for Pneumonia.</td>\n",
       "      <td>300.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.301408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>52005</td>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>Levofloxacin</td>\n",
       "      <td>500mg</td>\n",
       "      <td>Patient exhibiting adverse reaction to Levofloxacin prescribed for Pneumonia.</td>\n",
       "      <td>300.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.519128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>39637</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Hydrochlorothiazide</td>\n",
       "      <td>10mg</td>\n",
       "      <td>Instructed patient on proper administration of Hydrochlorothiazide for Hypertension.</td>\n",
       "      <td>500.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.023181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>19203</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Losartan</td>\n",
       "      <td>50mg</td>\n",
       "      <td>Noted improvement in patient's condition after administering Losartan for Hypertension.</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.218635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>25119</td>\n",
       "      <td>Influenza</td>\n",
       "      <td>Rimantadine</td>\n",
       "      <td>100mg</td>\n",
       "      <td>Recommended lifestyle modifications in addition to Rimantadine therapy for Influenza.</td>\n",
       "      <td>120.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.762323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id     diagnosis           medication dosage   \n",
       "1         34227     Pneumonia          Amoxicillin  500mg  \\\n",
       "325       52005     Pneumonia         Levofloxacin  500mg   \n",
       "639       39637  Hypertension  Hydrochlorothiazide   10mg   \n",
       "710       19203  Hypertension             Losartan   50mg   \n",
       "855       25119     Influenza          Rimantadine  100mg   \n",
       "\n",
       "                                                                                        note   \n",
       "1                         Reviewing patient's response to Amoxicillin therapy for Pneumonia.  \\\n",
       "325            Patient exhibiting adverse reaction to Levofloxacin prescribed for Pneumonia.   \n",
       "639     Instructed patient on proper administration of Hydrochlorothiazide for Hypertension.   \n",
       "710  Noted improvement in patient's condition after administering Losartan for Hypertension.   \n",
       "855    Recommended lifestyle modifications in addition to Rimantadine therapy for Influenza.   \n",
       "\n",
       "      invoice  visiting_hours  visiting_hours_is_issue   \n",
       "1       300.0            35.0                     True  \\\n",
       "325     300.0            20.0                     True   \n",
       "639     500.0            65.0                     True   \n",
       "710  200000.0            30.0                     True   \n",
       "855     120.0            28.0                     True   \n",
       "\n",
       "     visiting_hours_issue_score  visiting_hours_predicted_value  \n",
       "1                           1.0                        5.301408  \n",
       "325                         1.0                        5.519128  \n",
       "639                         1.0                        7.023181  \n",
       "710                         1.0                        5.218635  \n",
       "855                         1.0                        3.762323  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_column = 'visiting_hours'\n",
    "\n",
    "visiting_hours_df = inspect_column(audit_column)\n",
    "visiting_hours_issues = visiting_hours_df[visiting_hours_df[f\"{audit_column}_is_issue\"] == True].sort_values(f\"{audit_column}_issue_score\", ascending=False)\n",
    "visiting_hours_issues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visiting hours recorded in these entries appears off as patients don't typically have these sorts of consultations for such long hours. Such entries can be double checked based on domain knowledge and their presence may indicate you should implement regularly scheduled data validation to ensure values fall within known ranges.\n",
    "\n",
    "We repeat the same steps as above, but this time for the `dosage` column to check for entries with suspicious values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>medication</th>\n",
       "      <th>note</th>\n",
       "      <th>visiting_hours</th>\n",
       "      <th>invoice</th>\n",
       "      <th>dosage</th>\n",
       "      <th>dosage_is_issue</th>\n",
       "      <th>dosage_issue_score</th>\n",
       "      <th>dosage_predicted_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44136</td>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>Levofloxacin</td>\n",
       "      <td>Advised patient on importance of adherence to Levofloxacin regimen for Pneumonia.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>10 IU</td>\n",
       "      <td>True</td>\n",
       "      <td>0.532683</td>\n",
       "      <td>500mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>39637</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Hydrochlorothiazide</td>\n",
       "      <td>Instructed patient on proper administration of Hydrochlorothiazide for Hypertension.</td>\n",
       "      <td>65.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>10mg</td>\n",
       "      <td>True</td>\n",
       "      <td>0.531477</td>\n",
       "      <td>25mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>38965</td>\n",
       "      <td>Bronchitis</td>\n",
       "      <td>Guaifenesin</td>\n",
       "      <td>Patient diagnosed with Bronchitis. Prescribed Guaifenesin for treatment.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100mg</td>\n",
       "      <td>True</td>\n",
       "      <td>0.531120</td>\n",
       "      <td>200mg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>73051</td>\n",
       "      <td>Influenza</td>\n",
       "      <td>Rimantadine</td>\n",
       "      <td>Patient treated for Influenza using Rimantadine.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10mg</td>\n",
       "      <td>True</td>\n",
       "      <td>0.530678</td>\n",
       "      <td>100mg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id     diagnosis           medication   \n",
       "3         44136     Pneumonia         Levofloxacin  \\\n",
       "639       39637  Hypertension  Hydrochlorothiazide   \n",
       "109       38965    Bronchitis          Guaifenesin   \n",
       "484       73051     Influenza          Rimantadine   \n",
       "\n",
       "                                                                                     note   \n",
       "3       Advised patient on importance of adherence to Levofloxacin regimen for Pneumonia.  \\\n",
       "639  Instructed patient on proper administration of Hydrochlorothiazide for Hypertension.   \n",
       "109              Patient diagnosed with Bronchitis. Prescribed Guaifenesin for treatment.   \n",
       "484                                      Patient treated for Influenza using Rimantadine.   \n",
       "\n",
       "     visiting_hours  invoice dosage  dosage_is_issue  dosage_issue_score   \n",
       "3               5.0    300.0  10 IU             True            0.532683  \\\n",
       "639            65.0    500.0   10mg             True            0.531477   \n",
       "109             1.0     20.0  100mg             True            0.531120   \n",
       "484             1.0     40.0   10mg             True            0.530678   \n",
       "\n",
       "    dosage_predicted_value  \n",
       "3                    500mg  \n",
       "639                   25mg  \n",
       "109                  200mg  \n",
       "484                  100mg  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_column = 'dosage'\n",
    "\n",
    "dosage_df = inspect_column(audit_column)\n",
    "dosage_issues = dosage_df[dosage_df[f\"{audit_column}_is_issue\"] == True].sort_values(f\"{audit_column}_issue_score\", ascending=False)\n",
    "dosage_issues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levofloxacin is prescribed in milligrams (mg) not insulin units (IU), which signals that the dosage value is definitely wrong.\n",
    "Also, the recommended dosage for Rimantadine, as per [drugs.com](https://www.drugs.com/dosage/Rimantadine.html), is 100mg. Zanamivir, another drug for Influenza, is prescribed with [5-10mg dose](https://www.drugs.com/dosage/Zanamivir.html). So either the recorded dosage or medication seems off here. \n",
    "The same applies to [Hydrochlorothiazide](https://www.drugs.com/dosage/Hydrochlorothiazide.html) which is usually prescribed with 25-100mg dosage for Hypertension, and to Guaifenesin for treating Bronchitis.\n",
    "\n",
    "For all of these data entries, Cleanlab's predicted value seems more appropriate.\n",
    "\n",
    "Finally, we look for data entry errors in the \"invoice\" column using the same steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>medication</th>\n",
       "      <th>dosage</th>\n",
       "      <th>note</th>\n",
       "      <th>visiting_hours</th>\n",
       "      <th>invoice</th>\n",
       "      <th>invoice_is_issue</th>\n",
       "      <th>invoice_issue_score</th>\n",
       "      <th>invoice_predicted_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>19203</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Losartan</td>\n",
       "      <td>50mg</td>\n",
       "      <td>Noted improvement in patient's condition after administering Losartan for Hypertension.</td>\n",
       "      <td>30.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>606.011169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id     diagnosis medication dosage   \n",
       "710       19203  Hypertension   Losartan   50mg  \\\n",
       "\n",
       "                                                                                        note   \n",
       "710  Noted improvement in patient's condition after administering Losartan for Hypertension.  \\\n",
       "\n",
       "     visiting_hours   invoice  invoice_is_issue  invoice_issue_score   \n",
       "710            30.0  200000.0              True                  1.0  \\\n",
       "\n",
       "     invoice_predicted_value  \n",
       "710               606.011169  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit_column = 'invoice'\n",
    "\n",
    "invoice_df = inspect_column(audit_column)\n",
    "invoice_issues = invoice_df[invoice_df[f\"{audit_column}_is_issue\"] == True].sort_values(f\"{audit_column}_issue_score\", ascending=False)\n",
    "invoice_issues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The invoice value of $200k is too high. Such an entry should be verified from other records to avoid accounting issues later on.\n",
    "\n",
    "## Improve your dataset by correcting erroneous entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to ensure that you have high quality data is to manually inspect the entries that Cleanlab identified to have issues (i.e. `is_issue` = True) and correct them. However, that could be time consuming and hence you can also auto-correct your data by replacing the entries that have been flagged as issues with Cleanlab's predicted values. **We recommend reviewing various predicted values from diverse rows to ensure they are reasonable before doing this**.\n",
    "\n",
    "We demonstrate how to automatically obtain an improved dataset below, where `autocorrected_dataset` will have the exact same rows and columns as your original dataset, but with the entries estimated to be potentially erroneous replaced with values predicted by Cleanlab based on the other information in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrected_dataset = data.copy()\n",
    "fix_columns = categorical_columns + numeric_columns # You can reduce this to a list of specific columns\n",
    "\n",
    "impute_missing = False # Change this to True if you want to impute the missing values alongside fixing the erroneous entries\n",
    "mask_condition = {col: (is_issue_df[col] if not impute_missing else is_issue_df[col] | autocorrected_dataset[col].isna()) for col in fix_columns}\n",
    "\n",
    "for col in fix_columns:\n",
    "    autocorrected_dataset[col] = autocorrected_dataset[col].mask(mask_condition[col], predicted_value_df[col])\n",
    "\n",
    "autocorrected_dataset.to_csv('autocorrected_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we view the first 5 samples of the autocorrected dataset highlighting the corrected entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d901c_row1_col5, #T_d901c_row3_col3 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d901c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d901c_level0_col0\" class=\"col_heading level0 col0\" >patient_id</th>\n",
       "      <th id=\"T_d901c_level0_col1\" class=\"col_heading level0 col1\" >diagnosis</th>\n",
       "      <th id=\"T_d901c_level0_col2\" class=\"col_heading level0 col2\" >medication</th>\n",
       "      <th id=\"T_d901c_level0_col3\" class=\"col_heading level0 col3\" >dosage</th>\n",
       "      <th id=\"T_d901c_level0_col4\" class=\"col_heading level0 col4\" >note</th>\n",
       "      <th id=\"T_d901c_level0_col5\" class=\"col_heading level0 col5\" >visiting_hours</th>\n",
       "      <th id=\"T_d901c_level0_col6\" class=\"col_heading level0 col6\" >invoice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d901c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d901c_row0_col0\" class=\"data row0 col0\" >90235</td>\n",
       "      <td id=\"T_d901c_row0_col1\" class=\"data row0 col1\" >Bronchitis</td>\n",
       "      <td id=\"T_d901c_row0_col2\" class=\"data row0 col2\" >Dextromethorphan</td>\n",
       "      <td id=\"T_d901c_row0_col3\" class=\"data row0 col3\" >10mg</td>\n",
       "      <td id=\"T_d901c_row0_col4\" class=\"data row0 col4\" >Adjusting dosage of Dextromethorphan for Bronchitis.</td>\n",
       "      <td id=\"T_d901c_row0_col5\" class=\"data row0 col5\" >2.000000</td>\n",
       "      <td id=\"T_d901c_row0_col6\" class=\"data row0 col6\" >40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d901c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d901c_row1_col0\" class=\"data row1 col0\" >34227</td>\n",
       "      <td id=\"T_d901c_row1_col1\" class=\"data row1 col1\" >Pneumonia</td>\n",
       "      <td id=\"T_d901c_row1_col2\" class=\"data row1 col2\" >Amoxicillin</td>\n",
       "      <td id=\"T_d901c_row1_col3\" class=\"data row1 col3\" >500mg</td>\n",
       "      <td id=\"T_d901c_row1_col4\" class=\"data row1 col4\" >Reviewing patient's response to Amoxicillin therapy for Pneumonia.</td>\n",
       "      <td id=\"T_d901c_row1_col5\" class=\"data row1 col5\" >5.301408</td>\n",
       "      <td id=\"T_d901c_row1_col6\" class=\"data row1 col6\" >300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d901c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d901c_row2_col0\" class=\"data row2 col0\" >21253</td>\n",
       "      <td id=\"T_d901c_row2_col1\" class=\"data row2 col1\" >Hypertension</td>\n",
       "      <td id=\"T_d901c_row2_col2\" class=\"data row2 col2\" >Hydrochlorothiazide</td>\n",
       "      <td id=\"T_d901c_row2_col3\" class=\"data row2 col3\" >25mg</td>\n",
       "      <td id=\"T_d901c_row2_col4\" class=\"data row2 col4\" >Recommending additional tests to monitor efficacy of Hydrochlorothiazide for Hypertension.</td>\n",
       "      <td id=\"T_d901c_row2_col5\" class=\"data row2 col5\" >3.000000</td>\n",
       "      <td id=\"T_d901c_row2_col6\" class=\"data row2 col6\" >300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d901c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d901c_row3_col0\" class=\"data row3 col0\" >44136</td>\n",
       "      <td id=\"T_d901c_row3_col1\" class=\"data row3 col1\" >Pneumonia</td>\n",
       "      <td id=\"T_d901c_row3_col2\" class=\"data row3 col2\" >Levofloxacin</td>\n",
       "      <td id=\"T_d901c_row3_col3\" class=\"data row3 col3\" >500mg</td>\n",
       "      <td id=\"T_d901c_row3_col4\" class=\"data row3 col4\" >Advised patient on importance of adherence to Levofloxacin regimen for Pneumonia.</td>\n",
       "      <td id=\"T_d901c_row3_col5\" class=\"data row3 col5\" >5.000000</td>\n",
       "      <td id=\"T_d901c_row3_col6\" class=\"data row3 col6\" >300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d901c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d901c_row4_col0\" class=\"data row4 col0\" >76265</td>\n",
       "      <td id=\"T_d901c_row4_col1\" class=\"data row4 col1\" >Bronchitis</td>\n",
       "      <td id=\"T_d901c_row4_col2\" class=\"data row4 col2\" >Guaifenesin</td>\n",
       "      <td id=\"T_d901c_row4_col3\" class=\"data row4 col3\" >200mg</td>\n",
       "      <td id=\"T_d901c_row4_col4\" class=\"data row4 col4\" >Patient treated for Bronchitis using Guaifenesin.</td>\n",
       "      <td id=\"T_d901c_row4_col5\" class=\"data row4 col5\" >4.000000</td>\n",
       "      <td id=\"T_d901c_row4_col6\" class=\"data row4 col6\" >80.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x12eb2bac0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = 5\n",
    "highlight_corrected_values = True\n",
    "autocorrected_dataset_copy = autocorrected_dataset.copy()\n",
    "\n",
    "if highlight_corrected_values:\n",
    "    autocorrected_dataset_copy = autocorrected_dataset.head(samples).style.apply(lambda x: [apply_highlight(x, col, is_issue_df) for col in x.index], axis=1, subset=impute_columns)\n",
    "\n",
    "autocorrected_dataset_copy"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}