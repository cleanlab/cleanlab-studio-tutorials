{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting common types of Python image datasets\n",
    "\n",
    "This tutorial demonstrates how to format image data in various popular Python formats before running [Cleanlab Studio](https://studio.cleanlab.ai/). Each section of the tutorial covers one specific data format and outlines the steps to create a zip file that Cleanlab Studio can natively process. Here we only show how to produce a properly formatted data file, not how to run Cleanlab Studio on it -- for that refer to the [image data quickstart tutorial](/studio/tutorials/cleanlab-studio-api/image_data_quickstart/).\n",
    "\n",
    "\n",
    "Cleanlab Studio can be directly run on image datasets in a ZIP file format with or without metadata. The application natively supports many other data formats listed in this [guide](/studio/concepts/datasets/#image), **refer to it instead if your image data are not in one of the formats presented in this tutorial.**\n",
    "\n",
    "This tutorial demonstrates how to convert each of the following Python data formats into a dataset that can be directly processed by Cleanlab Studio:\n",
    "- [Huggingface Datasets](#1-huggingface-datasets)\n",
    "- [Torchvision Datasets](#2-torchvision-datasets)\n",
    "- [Tensorflow Datasets](#3-tensorflow-datasets)\n",
    "\n",
    "Below we show a toy example of the folder and file structure that a local dataset should adhere to before zipping the folder for Cleanlab Studio.\n",
    "\n",
    "```bash\n",
    "|-- <image_dataset>\n",
    "|   |-- <class_0>\n",
    "|   |   |-- <image_0>\n",
    "|   |   |-- <image_1>\n",
    "...\n",
    "|   |-- <class_n>\n",
    "...\n",
    "```\n",
    "The following command produces a ZIP file of the image dataset\u00a0that can be directly processed by Cleanlab Studio: \n",
    "```bash\n",
    "zip -r <image_dataset>.zip <image_dataset>\n",
    "```\n",
    "The rest of this tutorial demonstrates how to create such files from various Python datasets. We begin by installing and importing some necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tqdm ipywidgets Pillow datasets tensorflow-datasets tensorflow torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import io\n",
    "import zipfile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Huggingface Datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we load the [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset which consists of 60,000 images across 10 classes. It is one of the most common datasets for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['img', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['img', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset from the Hub\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "cifar10_dict = load_dataset(\"cifar10\")\n",
    "cifar10_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For finding issues across splits, we concatenate the splits into one single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['img', 'label'],\n",
       "    num_rows: 60000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_hf = concatenate_datasets(cifar10_dict.values())\n",
    "cifar10_hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View an example from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32>,\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_hf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}\n"
     ]
    }
   ],
   "source": [
    "# construct mapping from id to label str\n",
    "label_str_list = cifar10_hf.features[\"label\"].names\n",
    "label_mapping = {i: name for i, name in enumerate(label_str_list)}\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for formatting Huggingface dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_huggingface_image_dataset(\n",
    "    dataset, image_key, label_key, label_mapping, filename, save_dir\n",
    "):\n",
    "    \"\"\"Convert a Huggingface dataset to Cleanlab Studio format.\n",
    "\n",
    "    dataset: datasets.Dataset\n",
    "        HuggingFace image dataset\n",
    "    image_key: str\n",
    "        column name for image in dataset\n",
    "    label_key: str\n",
    "        column name for label in dataset\n",
    "    label_mapping: Dict[str, int]\n",
    "        id to label str mapping\n",
    "        If labels are already strings, set label_mapping to None\n",
    "    filename: str\n",
    "        filename for the zip file\n",
    "    save_dir: str\n",
    "        directory to save the zip file\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def image_data_generator():\n",
    "        \"\"\"Generator to yield image data and its path in the zip file.\"\"\"\n",
    "        for idx, data in enumerate(dataset):\n",
    "            image = data[image_key]\n",
    "            label = data[label_key]\n",
    "            class_dir = label_mapping[label] if label_mapping else label\n",
    "\n",
    "            buf = io.BytesIO()\n",
    "            image.save(buf, format=\"PNG\")\n",
    "            image_data = buf.getvalue()\n",
    "\n",
    "            yield f\"hf_dataset/{class_dir}/image_{idx}.png\", image_data\n",
    "\n",
    "    zip_path = os.path.join(save_dir, f\"{filename}.zip\")\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"w\") as zf:\n",
    "        for path, data in tqdm(image_data_generator(), total=len(dataset)):\n",
    "            zf.writestr(path, data)\n",
    "\n",
    "    print(f\"Saved zip file to: {zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the dataset and save to a zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_huggingface_image_dataset(\n",
    "    dataset=cifar10_hf,\n",
    "    image_key=\"img\",\n",
    "    label_key=\"label\",\n",
    "    label_mapping=label_mapping,\n",
    "    filename=\"cifar10_hf\",\n",
    "    save_dir=\"./\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can upload the file `./cifar10_hf.zip` to [Cleanlab Studio](https://studio.cleanlab.ai/), either using Web UI or Cleanlab Studio API. Check [Upload Dataset](https://help.cleanlab.ai/studio/tutorials/cleanlab-studio-api/large_image_datasets/#upload-dataset) section for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Torchvision datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we again load the [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset from torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_test = CIFAR10(root=\"./\", train=False, download=True)\n",
    "cifar10_train = CIFAR10(root=\"./\", train=True, download=True)\n",
    "cifar10_torch = ConcatDataset([cifar10_train, cifar10_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")\n",
    "label_mapping = {i: classes[i] for i in range(len(classes))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View an example from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=32x32>, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_torch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for formatting Torchvision dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_torchvision_dataset(\n",
    "    dataset, image_key, label_key, label_mapping, filename, save_dir\n",
    "):\n",
    "    \"\"\"Convert a Torchvision dataset to Cleanlab Studio format.\n",
    "\n",
    "    dataset: torchvision.datasets\n",
    "        Torchvision dataset\n",
    "    image_key: str\n",
    "        column name for image in dataset\n",
    "    label_key: str\n",
    "        column name for label in dataset\n",
    "    label_mapping: Dict[str, int]\n",
    "        id to label str mapping\n",
    "        If labels are already strings, set label_mapping to None\n",
    "    filename: str\n",
    "        filename for the zip file\n",
    "    save_dir: str\n",
    "        directory to save the zip file\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def image_data_generator():\n",
    "        \"\"\"Generator to yield image data and its path in the zip file.\"\"\"\n",
    "        for idx, data in enumerate(dataset):\n",
    "            image = data[image_key]\n",
    "            label = label_mapping[data[label_key]] if label_mapping else data[label_key]\n",
    "\n",
    "            buf = io.BytesIO()\n",
    "            image.save(buf, format=\"PNG\")\n",
    "            image_data = buf.getvalue()\n",
    "\n",
    "            yield f\"torch_dataset/{label}/image_{idx}.png\", image_data\n",
    "\n",
    "    zip_path = os.path.join(save_dir, f\"{filename}.zip\")\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"w\") as zf:\n",
    "        for path, data in tqdm(image_data_generator(), total=len(dataset)):\n",
    "            zf.writestr(path, data)\n",
    "\n",
    "    print(f\"Saved zip file to: {zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the dataset and save to a zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_torchvision_dataset(\n",
    "    dataset=cifar10_torch,\n",
    "    image_key=0,\n",
    "    label_key=1,\n",
    "    label_mapping=label_mapping,\n",
    "    filename=\"cifar10_torch\",\n",
    "    save_dir=\"./\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can upload the file `./cifar10_torch.zip` to Cleanlab Studio, either using Web UI or Studio API. Check [Upload Dataset](https://help.cleanlab.ai/studio/tutorials/cleanlab-studio-api/large_image_datasets/#upload-dataset) section for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tensorflow datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_tf, metadata = tfds.load(\n",
    "    \"cifar10\", split=\"train\", with_info=True, as_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'}\n"
     ]
    }
   ],
   "source": [
    "# construct mapping from id to label str\n",
    "label_str_list = metadata.features[\"label\"].names\n",
    "label_mapping = {i: name for i, name in enumerate(label_str_list)}\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_tensorflow_image_dataset(\n",
    "    dataset, image_key, label_key, label_mapping, filename, save_dir\n",
    "):\n",
    "    \"\"\"Convert a Tensorflow dataset to Cleanlab Studio format.\n",
    "\n",
    "    dataset: tf.data.Dataset\n",
    "        Tensorflow dataset\n",
    "    image_key: str\n",
    "        column name for image in dataset\n",
    "    label_key: str\n",
    "        column name for label in dataset\n",
    "    label_mapping: Dict[str, int]\n",
    "        id to label str mapping\n",
    "    filename: str\n",
    "        filename for the zip file\n",
    "    save_dir: str\n",
    "        directory to save the zip file\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def image_data_generator():\n",
    "        \"\"\"Generator to yield image data and its path in the zip file.\"\"\"\n",
    "        for idx, example in enumerate(dataset):\n",
    "            image = Image.fromarray(example[image_key].numpy())\n",
    "            label = label_mapping[example[label_key].numpy()]\n",
    "\n",
    "            buf = io.BytesIO()\n",
    "            image.save(buf, format=\"PNG\")\n",
    "            image_data = buf.getvalue()\n",
    "\n",
    "            yield f\"tf_dataset/{label}/image_{idx}.png\", image_data\n",
    "\n",
    "    zip_path = os.path.join(save_dir, f\"{filename}.zip\")\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"w\") as zf:\n",
    "        for path, data in tqdm(image_data_generator()):\n",
    "            zf.writestr(path, data)\n",
    "\n",
    "    print(f\"Saved zip file to: {zip_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_tensorflow_image_dataset(\n",
    "    dataset=cifar10_tf,\n",
    "    image_key=0,\n",
    "    label_key=1,\n",
    "    label_mapping=label_mapping,\n",
    "    filename=\"cifar10_tf\",\n",
    "    save_dir=\"./\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can upload the file `./cifar10_tf.zip` to Cleanlab Studio, either using Web UI or Studio API. Check [Upload Dataset](https://help.cleanlab.ai/studio/tutorials/cleanlab-studio-api/large_image_datasets/#upload-dataset) section for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}