{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting common types of Python text datasets\n",
    "\n",
    "This tutorial demonstrates how to format text data in various popular Python formats before uploading to [Cleanlab Studio](https://studio.cleanlab.ai/). Each section of the tutorial covers one specific data format and outlines the steps to create a data file that Cleanlab Studio can seamlessly process. In this tutorial, we focus on how to produce a properly formatted data file, not how to run Cleanlab Studio on it -- for that refer to our [text data quickstart tutorial](/studio/tutorials/cleanlab-studio-api/text_data_quickstart).\n",
    "\n",
    "Recall that Cleanlab Studio can be directly run on text datasets stored in one of the following formats: CSV, JSON, Excel, Pandas DataFrame. The application natively supports many other data formats listed in this [guide](/studio/concepts/datasets/#texttabular), **refer to it instead if your data are not in one of the formats presented in this tutorial**.\n",
    "\n",
    "This tutorial covers the following Python data formats:\n",
    "- [Huggingface Datasets](#1-huggingface-datasets)\n",
    "- [Tensorflow Datasets](#2-tensorflow-datasets)\n",
    "- [Scikit-learn Datasets](#3-sklearn-datasets)\n",
    "\n",
    "The example below shows how a data file will look after formatting. After formatting, you can directly load the dataset into Cleanlab Studio.\n",
    "\n",
    "```csv\n",
    ",text,label\n",
    "0,To make her feel threatened,fear\n",
    "1,It might be linked to the trust factor of your friend.,neutral\n",
    "2,\"Super, thanks\",gratitude\n",
    "3,What does FPTP have to do with the referendum?,confusion\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import required dependencies\n",
    "\n",
    "You can use `pip` to install all packages required for this tutorial as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas tensorflow-datasets tensorflow datasets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Huggingface Datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we load the [Go Emotions](https://huggingface.co/datasets/go_emotions) dataset which consists of Reddit comments (text) labeled for 27 emotion categories (including Neutral). This is a **multi-label classification** dataset, where more than one label can apply to a single text example.\n",
    "\n",
    "For multi-class classification text datasets, you can still use the same workflow outlined below to get a data file for Cleanlab Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from the Hub\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "emotion_dict = load_dataset(\"go_emotions\")\n",
    "emotion_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For finding issues across splits, we concatenate the splits into one single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels', 'id'],\n",
       "    num_rows: 54263\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_ds = concatenate_datasets(emotion_dict.values())\n",
    "emotion_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View few examples from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': [\"My favourite food is anything I didn't have to cook myself.\",\n",
       "  'Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead',\n",
       "  'WHY THE FUCK IS BAYLESS ISOING',\n",
       "  'To make her feel threatened',\n",
       "  'Dirty Southern Wankers'],\n",
       " 'labels': [[27], [27], [2], [14], [3]],\n",
       " 'id': ['eebbqej', 'ed00q6i', 'eezlygj', 'ed7ypvh', 'ed0bdzj']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_ds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for formatting Huggingface text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_huggingface_text_dataset(\n",
    "    dataset, text_key, label_key, output_csvpath, label_mapping\n",
    "):\n",
    "    \"\"\"Convert a Huggingface text dataset to a Cleanlab Studio file format.\n",
    "\n",
    "    dataset: datasets.Dataset\n",
    "        HuggingFace text dataset\n",
    "    text_key: str\n",
    "        column name for text in dataset\n",
    "    label_key: str\n",
    "        column name for label in dataset\n",
    "    label_mapping: Dict[str, int]\n",
    "        id to label str mapping\n",
    "        If labels are already strings, set label_mapping to None\n",
    "    output_csvpath: str\n",
    "        filepath to save csv file\n",
    "\n",
    "    \"\"\"\n",
    "    df = dataset.to_pandas()\n",
    "    df = df.rename(columns={text_key: \"text\", label_key: \"label\"})\n",
    "\n",
    "    # Map integer labels to label strings, for example, 0 -> positive, 1 -> negative\n",
    "    if label_mapping:\n",
    "        if isinstance(dataset[0][label_key], list):\n",
    "            df[\"label\"] = [\n",
    "                \",\".join([label_mapping[label_id] for label_id in label_id_list])\n",
    "                for label_id_list in df[\"label\"]\n",
    "            ]\n",
    "        elif isinstance(dataset[0][label_key], int):\n",
    "            df[\"label\"] = [label_mapping[label_id] for label_id in df[\"label\"]]\n",
    "\n",
    "    # Save to csv\n",
    "    df.to_csv(output_csvpath, index=False)\n",
    "    print(f\"Saved data file to {output_csvpath}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'admiration', 1: 'amusement', 2: 'anger', 3: 'annoyance', 4: 'approval', 5: 'caring', 6: 'confusion', 7: 'curiosity', 8: 'desire', 9: 'disappointment', 10: 'disapproval', 11: 'disgust', 12: 'embarrassment', 13: 'excitement', 14: 'fear', 15: 'gratitude', 16: 'grief', 17: 'joy', 18: 'love', 19: 'nervousness', 20: 'optimism', 21: 'pride', 22: 'realization', 23: 'relief', 24: 'remorse', 25: 'sadness', 26: 'surprise', 27: 'neutral'}\n"
     ]
    }
   ],
   "source": [
    "# construct mapping from id to label str\n",
    "label_str_list = emotion_ds.features[\"labels\"].feature.names\n",
    "label_mapping = {i: name for i, name in enumerate(label_str_list)}\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the dataset and save to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_huggingface_text_dataset(\n",
    "    dataset=emotion_ds,\n",
    "    text_key=\"text\",\n",
    "    label_key=\"labels\",\n",
    "    label_mapping=label_mapping,\n",
    "    output_csvpath=\"./emotion.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the data file created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>eebbqej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ed00q6i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>anger</td>\n",
       "      <td>eezlygj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>fear</td>\n",
       "      <td>ed7ypvh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>annoyance</td>\n",
       "      <td>ed0bdzj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      label       id\n",
       "0  My favourite food is anything I didn't have to...    neutral  eebbqej\n",
       "1  Now if he does off himself, everyone will thin...    neutral  ed00q6i\n",
       "2                     WHY THE FUCK IS BAYLESS ISOING      anger  eezlygj\n",
       "3                        To make her feel threatened       fear  ed7ypvh\n",
       "4                             Dirty Southern Wankers  annoyance  ed0bdzj"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./emotion.csv\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can load the file `./emotion.csv` into Cleanlab Studio, either using the Web Interface or Python API (see [Load Dataset](/studio/tutorials/cleanlab-studio-api/text_data_quickstart/#load-dataset-into-cleanlab-studio) for more details on the latter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensorflow datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we load the [IMDB Reviews](https://ai.stanford.edu/~amaas/data/sentiment/) dataset, which contains reviews classified as either positive or negative (**binary classification** data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_reviews, metadata = tfds.load(\n",
    "    \"imdb_reviews\", split=\"train\", with_info=True, as_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View few examples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-23 18:25:20.650895: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1cdb7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1cdb7_level0_col0\" class=\"col_heading level0 col0\" >label</th>\n",
       "      <th id=\"T_1cdb7_level0_col1\" class=\"col_heading level0 col1\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1cdb7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1cdb7_row0_col0\" class=\"data row0 col0\" >0 (neg)</td>\n",
       "      <td id=\"T_1cdb7_row0_col1\" class=\"data row0 col1\" >This was an absolutely terrible movie. Don&#x27;t be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie&#x27;s ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor&#x27;s like Christopher Walken&#x27;s good name. I could barely sit through it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cdb7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1cdb7_row1_col0\" class=\"data row1 col0\" >0 (neg)</td>\n",
       "      <td id=\"T_1cdb7_row1_col1\" class=\"data row1 col1\" >I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cdb7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1cdb7_row2_col0\" class=\"data row2 col0\" >0 (neg)</td>\n",
       "      <td id=\"T_1cdb7_row2_col1\" class=\"data row2 col1\" >Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. &lt;br /&gt;&lt;br /&gt;But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? &lt;br /&gt;&lt;br /&gt;Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.&lt;br /&gt;&lt;br /&gt;Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cdb7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_1cdb7_row3_col0\" class=\"data row3 col0\" >1 (pos)</td>\n",
       "      <td id=\"T_1cdb7_row3_col1\" class=\"data row3 col1\" >This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cdb7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_1cdb7_row4_col0\" class=\"data row4 col0\" >1 (pos)</td>\n",
       "      <td id=\"T_1cdb7_row4_col1\" class=\"data row4 col1\" >As others have mentioned, all the women that go nude in this film are mostly absolutely gorgeous. The plot very ably shows the hypocrisy of the female libido. When men are around they want to be pursued, but when no &quot;men&quot; are around, they become the pursuers of a 14 year old boy. And the boy becomes a man really fast (we should all be so lucky at this age!). He then gets up the courage to pursue his true love.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  b\"This was an absolutely terrible movie. Don't...\n",
       "1      0  b'I have been known to fall asleep during film...\n",
       "2      0  b'Mann photographs the Alberta Rocky Mountains...\n",
       "3      1  b'This is the kind of film for a snowy Sunday ...\n",
       "4      1  b'As others have mentioned, all the women that..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.as_dataframe(imdb_reviews.take(5), metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for formatting Tensorflow text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_tensorflow_text_dataset(\n",
    "    dataset, metadata, text_key, label_key, output_csvpath, label_mapping\n",
    "):\n",
    "    \"\"\"Convert a Tensorflow text dataset to a Studio file format.\n",
    "\n",
    "    dataset: tf.data.Dataset\n",
    "        Tensorflow text dataset\n",
    "    metadata: tfds.core.DatasetInfo\n",
    "        Info associated with dataset\n",
    "    text_key: str\n",
    "        column name for text in dataset\n",
    "    label_key: str\n",
    "        column name for label in dataset\n",
    "    label_mapping: Dict[str, int]\n",
    "        id to label str mapping\n",
    "        If labels are already strings, set label_mapping to None\n",
    "    output_csvpath: str\n",
    "        filepath to save csv file\n",
    "\n",
    "    \"\"\"\n",
    "    df = tfds.as_dataframe(dataset, metadata)\n",
    "\n",
    "    # Map integer labels to label strings, for example, 0 -> positive, 1 -> negative\n",
    "    if label_mapping:\n",
    "        df[label_key] = [label_mapping[label_id] for label_id in df[label_key]]\n",
    "\n",
    "    df = df.rename(columns={text_key: \"text\", label_key: \"label\"})\n",
    "\n",
    "    # Save to csv\n",
    "    df.to_csv(output_csvpath, index=False)\n",
    "    print(f\"Saved data file to {output_csvpath}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct mapping from id to label str\n",
    "label_str_list = metadata.features[\"label\"].names\n",
    "label_mapping = {i: label_str for i, label_str in enumerate(label_str_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the dataset and save to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_tensorflow_text_dataset(\n",
    "    dataset=imdb_reviews,\n",
    "    metadata=metadata,\n",
    "    text_key=\"text\",\n",
    "    label_key=\"label\",\n",
    "    label_mapping=label_mapping,\n",
    "    output_csvpath=\"./imdb_reviews.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the data file created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>b\"This was an absolutely terrible movie. Don't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>b'I have been known to fall asleep during film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>b'Mann photographs the Alberta Rocky Mountains...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>b'This is the kind of film for a snowy Sunday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>b'As others have mentioned, all the women that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   neg  b\"This was an absolutely terrible movie. Don't...\n",
       "1   neg  b'I have been known to fall asleep during film...\n",
       "2   neg  b'Mann photographs the Alberta Rocky Mountains...\n",
       "3   pos  b'This is the kind of film for a snowy Sunday ...\n",
       "4   pos  b'As others have mentioned, all the women that..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./imdb_reviews.csv\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can load the file `./imdb_reviews.csv` to Cleanlab Studio, either using the Web Interface or Python API (see [Load Dataset](/studio/tutorials/cleanlab-studio-api/text_data_quickstart/#load-dataset-into-cleanlab-studio) for more details on the latter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sklearn datasets\n",
    "\n",
    "### Install the scikit-learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we load the 20 newsgroups dataset which consists of 18000 newsgroups text posts categorized amongst 20 possible topics, split into train and test sets (**multi-class text classification** dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Load the dataset\n",
    "newsgroups_train = fetch_20newsgroups(subset=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the text and label from the `data` and `target` attributes of the dataset. Let's view an example from the dataset and its corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Label: {newsgroups_train.target[0]}\")\n",
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to view the label names corresponding to integers, we can use the `target_names` attribute of the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first 5 categories\n",
    "newsgroups_train.target_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for formatting sklearn text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sklearn_text_dataset(dataset, output_csvpath, label_mapping):\n",
    "    \"\"\"Convert a sklearn text dataset to a Studio file format.\n",
    "\n",
    "    dataset: sklearn.utils.Bunch\n",
    "        sklearn text dataset\n",
    "    label_mapping: Dict[str, int]\n",
    "        id to label str mapping\n",
    "        If labels are already strings, set label_mapping to None\n",
    "    output_csvpath: str\n",
    "        filepath to save csv file\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Map integer labels to label strings, for example, 0 -> positive, 1 -> negative\n",
    "    if label_mapping:\n",
    "        label_col = [label_mapping[label_id] for label_id in dataset.target]\n",
    "    else:\n",
    "        label_col = dataset.target\n",
    "\n",
    "    df = pd.DataFrame({\"text\": dataset.data, \"label\": label_col})\n",
    "\n",
    "    # Save to csv\n",
    "    df.to_csv(output_csvpath, index=False)\n",
    "    print(f\"Saved data file to {output_csvpath}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct mapping from id to label str\n",
    "label_mapping = {\n",
    "    i: labe_str for i, labe_str in enumerate(newsgroups_train.target_names)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the dataset and save to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_sklearn_text_dataset(newsgroups_train, \"./newsgroups_train.csv\", label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the data file created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                  label\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...              rec.autos\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  comp.sys.mac.hardware\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...  comp.sys.mac.hardware\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...          comp.graphics\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...              sci.space"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./newsgroups_train.csv\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can load the file `./newsgroups_train.csv` to Cleanlab Studio, either using the Web Interface or Python API (see [Load Dataset](/studio/tutorials/cleanlab-studio-api/text_data_quickstart/#load-dataset-into-cleanlab-studio) for more details on the latter)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}