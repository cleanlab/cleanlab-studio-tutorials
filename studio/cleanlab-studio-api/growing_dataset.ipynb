{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTabL3Qsj0PH"
   },
   "source": [
    "# Catching Issues in a Dynamically Growing Dataset\n",
    "\n",
    "This is the recommended tutorial for programatically auditing datasets that grow over time with the Cleanlab Studio [Python API](/studio/quickstart/api/).\n",
    "\n",
    "In this tutorial, we consider data that comes in batches accumulated into a master dataset. While one could follow the other tutorials to use Cleanlab to auto-detect issues across the\u00a0entire master dataset, here we demonstrate how to catch issues in the most recent batch of data. We additionally demonstrate how to fix issues in the latest data batch, in order to create a higher-quality master dataset.\n",
    "\n",
    "While this tutorial focuses specifically on label issues for brevity, the same ideas can be applied to catch any of the other data issues Cleanlab Studio can auto-detect (outliers, near duplicates, unsafe or low-quality content, ...). This tutorial focuses on text data, but the same ideas can be applied to the other data modalities Cleanlab Studio supports such as images or structured/tabular data. We recommend first completing our [text data quickstart tutorial](/studio/tutorials/cleanlab-studio-api/text_data_quickstart/) to first understand how Cleanlab Studio works with a static dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caOwD-Fsj0PO"
   },
   "source": [
    "## Install and import dependencies\n",
    "\n",
    "Make sure you have `wget` installed to run this tutorial. You can use pip to install all other packages required for this tutorial as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bo4d-uiZj0PQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install cleanlab-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8p24kW4kj0PS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-IQne0mj0PT"
   },
   "source": [
    "## Fetch and view dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nv3hZf35j0PT"
   },
   "source": [
    "Here we use a variant of the [BANKING77](https://paperswithcode.com/dataset/banking77-oos) text classification dataset, in which customer service request are labeled as belonging to one of *K* classes (intent categories). To fetch the dataset for this tutorial, make sure you have `wget` and `zip` installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rT-UReATj0PU"
   },
   "outputs": [],
   "source": [
    "!mkdir -p data/\n",
    "!wget -nc https://cleanlab-public.s3.amazonaws.com/Datasets/growing_dataset.zip -O data/growing_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ss72nAYsErBe"
   },
   "outputs": [],
   "source": [
    "!unzip -q data/growing_dataset.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzRrYA41tFyz"
   },
   "source": [
    "This data is stored amongst 3 unequal batches, which will be received incrementally in this tutorial. Batch 3 contains **1 class** that was not seen in batches 1 or 2, to help you handle applications where certain dataset classes might appear or disappear over time. Let's load the first batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZLJe1ZGMj0PW"
   },
   "outputs": [],
   "source": [
    "BASE_PATH = os.getcwd()\n",
    "dataset_path = os.path.join(BASE_PATH, \"data/growing_dataset\")\n",
    "\n",
    "batch_1 = pd.read_csv(os.path.join(dataset_path, \"data_batch1.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7iWIa7TPQvC"
   },
   "source": [
    "### Ensure unique identifier for data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARQ7SeaTPbdn"
   },
   "source": [
    "For a dynamic dataset, having a unique identifier for each data point allows us to better track results.\n",
    "The current dataset has two columns - `text` and `label` - both of which cannot be used to identify a unique row.\n",
    "\n",
    "We can add a column `id` that would just contain sequential numbers, starting from 0 to batch size - 1. For the subsequent batches, we\"ll start from previous batch's size to the total size of the merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FPARVziHbQNz",
    "outputId": "7fa79f85-7052-40f3-ba96-c36984ccc017"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why is there a fee when i thought there would be no fees?</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why can't my beneficiary access my account?</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>does it cost extra to send out more than one card?</td>\n",
       "      <td>getting_spare_card</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can i change my pin at an atm?</td>\n",
       "      <td>change_pin</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have a us credit card, will you accept it?</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text   \n",
       "0  why is there a fee when i thought there would be no fees?  \\\n",
       "1                why can't my beneficiary access my account?   \n",
       "2         does it cost extra to send out more than one card?   \n",
       "3                             can i change my pin at an atm?   \n",
       "4               i have a us credit card, will you accept it?   \n",
       "\n",
       "                            label  id  \n",
       "0        card_payment_fee_charged   0  \n",
       "1         beneficiary_not_allowed   1  \n",
       "2              getting_spare_card   2  \n",
       "3                      change_pin   3  \n",
       "4  supported_cards_and_currencies   4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column and assign sequential numbers till batch size\n",
    "batch_1[\"id\"] = range(0, len(batch_1))\n",
    "\n",
    "batch_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0D4a9epHUlS",
    "outputId": "5806411d-2b01-4491-d548-27bf48af3cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of rows in the current dataset: 500\n"
     ]
    }
   ],
   "source": [
    "print(f\"The total number of rows in the current dataset: {len(batch_1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-MifGmbj0PZ"
   },
   "source": [
    "## Load batch 1 into Cleanlab Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kbrclvvjj0PZ"
   },
   "source": [
    "Upon receiving our batch\u00a0of data, let's load it into Cleanlab Studio for analysis. First use your API key to instantiate a `Studio` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wWTWUmxTj0PZ"
   },
   "outputs": [],
   "source": [
    "from cleanlab_studio import Studio\n",
    "\n",
    "# You can find your Cleanlab Studio API key by going to studio.cleanlab.ai/upload,\n",
    "# clicking \"Upload via Python API\", and copying the API key there\n",
    "API_KEY = \"<insert your API key>\"\n",
    "\n",
    "studio = Studio(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XQg_8iCj0Pa"
   },
   "source": [
    "Load the data from batch 1\n",
    "into Cleanlab Studio. More details on formatting datasets can be found in [this guide](/studio/concepts/datasets/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bLApnPMj0Pa"
   },
   "outputs": [],
   "source": [
    "dataset_id = studio.upload_dataset(batch_1, dataset_name=\"data-batch-1\")\n",
    "print(f\"Dataset ID: {dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR9NkGufj0Pa"
   },
   "source": [
    "### Launch a Project\n",
    "\n",
    "A Cleanlab Studio Project automatically trains ML models to provide AI-based analysis of your dataset. Let's launch one for the data we have received so far.\n",
    "\n",
    "**Note**: For our `label_column` and `text_column` specified below, they happened to be called `label` and `text` for this example. The values for these arguments should be the name of the columns pertaining to your label and containing the text field in your dataset. If you have multiple text columns, please merge them into a single column as demonstrated in our [FAQ](/studio/FAQ/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Rf5MrlpO0GXI"
   },
   "outputs": [],
   "source": [
    "label_column = \"label\"  # name of column containing labels\n",
    "text_column = \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_q860dwj0Pa"
   },
   "outputs": [],
   "source": [
    "project_id = studio.create_project(\n",
    "    dataset_id=dataset_id,\n",
    "    project_name=\"batch-1-analysis\",\n",
    "    modality=\"text\",\n",
    "    task_type=\"multi-class\",\n",
    "    model_type=\"regular\",  # set this to \"fast\" if time-constrained\n",
    "    label_column=label_column,\n",
    "    text_column=text_column\n",
    ")\n",
    "print(f\"Project successfully created and training has begun! project_id: {project_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHlWS1SQj0Pa"
   },
   "source": [
    "Once the project has been launched successfully and the `project_id` is visible, feel free to close this notebook. It will take some time for Cleanlab\u2019s AI to train models on this data and analyze it. Come back after training is complete (you will receive an email) and continue with the notebook to review your results. The training for this example would take approximately 10 minutes.\n",
    "\n",
    "You should only execute the above cell once per data batch.  After launching the project, you can poll for its status to programmatically wait until the results are ready for review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XBSJdRLj0Pb"
   },
   "outputs": [],
   "source": [
    "# Fetch the cleanset id corresponding to the above project_id\n",
    "cleanset_id = studio.get_latest_cleanset_id(project_id)\n",
    "print(f\"cleanset_id: {cleanset_id}\")\n",
    "project_status = studio.wait_until_cleanset_ready(cleanset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQodxhEMmYOE"
   },
   "source": [
    "If your notebook timed out, you can resume by re-running the above lines of code. **Do not** create a new project for the same batch when coming back to this notebook. When the project is complete, the resulting [cleanset](/studio/concepts/cleanset) contains many Cleanlab columns of metadata that can be used to produce an **clean**er version of our original data**set**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArmrxE-Fj0Pc"
   },
   "source": [
    "### Review issues detected in batch 1\n",
    "\n",
    "Fetch the [Cleanlab columns](/studio/concepts/cleanlab_columns/) of metadata for this [cleanset](/studio/concepts/cleanset) using its `cleanset_id`. These columns have the same length as our original data batch  and provide metadata about each individual data point, like what types of issues it exhibits and how severely.\n",
    "\n",
    "If at any point you want to re-run the remaining parts of this notebook (without creating another Project), simply call `studio.download_cleanlab_columns(cleanset_id)` with the `cleanset_id` printed from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "W1-oxv09j0Pc",
    "outputId": "46f54bee-c6b4-4bc9-b5fe-01e642047288"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanlab_row_ID</th>\n",
       "      <th>corrected_label</th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>label_issue_score</th>\n",
       "      <th>suggested_label</th>\n",
       "      <th>suggested_label_confidence_score</th>\n",
       "      <th>is_ambiguous</th>\n",
       "      <th>ambiguous_score</th>\n",
       "      <th>is_well_labeled</th>\n",
       "      <th>is_near_duplicate</th>\n",
       "      <th>...</th>\n",
       "      <th>non_english_score</th>\n",
       "      <th>predicted_language</th>\n",
       "      <th>is_toxic</th>\n",
       "      <th>toxic_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>bias_score</th>\n",
       "      <th>is_biased</th>\n",
       "      <th>gender_bias_score</th>\n",
       "      <th>racial_bias_score</th>\n",
       "      <th>sexual_orientation_bias_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.311937</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.477899</td>\n",
       "      <td>False</td>\n",
       "      <td>0.946097</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.181641</td>\n",
       "      <td>0.134277</td>\n",
       "      <td>0.394824</td>\n",
       "      <td>False</td>\n",
       "      <td>0.394824</td>\n",
       "      <td>0.232544</td>\n",
       "      <td>0.146484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.254897</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.565403</td>\n",
       "      <td>False</td>\n",
       "      <td>0.893302</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008784</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.062164</td>\n",
       "      <td>0.159088</td>\n",
       "      <td>0.259082</td>\n",
       "      <td>False</td>\n",
       "      <td>0.259082</td>\n",
       "      <td>0.093933</td>\n",
       "      <td>0.024902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.494578</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.230432</td>\n",
       "      <td>False</td>\n",
       "      <td>0.968427</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.184692</td>\n",
       "      <td>0.377869</td>\n",
       "      <td>0.244189</td>\n",
       "      <td>False</td>\n",
       "      <td>0.244189</td>\n",
       "      <td>0.131470</td>\n",
       "      <td>0.013443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.353640</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.411544</td>\n",
       "      <td>False</td>\n",
       "      <td>0.921234</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058934</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.120056</td>\n",
       "      <td>0.543640</td>\n",
       "      <td>0.379687</td>\n",
       "      <td>False</td>\n",
       "      <td>0.379687</td>\n",
       "      <td>0.112732</td>\n",
       "      <td>0.013229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333641</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.441447</td>\n",
       "      <td>False</td>\n",
       "      <td>0.892788</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008220</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.573120</td>\n",
       "      <td>0.161621</td>\n",
       "      <td>False</td>\n",
       "      <td>0.146045</td>\n",
       "      <td>0.161621</td>\n",
       "      <td>0.002678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cleanlab_row_ID corrected_label  is_label_issue  label_issue_score   \n",
       "0                1            <NA>           False           0.311937  \\\n",
       "1                2            <NA>           False           0.254897   \n",
       "2                3            <NA>           False           0.494578   \n",
       "3                4            <NA>           False           0.353640   \n",
       "4                5            <NA>           False           0.333641   \n",
       "\n",
       "  suggested_label  suggested_label_confidence_score  is_ambiguous   \n",
       "0            <NA>                          0.477899         False  \\\n",
       "1            <NA>                          0.565403         False   \n",
       "2            <NA>                          0.230432         False   \n",
       "3            <NA>                          0.411544         False   \n",
       "4            <NA>                          0.441447         False   \n",
       "\n",
       "   ambiguous_score  is_well_labeled  is_near_duplicate  ...   \n",
       "0         0.946097             True              False  ...  \\\n",
       "1         0.893302             True              False  ...   \n",
       "2         0.968427            False              False  ...   \n",
       "3         0.921234             True              False  ...   \n",
       "4         0.892788             True              False  ...   \n",
       "\n",
       "   non_english_score  predicted_language  is_toxic  toxic_score   \n",
       "0           0.007218                <NA>     False     0.181641  \\\n",
       "1           0.008784                <NA>     False     0.062164   \n",
       "2           0.004739                <NA>     False     0.184692   \n",
       "3           0.058934                <NA>     False     0.120056   \n",
       "4           0.008220                <NA>     False     0.107422   \n",
       "\n",
       "   sentiment_score  bias_score  is_biased  gender_bias_score   \n",
       "0         0.134277    0.394824      False           0.394824  \\\n",
       "1         0.159088    0.259082      False           0.259082   \n",
       "2         0.377869    0.244189      False           0.244189   \n",
       "3         0.543640    0.379687      False           0.379687   \n",
       "4         0.573120    0.161621      False           0.146045   \n",
       "\n",
       "   racial_bias_score  sexual_orientation_bias_score  \n",
       "0           0.232544                       0.146484  \n",
       "1           0.093933                       0.024902  \n",
       "2           0.131470                       0.013443  \n",
       "3           0.112732                       0.013229  \n",
       "4           0.161621                       0.002678  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanlab_columns_df = studio.download_cleanlab_columns(cleanset_id)\n",
    "cleanlab_columns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVP5vlO9j0Pc"
   },
   "source": [
    "Details about the Cleanlab columns and their meanings can be found in [the Cleanlab columns guide](/studio/concepts/cleanlab_columns/).\n",
    "\n",
    "In this tutorial, we focus on label issues only.  The ideas demonstrated here can be used for other types of data issues\u00a0that Cleanlab Studio auto-detects.\n",
    "\n",
    "A data point flagged with a **label issue** likely has a wrong given label. For such data points, consider correcting their label to the `suggested_label` if it seems more appropriate.\n",
    "\n",
    "The data points exhibiting this issue are indicated with boolean values in the `is_label_issue` column, and the severity of this issue in each data point is quantified in the `label_issue_score` column (on a scale of 0-1 with 1 indicating the most severe instances of the issue).\n",
    "\n",
    "Let's create a `given_label` column in our dataframe to clearly indicate the class label originally assigned to each data point (customer service request)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Zc24u-5Dj0Pd"
   },
   "outputs": [],
   "source": [
    "# Copy data into a new DataFrame\n",
    "df1 = batch_1.copy()\n",
    "\n",
    "# Combine the dataset with cleanlab columns\n",
    "merge_df_cleanlab = df1.merge(cleanlab_columns_df, left_index=True, right_index=True)\n",
    "\n",
    "# Rename label column to \"given_label\"\n",
    "merge_df_cleanlab.rename(columns={\"label\": \"given_label\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZ_y_0y5j0Pd"
   },
   "source": [
    "To see which data points are estimated to be mislabeled, we filter by `is_label_issue`. We sort by `label_issue_score` to see which of these data points are *most likely* mislabeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "abOnI-LAY4iz",
    "outputId": "eef7dda5-f7db-4237-c5e3-7c71edaac5b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_issue_score</th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>can i change my pin on holiday?</td>\n",
       "      <td>0.706490</td>\n",
       "      <td>True</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>459</td>\n",
       "      <td>will i be sent a new card before mine expires?</td>\n",
       "      <td>0.665202</td>\n",
       "      <td>True</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>my card is almost expired.  how fast will i get a new one and what is the cost?</td>\n",
       "      <td>0.656704</td>\n",
       "      <td>True</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>is it possible to change my pin?</td>\n",
       "      <td>0.648337</td>\n",
       "      <td>True</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>160</td>\n",
       "      <td>p</td>\n",
       "      <td>0.605484</td>\n",
       "      <td>True</td>\n",
       "      <td>getting_spare_card</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>can i get a new card even though i am in china?</td>\n",
       "      <td>0.575734</td>\n",
       "      <td>True</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>what currencies does google pay top up accept?</td>\n",
       "      <td>0.557280</td>\n",
       "      <td>True</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>369</td>\n",
       "      <td>do i need to verify my top-up card?</td>\n",
       "      <td>0.527742</td>\n",
       "      <td>True</td>\n",
       "      <td>getting_spare_card</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   \n",
       "7      7  \\\n",
       "459  459   \n",
       "117  117   \n",
       "54    54   \n",
       "160  160   \n",
       "115  115   \n",
       "119  119   \n",
       "369  369   \n",
       "\n",
       "                                                                                text   \n",
       "7                                                    can i change my pin on holiday?  \\\n",
       "459                                   will i be sent a new card before mine expires?   \n",
       "117  my card is almost expired.  how fast will i get a new one and what is the cost?   \n",
       "54                                                  is it possible to change my pin?   \n",
       "160                                                                                p   \n",
       "115                                  can i get a new card even though i am in china?   \n",
       "119                                   what currencies does google pay top up accept?   \n",
       "369                                              do i need to verify my top-up card?   \n",
       "\n",
       "     label_issue_score  is_label_issue              given_label   \n",
       "7             0.706490            True  beneficiary_not_allowed  \\\n",
       "459           0.665202            True  apple_pay_or_google_pay   \n",
       "117           0.656704            True  apple_pay_or_google_pay   \n",
       "54            0.648337            True  beneficiary_not_allowed   \n",
       "160           0.605484            True       getting_spare_card   \n",
       "115           0.575734            True  apple_pay_or_google_pay   \n",
       "119           0.557280            True  apple_pay_or_google_pay   \n",
       "369           0.527742            True       getting_spare_card   \n",
       "\n",
       "                    suggested_label  \n",
       "7                        change_pin  \n",
       "459            card_about_to_expire  \n",
       "117            card_about_to_expire  \n",
       "54                       change_pin  \n",
       "160  supported_cards_and_currencies  \n",
       "115            card_about_to_expire  \n",
       "119  supported_cards_and_currencies  \n",
       "369         apple_pay_or_google_pay  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_issues = merge_df_cleanlab.query(\"is_label_issue\", engine=\"python\").sort_values(\"label_issue_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"id\", \"text\", \"label_issue_score\", \"is_label_issue\", \"given_label\", \"suggested_label\"]\n",
    "\n",
    "display(label_issues[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtQKtxopj0Pd"
   },
   "source": [
    "Note that in most of these rows, the `given_label` really does seem wrong (the annotated intent in the original dataset does not appear appropriate for the customer request), except the rows which have a label issue score less than 0.7. Luckily we can easily correct these data points by just using Cleanlab's `suggested_label` above, which seems like a more appropriate label in most cases.\n",
    "\n",
    "While the boolean flags above help us estimate the overall label error rate, the numeric scores help decide what data to prioritize for review. In this tutorial, we use a threshold on `label_issue_score` to select which data points to fix, excluding the rest of the data points which doesn't meet the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcVz__pjj0P3"
   },
   "source": [
    "### Improve batch 1 data based on the detected issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZSDT8Yqj0P3"
   },
   "source": [
    "Let's use the Cleanlab columns to improve the quality of our dataset. For your own datasets, which actions you should take to remedy the detected issues will depend on what you are using the data for. No action may be the best choice for certain datasets, we caution against blindly copying the actions we perform here.\n",
    "\n",
    "For data flagged as label issues, we create a new `corrected_label` column, which will be the `given_label` for data points without detected label issues, and the `suggested_label` for data points with detected label issues. We  use a `label_issue_score` threshold of 0.7 to determine which data points to re-label. The remaining data points flagged as label issues will be excluded from the dataset to avoid potential contamination.\n",
    "\n",
    "Throughout, we track all of the rows we fixed (re-labeled) or excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9FiBHxk2j0P3",
    "outputId": "d46827cb-c1fd-44ba-b077-c462031097f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding 7 text examples (out of 500)\n"
     ]
    }
   ],
   "source": [
    "# Set issue score threshold\n",
    "label_threshold = 0.70\n",
    "\n",
    "# DataFrame to track excluded rows\n",
    "threshold_filtered_rows = label_issues.query(\"label_issue_score < @label_threshold\")\n",
    "\n",
    "# Find indices of rows to exclude\n",
    "ids_to_exclude1 = threshold_filtered_rows[\"id\"]\n",
    "indices_to_exclude1 = merge_df_cleanlab.query(\"id in @ids_to_exclude1\").index\n",
    "\n",
    "print(f\"Excluding {len(threshold_filtered_rows)} text examples (out of {len(merge_df_cleanlab)})\")\n",
    "\n",
    "# Drop rows from the merge DataFrame\n",
    "merge_df_cleanlab = merge_df_cleanlab.drop(indices_to_exclude1)\n",
    "\n",
    "corrected_label = np.where(merge_df_cleanlab[\"is_label_issue\"],\n",
    "                           merge_df_cleanlab[\"suggested_label\"],\n",
    "                           merge_df_cleanlab[\"given_label\"])\n",
    "\n",
    "# DataFrame to track fixed (re-labeled) rows\n",
    "label_issues_fixed_rows = merge_df_cleanlab.query(\"is_label_issue\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CioJ4r2Dj0P5"
   },
   "source": [
    "Let's make a cleaned version of the batch 1 data after applying these corrections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XdbAIEPrmQ9h"
   },
   "outputs": [],
   "source": [
    "fixed_batch_1 = merge_df_cleanlab[[\"text\", \"id\"]].copy()\n",
    "fixed_batch_1[\"label\"] = corrected_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huXuDvG0M2gY"
   },
   "source": [
    "Let's also initialize our curated master dataset, a single DataFrame to store the clean data points accumulated across all the data batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "utN78KMfNLGz"
   },
   "outputs": [],
   "source": [
    "fixed_dataset = pd.DataFrame(columns=[\"text\", \"label\", \"id\"])\n",
    "fixed_dataset = pd.concat([fixed_dataset, fixed_batch_1], ignore_index=True)  # add clean data from batch 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85tGziIHTgpW"
   },
   "source": [
    "Perfect! Now let's grow our master dataset after recieving the data from batch 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crQA6RflIZRm"
   },
   "source": [
    "## Adding a second batch of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INST49avIZR3"
   },
   "source": [
    "Our `fixed_dataset` currently contains the cleaned version of our first data batch. Suppose now we've collected a second batch of data, which consists of 300 rows, that we wish to add to this master fixed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SVHQ8JEmP42T"
   },
   "outputs": [],
   "source": [
    "batch_2 = pd.read_csv(os.path.join(dataset_path, \"data_batch2.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7J68VFtHBYdx"
   },
   "source": [
    "We will again add a unique identifier `id` which would start from the last id of batch 1 i.e. the size of batch 1 (500), till the size of batch 1 + batch 2 (800)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zBTSWSlRBYKG"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i received my american express in apple pay, why is top up not working?</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i want to change my pin - do i need to be in a bank?</td>\n",
       "      <td>change_pin</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i want to use a payment card to top up my account. how can i do this?</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i would like to give another card to my daughter, how can i proceed?</td>\n",
       "      <td>getting_spare_card</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is there a location where i can change my pin?</td>\n",
       "      <td>change_pin</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      text   \n",
       "0  i received my american express in apple pay, why is top up not working?  \\\n",
       "1                     i want to change my pin - do i need to be in a bank?   \n",
       "2    i want to use a payment card to top up my account. how can i do this?   \n",
       "3     i would like to give another card to my daughter, how can i proceed?   \n",
       "4                           is there a location where i can change my pin?   \n",
       "\n",
       "                            label   id  \n",
       "0         apple_pay_or_google_pay  500  \n",
       "1                      change_pin  501  \n",
       "2  supported_cards_and_currencies  502  \n",
       "3              getting_spare_card  503  \n",
       "4                      change_pin  504  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rows = len(batch_1) + len(batch_2)\n",
    "batch_2[\"id\"] = range(len(batch_1), total_rows)\n",
    "batch_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VJ33p2hHIH4"
   },
   "source": [
    "Let's first check what class labels are present in this second batch of data. We define a helper function to compare the unique values of the `label` column against our previously observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049e171-5b37-44af-b5f3-95fb8a3a50de",
   "metadata": {},
   "source": [
    "**Optional: Initialize helper method to compare classes**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "et0CMrTgHHbo"
   },
   "outputs": [],
   "source": [
    "\n",
    "def compare_classes(new_data, historical_data, label_column):\n",
    "    historical_data_classes = set(historical_data[label_column])\n",
    "    new_batch_classes = set(new_data[label_column])\n",
    "    if len(historical_data_classes.difference(new_batch_classes)) > 0:\n",
    "        print(f\"New batch has no data points from the following classes: {historical_data_classes.difference(new_batch_classes)}\")\n",
    "    if len(new_batch_classes.difference(historical_data_classes)) > 0:\n",
    "        print(f\"New batch has data points from previously unseen classes: {new_batch_classes.difference(historical_data_classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nFqCCS8EIAun",
    "outputId": "81bb34a7-10ef-4212-c91e-55b9e9195be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New batch has no data points from the following classes: {'lost_or_stolen_phone'}\n"
     ]
    }
   ],
   "source": [
    "compare_classes(batch_2, fixed_dataset, label_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFdmICRHmYOr"
   },
   "source": [
    "Here we don't act on this information, but such information may be concerning depending on your application.\n",
    "\n",
    "We'll repeat the Cleanlab Studio steps that we previously performed for our first data batch, this time on a larger dataset composed of our clean historical data plus the newest data batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cRRnoIqRIZR3"
   },
   "outputs": [],
   "source": [
    "batch_1_2 = pd.concat([fixed_dataset, batch_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhaMMXdWs3DX"
   },
   "source": [
    "### Load dataset, launch Project, and get Cleanlab columns\n",
    "\n",
    "Again: if your notebook times out during any of the following steps, you likely don't need to re-run that step (re-running the step may take a long time again). Instead try to run the next step after restarting your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRVyEcaDOCpz"
   },
   "outputs": [],
   "source": [
    "dataset_id = studio.upload_dataset(batch_1_2, dataset_name=\"data-batch-1-2\")\n",
    "print(f\"Dataset ID: {dataset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ouLGSMU6Oys5"
   },
   "outputs": [],
   "source": [
    "project_id = studio.create_project(\n",
    "    dataset_id=dataset_id,\n",
    "    project_name=\"batch-1-2-analysis\",\n",
    "    modality=\"text\",\n",
    "    task_type=\"multi-class\",\n",
    "    model_type=\"regular\",\n",
    "    label_column=label_column,\n",
    "    text_column=text_column\n",
    ")\n",
    "print(f\"Project successfully created and training has begun! project_id: {project_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTMvjjDgPxYF"
   },
   "outputs": [],
   "source": [
    "cleanset_id = studio.get_latest_cleanset_id(project_id)\n",
    "print(f\"cleanset_id: {cleanset_id}\")\n",
    "project_status = studio.wait_until_cleanset_ready(cleanset_id)\n",
    "cleanlab_columns_df = studio.download_cleanlab_columns(cleanset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdRgLQzhtVuL"
   },
   "source": [
    "### Review issues detected in batch 2\n",
    "\n",
    "Similar to how we reviewed the label issues detected in batch 1 data, here we will focus on the label issues detected in the newest (second) batch of data. Note that our Project analyzed this batch of data together with the clean historical data, as more data allows Cleanlab's AI to more accurately detect data issues. As before, the first step toward reviewing results is to merge the Cleanlab columns with the dataset that the Project was run on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "TBB_zwGv_Pou"
   },
   "outputs": [],
   "source": [
    "df2 = batch_1_2.copy()\n",
    "merge_df_cleanlab = df2.merge(cleanlab_columns_df, left_index=True, right_index=True)\n",
    "merge_df_cleanlab.rename(columns={\"label\": \"given_label\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DT9WCqXXBRkY"
   },
   "source": [
    "The current `merge_df_cleanlab` dataset consists of both the cleaned historical data (from batch 1) and the raw batch 2 data. Here we demonstrate how to focus on catching label issues in the new (batch 2) data only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "d9ajFLgUZ0P4",
    "outputId": "b2ba215d-0ac7-4a34-de27-de1b02735c41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_issue_score</th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>749</td>\n",
       "      <td>why am i being charge a fee when using an atm?</td>\n",
       "      <td>0.789770</td>\n",
       "      <td>True</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>693</td>\n",
       "      <td>what atms will allow me to change my pin?</td>\n",
       "      <td>0.716286</td>\n",
       "      <td>True</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>795</td>\n",
       "      <td>what services can i use to top up?</td>\n",
       "      <td>0.676584</td>\n",
       "      <td>True</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>659</td>\n",
       "      <td>why do i see extra charges for withdrawing my money?</td>\n",
       "      <td>0.672628</td>\n",
       "      <td>True</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>594</td>\n",
       "      <td>bad bank</td>\n",
       "      <td>0.601791</td>\n",
       "      <td>True</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                                  text   \n",
       "742  749        why am i being charge a fee when using an atm?  \\\n",
       "686  693             what atms will allow me to change my pin?   \n",
       "788  795                    what services can i use to top up?   \n",
       "652  659  why do i see extra charges for withdrawing my money?   \n",
       "587  594                                              bad bank   \n",
       "\n",
       "     label_issue_score  is_label_issue              given_label   \n",
       "742           0.789770            True     card_about_to_expire  \\\n",
       "686           0.716286            True  beneficiary_not_allowed   \n",
       "788           0.676584            True  apple_pay_or_google_pay   \n",
       "652           0.672628            True     card_about_to_expire   \n",
       "587           0.601791            True  apple_pay_or_google_pay   \n",
       "\n",
       "                    suggested_label  \n",
       "742        card_payment_fee_charged  \n",
       "686                      change_pin  \n",
       "788  supported_cards_and_currencies  \n",
       "652        card_payment_fee_charged  \n",
       "587  supported_cards_and_currencies  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use identifier to create an array of batch-2 id's\n",
    "ids_of_batch_2 = batch_2[\"id\"]\n",
    "# Isolate batch-2 data from the merged dataset\n",
    "batch_2_subset = merge_df_cleanlab.query(\"id in @ids_of_batch_2\", engine=\"python\")\n",
    "# Get batch 2 rows flagged as label issues\n",
    "label_issues = batch_2_subset.query(\"is_label_issue\", engine=\"python\").sort_values(\"label_issue_score\", ascending=False)\n",
    "\n",
    "display(label_issues[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFWf4hajvJq9"
   },
   "source": [
    "### Improve batch 2 data based on the detected issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYvT7AqOzb8_"
   },
   "source": [
    "Assume we are in working with a production data pipeline where fixing issues in the most recent batch of data is highest priority. Just as before, we can apply the same strategy to clean the batch 2 data (re-label the flagged data points with `label_issue_score` above the same threshold and exclude the rest of the label issues from the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ibm2156z9XNH",
    "outputId": "724a2f85-2d46-4014-9dd5-6a64d2925e2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding 3 text example(s) (out of 300 from batch-2)\n"
     ]
    }
   ],
   "source": [
    "# Keep track of excluded rows\n",
    "issues_below_threshold = label_issues.query(\"label_issue_score < @label_threshold\", engine=\"python\")\n",
    "\n",
    "threshold_filtered_rows = pd.concat([issues_below_threshold, threshold_filtered_rows])\n",
    "\n",
    "# Find indices of rows to exclude\n",
    "ids_to_exclude2 = issues_below_threshold[\"id\"]\n",
    "indices_to_exclude2 = batch_2_subset.query(\"id in @ids_to_exclude2\", engine=\"python\").index\n",
    "\n",
    "print(f\"Excluding {len(ids_to_exclude2)} text example(s) (out of {len(batch_2_subset)} from batch-2)\")\n",
    "\n",
    "# Drop rows from the batch-2 subset\n",
    "batch_2_subset = batch_2_subset.drop(indices_to_exclude2)\n",
    "\n",
    "corrected_label = np.where(batch_2_subset[\"is_label_issue\"],\n",
    "                           batch_2_subset[\"suggested_label\"],\n",
    "                           batch_2_subset[\"given_label\"])\n",
    "\n",
    "# Keep track of fixed rows\n",
    "label_issues_fixed_rows = pd.concat([label_issues_fixed_rows, batch_2_subset.query(\"is_label_issue\", engine=\"python\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiGbG3ZADwXA"
   },
   "source": [
    "Applying these corrections produces a cleaned version of the batch 2 data.\n",
    "We add this cleaned batch 2 data to our master fixed dataset (which up to this point contained the cleaned batch 1 data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "rfgS6BPBDwXG"
   },
   "outputs": [],
   "source": [
    "fixed_batch_2 = batch_2_subset[[\"text\", \"id\"]].copy()\n",
    "fixed_batch_2[\"label\"] = corrected_label\n",
    "fixed_dataset = pd.concat([fixed_dataset, fixed_batch_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOh_oqKs8eJo"
   },
   "source": [
    "Awesome! We have grown our master dataset with the additional data being collected, while still ensuring this dataset is clean and free of label issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAh7t9Pt-jRL"
   },
   "source": [
    "## Adding another batch of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB7LQSM9-21Z"
   },
   "source": [
    "Finally, let's clean and then add another batch of newly collected data (200 rows) to our master dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "h0nLkVcPFP8F"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i need to cancel my recent transfer as soon as possible. i made an error there. please help before it goes through.</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i need help as fast as possible! i made a mistake on my most recent transfer; can you please stop it before it goes through?</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i already made a transfer and want to cancel it, how do i do that?</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i just realised i made the wrong payment yesterday. can you please change it to the right account? it's my rent payment and really really needs to be in the right account by tomorrow</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi, i made a transfer yesterday that i need to reverse.  i need to put the money in a different account.</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                     text   \n",
       "0                                                                     i need to cancel my recent transfer as soon as possible. i made an error there. please help before it goes through.  \\\n",
       "1                                                            i need help as fast as possible! i made a mistake on my most recent transfer; can you please stop it before it goes through?   \n",
       "2                                                                                                                      i already made a transfer and want to cancel it, how do i do that?   \n",
       "3  i just realised i made the wrong payment yesterday. can you please change it to the right account? it's my rent payment and really really needs to be in the right account by tomorrow   \n",
       "4                                                                                hi, i made a transfer yesterday that i need to reverse.  i need to put the money in a different account.   \n",
       "\n",
       "             label   id  \n",
       "0  cancel_transfer  800  \n",
       "1  cancel_transfer  801  \n",
       "2  cancel_transfer  802  \n",
       "3  cancel_transfer  803  \n",
       "4  cancel_transfer  804  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_3 = pd.read_csv(os.path.join(dataset_path, \"data_batch3.csv\"))\n",
    "\n",
    "# Create an id column for unique identification of rows\n",
    "total_rows = total_rows + len(batch_3)\n",
    "batch_3[\"id\"] = range(len(batch_1) + len(batch_2), total_rows)\n",
    "batch_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_Jw9IHAdIJr"
   },
   "source": [
    "Let's first check what class labels are present in this third batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-ep0apQdNft",
    "outputId": "5fff84d6-9138-402f-89a1-27be84e1797f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New batch has data points from previously unseen classes: {'cancel_transfer'}\n"
     ]
    }
   ],
   "source": [
    "compare_classes(batch_3, fixed_dataset, label_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OujQWPNFmYPA"
   },
   "source": [
    "Here we don't act on this information, but it may be a concern depending on your application. We repeat the Cleanlab Studio related steps that we performed before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "xjZPPwrr-21Z"
   },
   "outputs": [],
   "source": [
    "batch_1_2_3 = pd.concat([fixed_dataset, batch_3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9ObYO0T-21a"
   },
   "source": [
    "### Load dataset, launch Project, and get Cleanlab columns\n",
    "\n",
    "Again: if your notebook times out during any of the following steps, you likely don't need to re-run that step (re-running the step may take a long time again). Instead try to run the next step after restarting your notebook\n",
    "The training for this example could take approximately 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-pEf_6m-21a"
   },
   "outputs": [],
   "source": [
    "dataset_id = studio.upload_dataset(batch_1_2_3, dataset_name=\"data-batch-1-3\")\n",
    "print(f\"Dataset ID: {dataset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xP-tjAc-21a"
   },
   "outputs": [],
   "source": [
    "project_id = studio.create_project(\n",
    "    dataset_id=dataset_id,\n",
    "    project_name=\"batch-1-3-analysis\",\n",
    "    modality=\"text\",\n",
    "    task_type=\"multi-class\",\n",
    "    model_type=\"regular\",\n",
    "    label_column=label_column,\n",
    "    text_column=text_column\n",
    ")\n",
    "print(f\"Project successfully created and training has begun! project_id: {project_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UoUcFjjK-21b"
   },
   "outputs": [],
   "source": [
    "cleanset_id = studio.get_latest_cleanset_id(project_id)\n",
    "print(f\"cleanset_id: {cleanset_id}\")\n",
    "project_status = studio.wait_until_cleanset_ready(cleanset_id)\n",
    "cleanlab_columns_df = studio.download_cleanlab_columns(cleanset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGouKFen-21b"
   },
   "source": [
    "### Review issues detected in batch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "4JAX85_Q-21b"
   },
   "outputs": [],
   "source": [
    "df3 = batch_1_2_3.copy()\n",
    "merge_df_cleanlab = df3.merge(cleanlab_columns_df, left_index=True, right_index=True)\n",
    "merge_df_cleanlab.rename(columns={\"label\": \"given_label\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44ADhemY-21c"
   },
   "source": [
    "The merged dataset `batch_1_2_3` consists of clean historical data (from batches 1 + 2) and the raw batch 3 data.\n",
    "As before, let's focus on the issues detected in the batch 3 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "c3SCU3Lu-21c",
    "outputId": "01133bf4-ebd8-4621-8b07-b3a550f38563"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_issue_score</th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>860</td>\n",
       "      <td>which currencies can i used to add funds to my account?</td>\n",
       "      <td>0.850656</td>\n",
       "      <td>True</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>988</td>\n",
       "      <td>i was charged for getting cash.</td>\n",
       "      <td>0.834128</td>\n",
       "      <td>True</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>959</td>\n",
       "      <td>so, i was just charged for my recent atm withdrawal and any withdrawal prior to this has been free. what is the issue here?</td>\n",
       "      <td>0.769915</td>\n",
       "      <td>True</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>850</td>\n",
       "      <td>how long does it take for a top up to be approved?</td>\n",
       "      <td>0.582045</td>\n",
       "      <td>True</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   \n",
       "850  860  \\\n",
       "978  988   \n",
       "949  959   \n",
       "840  850   \n",
       "\n",
       "                                                                                                                            text   \n",
       "850                                                                      which currencies can i used to add funds to my account?  \\\n",
       "978                                                                                              i was charged for getting cash.   \n",
       "949  so, i was just charged for my recent atm withdrawal and any withdrawal prior to this has been free. what is the issue here?   \n",
       "840                                                                           how long does it take for a top up to be approved?   \n",
       "\n",
       "     label_issue_score  is_label_issue           given_label   \n",
       "850           0.850656            True       cancel_transfer  \\\n",
       "978           0.834128            True  card_about_to_expire   \n",
       "949           0.769915            True  card_about_to_expire   \n",
       "840           0.582045            True       cancel_transfer   \n",
       "\n",
       "                    suggested_label  \n",
       "850  supported_cards_and_currencies  \n",
       "978        card_payment_fee_charged  \n",
       "949        card_payment_fee_charged  \n",
       "840  supported_cards_and_currencies  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an array of batch-3 id's\n",
    "ids_of_batch_3 = batch_3[\"id\"]\n",
    "# Isolate batch-3 subset from the current dataset\n",
    "batch_3_subset = merge_df_cleanlab.query(\"id in @ids_of_batch_3\", engine=\"python\")\n",
    "# Fetch rows with label issues\n",
    "label_issues = batch_3_subset.query(\"is_label_issue\", engine=\"python\").sort_values(\"label_issue_score\", ascending=False)\n",
    "\n",
    "display(label_issues[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xR873isCGWJj"
   },
   "source": [
    "### Review issues in older batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTiOebPA-21c"
   },
   "source": [
    "While we've been focusing on the issues detected in the latest batch of data only, we can also see if any issues have been detected in the older historical data (the cleaned version of batches 1 and 2). Now that there is significantly more data in the Cleanlab Studio Project, the AI is able to detect data issues more accurately and may find issues missed in previous rounds. Let's see if there are any new label issues detected in the previous cleaned versions of batches 1 and 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "TtOqxo386riu",
    "outputId": "96e4e7b6-3431-4134-a1a5-42402eaa843f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_issue_score</th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>please tell me how to change my pin.</td>\n",
       "      <td>0.830466</td>\n",
       "      <td>True</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>how do i find my new pin?</td>\n",
       "      <td>0.811987</td>\n",
       "      <td>True</td>\n",
       "      <td>visa_or_mastercard</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>explain roth ira</td>\n",
       "      <td>0.585797</td>\n",
       "      <td>True</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>what cards do you offer?</td>\n",
       "      <td>0.726222</td>\n",
       "      <td>True</td>\n",
       "      <td>visa_or_mastercard</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                  text  label_issue_score   \n",
       "39  39  please tell me how to change my pin.           0.830466  \\\n",
       "67  68             how do i find my new pin?           0.811987   \n",
       "90  91                      explain roth ira           0.585797   \n",
       "94  95              what cards do you offer?           0.726222   \n",
       "\n",
       "    is_label_issue              given_label                 suggested_label  \n",
       "39            True  beneficiary_not_allowed                      change_pin  \n",
       "67            True       visa_or_mastercard                      change_pin  \n",
       "90            True  beneficiary_not_allowed  supported_cards_and_currencies  \n",
       "94            True       visa_or_mastercard  supported_cards_and_currencies  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_1_2_subset = merge_df_cleanlab.query(\"id not in @ids_of_batch_3\", engine=\"python\")\n",
    "\n",
    "display(batch_1_2_subset.query(\"is_label_issue\", engine=\"python\")[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFS8H2N5OjTj"
   },
   "source": [
    "While we've been fixing the label issues detected in each older data batch at the time the data was collected, this doesn't guarantee the older batches are 100% free of label issues.\n",
    "\n",
    "To demonstrate another type of issue, we can also review the outliers detected in these data batches in isolation. From the latest Cleanlab Studio Project, here are the outliers detected in batch 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "udzH8Ld-bwyP",
    "outputId": "261b8d37-789e-4f02-82dc-20a79a3bbc1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>given_label</th>\n",
       "      <th>outlier_score</th>\n",
       "      <th>is_empty_text</th>\n",
       "      <th>text_num_characters</th>\n",
       "      <th>is_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>862</td>\n",
       "      <td>cancel transaction</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>0.178126</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                text      given_label  outlier_score  is_empty_text   \n",
       "852  862  cancel transaction  cancel_transfer       0.178126          False  \\\n",
       "\n",
       "     text_num_characters  is_outlier  \n",
       "852                   18        True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_to_display_outlier = [\"id\", \"text\", \"given_label\", \"outlier_score\", \"is_empty_text\", \"text_num_characters\", \"is_outlier\"]\n",
    "outlier_issues_batch_3 = merge_df_cleanlab.query('(id in @ids_of_batch_3) & (is_outlier)', engine='python')\n",
    "\n",
    "display(outlier_issues_batch_3[columns_to_display_outlier])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZvh3ZQzmYPY"
   },
   "source": [
    "Outliers detected in batch 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "NtEtm7xz5WmI",
    "outputId": "a70ca102-a499-431a-eb19-6b66576a26e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>given_label</th>\n",
       "      <th>outlier_score</th>\n",
       "      <th>is_empty_text</th>\n",
       "      <th>text_num_characters</th>\n",
       "      <th>is_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>509</td>\n",
       "      <td>metal card</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "      <td>0.234098</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>568</td>\n",
       "      <td>changing my pin</td>\n",
       "      <td>change_pin</td>\n",
       "      <td>0.172110</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>589</td>\n",
       "      <td>750 credit score</td>\n",
       "      <td>getting_spare_card</td>\n",
       "      <td>0.154556</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>647</td>\n",
       "      <td>404Error&lt;body&gt;&lt;p&gt;InvalidUsername&lt;/p&gt;&lt;p&gt; InvalidPIN&lt;/p&gt;&lt;/body&gt;</td>\n",
       "      <td>change_pin</td>\n",
       "      <td>0.202901</td>\n",
       "      <td>False</td>\n",
       "      <td>61</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                                           text   \n",
       "502  509                                                     metal card  \\\n",
       "561  568                                                changing my pin   \n",
       "582  589                                               750 credit score   \n",
       "639  647  404Error<body><p>InvalidUsername</p><p> InvalidPIN</p></body>   \n",
       "\n",
       "              given_label  outlier_score  is_empty_text  text_num_characters   \n",
       "502  card_about_to_expire       0.234098          False                   10  \\\n",
       "561            change_pin       0.172110          False                   15   \n",
       "582    getting_spare_card       0.154556          False                   16   \n",
       "639            change_pin       0.202901          False                   61   \n",
       "\n",
       "     is_outlier  \n",
       "502        True  \n",
       "561        True  \n",
       "582        True  \n",
       "639        True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outlier_issues_batch_2 = merge_df_cleanlab.query('(id in @ids_of_batch_2) & (is_outlier)', engine='python')\n",
    "display(outlier_issues_batch_2[columns_to_display_outlier])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJJwiSqimYPY"
   },
   "source": [
    "Outliers detected in batch 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "ADrRlGEd5WmI",
    "outputId": "e9e8d215-2462-4394-c3aa-86ac726ff905"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>given_label</th>\n",
       "      <th>outlier_score</th>\n",
       "      <th>is_empty_text</th>\n",
       "      <th>text_num_characters</th>\n",
       "      <th>is_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>explain roth ira</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>0.176312</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>285</td>\n",
       "      <td>payment did not process</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>0.184214</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>456</td>\n",
       "      <td>switch banks</td>\n",
       "      <td>change_pin</td>\n",
       "      <td>0.186031</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>463</td>\n",
       "      <td>my sc</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "      <td>0.247411</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                     text              given_label  outlier_score   \n",
       "90    91         explain roth ira  beneficiary_not_allowed       0.176312  \\\n",
       "280  285  payment did not process  beneficiary_not_allowed       0.184214   \n",
       "450  456             switch banks               change_pin       0.186031   \n",
       "456  463                    my sc  apple_pay_or_google_pay       0.247411   \n",
       "\n",
       "     is_empty_text  text_num_characters  is_outlier  \n",
       "90           False                   16        True  \n",
       "280          False                   23        True  \n",
       "450          False                   12        True  \n",
       "456          False                    5        True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ids_of_batch_1 = batch_1[\"id\"]\n",
    "outlier_issues_batch_1 = merge_df_cleanlab.query(\"(id in @ids_of_batch_1) & (is_outlier)\", engine=\"python\")\n",
    "display(outlier_issues_batch_1[columns_to_display_outlier])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKO8ECGvhPv9"
   },
   "source": [
    "### Improve batch 3 data based on the detected issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YoyqpAbn5WmI"
   },
   "source": [
    "Finally, we fix just the label issues detected in batch 3, using the same strategy applied to the previous data batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNqwe3fmPvQd",
    "outputId": "4502f13e-9a11-497b-894a-1e264535a1a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding 1 text example(s) (out of 200 from batch-3)\n"
     ]
    }
   ],
   "source": [
    "# Keep track of excluded rows\n",
    "issues_below_threshold = label_issues.query(\"label_issue_score < @label_threshold\", engine=\"python\")\n",
    "\n",
    "threshold_filtered_rows = pd.concat([issues_below_threshold, threshold_filtered_rows])\n",
    "\n",
    "# Find indices of rows to exclude\n",
    "ids_to_exclude3 = issues_below_threshold[\"id\"]\n",
    "indices_to_exclude3 = batch_3_subset.query(\"id in @ids_to_exclude3\", engine=\"python\").index\n",
    "\n",
    "print(f\"Excluding {len(ids_to_exclude3)} text example(s) (out of {len(batch_3_subset)} from batch-3)\")\n",
    "\n",
    "# Drop rows from the batch-3 subset\n",
    "batch_3_subset = batch_3_subset.drop(indices_to_exclude3)\n",
    "\n",
    "corrected_label = np.where(batch_3_subset[\"is_label_issue\"],\n",
    "                           batch_3_subset[\"suggested_label\"],\n",
    "                           batch_3_subset[\"given_label\"])\n",
    "\n",
    "# Keep track of fixed rows\n",
    "label_issues_fixed_rows = pd.concat([label_issues_fixed_rows, batch_3_subset.query(\"is_label_issue\", engine=\"python\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCwRj_n9mYPa"
   },
   "source": [
    "And then add the cleaned batch 3 data to our master dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9K5B1ERQps0",
    "outputId": "99241067-3e21-4b43-8253-8991ab4a0416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of label issues fixed across all 3 batches: 6\n",
      "Total number of rows, with label issues, excluded due to score less than threshold (0.7): 11\n"
     ]
    }
   ],
   "source": [
    "fixed_batch_3 = batch_3_subset[[\"text\", \"id\"]].copy()\n",
    "fixed_batch_3[\"label\"] = corrected_label\n",
    "fixed_dataset = pd.concat([fixed_dataset, fixed_batch_3], ignore_index=True)\n",
    "\n",
    "print(f\"Total number of label issues fixed across all 3 batches: {len(label_issues_fixed_rows)}\")\n",
    "print(f\"Total number of rows, with label issues, excluded due to score less than threshold ({label_threshold}): {len(threshold_filtered_rows)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTW_FdtIS1AZ"
   },
   "source": [
    "### Saving the master dataset\n",
    "\n",
    "After cleaning and accumulating multiple batches of data, we save the resulting master fixed dataset to a CSV file that can be used as a plug-in replacement in your existing modeling workflows. The cleaned dataset will have the same format as your original dataset, so you can use it as a plug-in replacement to get more reliable results in your ML/Analytics pipelines (without changing your existing modeling code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YY_Q0QaD5WmJ",
    "outputId": "bd0edaf2-5c2e-4aac-e084-a0c3e1b8b0e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master fixed dataset saved to fixed_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "new_dataset_filename = \"fixed_dataset.csv\"  # Location to save clean master dataset\n",
    "\n",
    "if os.path.exists(new_dataset_filename):\n",
    "    raise ValueError(f\"File {new_dataset_filename} already exists. Cannot overwite so please delete it first, or specify a different new_dataset_filename.\")\n",
    "else:\n",
    "    fixed_dataset.to_csv(new_dataset_filename, index=False, columns=[\"text\", \"label\"])\n",
    "    print(f\"Master fixed dataset saved to {new_dataset_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTW_FdtIS1AZ"
   },
   "source": [
    "### Faster methods \n",
    "\n",
    "The approach demonstrated here is how we recommend handling growing datasets in the generally available version of Cleanlab Studio. If your only goal is to label/categorize data coming in at rapid volumes, you can instead [deploy a ML model to more quickly process incoming data](/studio/tutorials/cleanlab-studio-api/inference_api/). For companies with particular data workloads, Cleanlab offers more compute-efficient and integrated solutions that scale to larger volumes of incoming data. [Contact us](https://cleanlab.ai/sales/) to learn more."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}