{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Reliable ML Models in Production \n",
    "\n",
    "<head>\n",
    "  <meta name=\"title\" content=\"Reliable ML Model Training + Deployment From Raw Data (in Minutes)\"/>\n",
    "  <meta property=\"og:title\" content=\"Reliable ML Model Training + Deployment From Raw Data (in Minutes)\"/>\n",
    "  <meta name=\"twitter:title\" content=\"Reliable ML Model Training + Deployment From Raw Data (in Minutes)\" />\n",
    "  <meta name=\"image\" content=\"/img/modeldeployment.png\" />\n",
    "  <meta property=\"og:image\" content=\"/img/modeldeployment.png\" />\n",
    "  <meta name=\"description\" content=\"Automate data prep, model training, and serving predictions for image/text/tabular data.\"  />\n",
    "  <meta property=\"og:description\" content=\"Automate data prep, model training, and serving predictions for image/text/tabular data.\" />\n",
    "  <meta name=\"twitter:description\" content=\"Automate data prep, model training, and serving predictions for image/text/tabular data.\" />\n",
    "</head>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll use Cleanlab Studio to train a reliable ML model on raw data and deploy it in production with a single click. Using the deployed model, we can obtain predictions on new data using Cleanlab Studio's Python API.\n",
    "\n",
    "![Model training and deployment pipeline overview](./assets/inference-tutorial/mldeployment.png)\n",
    "\n",
    "We'll work with a [dataset](https://data.dws.informatik.uni-mannheim.de/largescaleproductcorpus/data/amazon_training.json.gzip) from Web Data Commons where the ML task is to classify products based on their text descriptions. Model deployment works similarly for tabular and image datasets. The text classification dataset for this tutorial contains titles, descriptions, and category labels for 23,000 products on Amazon. It looks like this:\n",
    "\n",
    "![Product Descriptions Dataset](./assets/inference-tutorial/dataset_preview.png)\n",
    "\n",
    "For the above dataset, we'll train and deploy a reliable model that can be used to automatically classify the category of new products:\n",
    "\n",
    "```python\n",
    ">>> model.predict(['$100 Dollar Bill Design (Benjamin) Eraser'])\n",
    "['Office_Products']\n",
    "```\n",
    "\n",
    "Here we are running model deployment with a multi-class text dataset. Cleanlab Studio can similarly auto-train and deploy ML models for many other data modalities, as well as for multi-label datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "For online retailers like Amazon, product classification is a highly important task. Reliable product classification allows customers to find products and retailers to suggest related products \u2014 both of which are crucial to making sales and generating revenue!\n",
    "\n",
    "As with any classification task, the quality of the data going in has a tremendous effect on the quality of the inferences generated by the model. For a retailer like Amazon, the initial labels might be created by a team of annotators who are paid for each example they annotate. The quality of these labels will not always be high.\n",
    "\n",
    "The underlying data itself can be suspect. Datasets will often contain duplicate, null, or corrupted examples \u2014 all of which will impact the performance of the model trained on the dataset.\n",
    "\n",
    "Using Cleanlab Studio, training a model begins with cleaning your dataset, a process made easy by our algorithms which automatically find [data and label issues](/studio/concepts/cleanlab_columns) and recommend actions to fix them. Once you have a clean dataset, with a single click, Cleanlab Studio's autoML can train and deploy a reliable model suitable for use in a production setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and Import Required Dependencies\n",
    "\n",
    "You can use `pip` to install all packages required for this tutorial as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install cleanlab-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab_studio import Studio\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe54e6d-b37a-48aa-b412-d72f85970104",
   "metadata": {},
   "source": [
    "**Optional: Initialize helper method to render dataframes**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "def display(data) -> None:\n",
    "    return HTML(data.to_html(escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and Upload Dataset\n",
    "\n",
    "In this tutorial, we want to train a text-based ML model that predicts the category label based on a single text field. Let's first load the original dataset and see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>categoryLabel</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000JGEKLK</td>\n",
       "      <td>Rothco</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>USA Antenna Flag - Size: 4.5\" x 6\". United States Mini Flag For Antennas. US Antenna Flag.</td>\n",
       "      <td>USA Antenna Flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B004KEIU1S</td>\n",
       "      <td>None</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Schrader Part #20395 is a 100/box set of plastic sealing valve caps.</td>\n",
       "      <td>Schrader 20395 TPMS Plastic Sealing Valve Cap - Pack of 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B005FL767Y</td>\n",
       "      <td>Power Stop</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Power Stop brake kits include a complete set of cross-drilled and slotted rotors and high performance evolution ceramic pads. It is made simple by matching the pads and rotors for a big brake feel without the big price. The Power Stop brake kit offers more pad bite than other leading brands without noise and dust. If you need a fast, easy and affordable solution for better braking, then you need the Power Stop brake kit.</td>\n",
       "      <td>Power Stop K2434 Rear Ceramic Brake Pad and Cross Drilled/Slotted Combo Rotor One-Click Brake Kit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('https://cleanlab-public.s3.amazonaws.com/StudioDemoDatasets/amazon_training.json')\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data\n",
    "\n",
    "We'd like to use both the title and the description as part of the text that the model uses for predictions. To enable this, we modify the DataFrame so it contains a new column (we call it `text`) that concates the title and description, separated by a newline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>brand</th>\n",
       "      <th>categoryLabel</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000JGEKLK</td>\n",
       "      <td>Rothco</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>USA Antenna Flag - Size: 4.5\" x 6\". United States Mini Flag For Antennas. US Antenna Flag.</td>\n",
       "      <td>USA Antenna Flag</td>\n",
       "      <td>USA Antenna Flag\\nUSA Antenna Flag - Size: 4.5\" x 6\". United States Mini Flag For Antennas. US Antenna Flag.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B004KEIU1S</td>\n",
       "      <td>None</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Schrader Part #20395 is a 100/box set of plastic sealing valve caps.</td>\n",
       "      <td>Schrader 20395 TPMS Plastic Sealing Valve Cap - Pack of 100</td>\n",
       "      <td>Schrader 20395 TPMS Plastic Sealing Valve Cap - Pack of 100\\nSchrader Part #20395 is a 100/box set of plastic sealing valve caps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B005FL767Y</td>\n",
       "      <td>Power Stop</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Power Stop brake kits include a complete set of cross-drilled and slotted rotors and high performance evolution ceramic pads. It is made simple by matching the pads and rotors for a big brake feel without the big price. The Power Stop brake kit offers more pad bite than other leading brands without noise and dust. If you need a fast, easy and affordable solution for better braking, then you need the Power Stop brake kit.</td>\n",
       "      <td>Power Stop K2434 Rear Ceramic Brake Pad and Cross Drilled/Slotted Combo Rotor One-Click Brake Kit</td>\n",
       "      <td>Power Stop K2434 Rear Ceramic Brake Pad and Cross Drilled/Slotted Combo Rotor One-Click Brake Kit\\nPower Stop brake kits include a complete set of cross-drilled and slotted rotors and high performance evolution ceramic pads. It is made simple by matching the pads and rotors for a big brake feel without the big price. The Power Stop brake kit offers more pad bite than other leading brands without noise and dust. If you need a fast, easy and affordable solution for better braking, then you need the Power Stop brake kit.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['title'] + '\\n' + df['description']\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>This tutorial focuses on using the Python API, but you can also use our <a href=\"https://studio.cleanlab.ai\">Web UI</a> for a no-code option <b>(click to expand)</b></summary>\n",
    "\n",
    "If you would like to upload your data without writing code, simply go to [https://studio.cleanlab.ai/upload](https://studio.cleanlab.ai/upload) and follow these steps:\n",
    "1. Click \"Upload from URL\"\n",
    "2. Enter [link to dataset](https://cleanlab-public.s3.amazonaws.com/StudioDemoDatasets/amazon-products/amazon_products_train.csv) (we added the text column here)\n",
    "3. Click \"Upload\" and wait for the file to upload\n",
    "4. Click \"Next\"\n",
    "5. Make sure \"text\" is selected as the dataset modality. Leave everything else on the schema editing page as default\n",
    "6. Click \"Confirm\"\n",
    "7. Wait for data ingestion to complete\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To upload your dataset to Cleanlab Studio using our Python API, use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can find your API key by going to studio.cleanlab.ai/upload, \n",
    "# clicking \"Upload via Python API\", and copying the API key there\n",
    "API_KEY = \"<YOUR_API_KEY>\"\n",
    "\n",
    "# authenticate with your API key\n",
    "studio = Studio(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = studio.upload_dataset(df, dataset_name=\"Product Descriptions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Data\n",
    "\n",
    "Real world data is messy and often contains issues such as label errors, outliers, and duplicate examples. If we use Cleanlab Studio to address these issues and train a model on the improved data, we'll obtain a [model that gives more reliable predictions](https://cleanlab.ai/blog/model-deployment/).\n",
    "\n",
    "Since cleaning your data using Cleanlab Studio isn't the main focus of this tutorial, we won't go into detail on it here. Instead see our [Python API](/studio/quickstart/api/) or [Web UI](/studio/quickstart/web#create-a-project-to-detect-data-and-label-issues) quickstarts. \n",
    "\n",
    "**Note**: make sure you create a `text` project and use the `text` column for the predictive column! This will ensure that the model is trained on the column containing the concatenated product titles and descriptions, leading to the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Issue Examples\n",
    "\n",
    "Below, we can see two examples of label issues caught by Cleanlab Studio.\n",
    "\n",
    "**The following data point is labeled `Sports_and_Outdoors`, but it should be labeled `Jewelry`:**\n",
    "\n",
    "![Relabel Example 1](./assets/inference-tutorial/relabel_example_1.png)\n",
    "\n",
    "**The following data point is labeled `Tools_and_Home_Improvement`, but it should be labeled `Books`:**\n",
    "\n",
    "![Relabel Example 2](./assets/inference-tutorial/relabel_example_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model\n",
    "\n",
    "Once you're happy with your dataset corrections, you can use Cleanlab Studio to automatically train and deploy a model using the cleaned data. To do this, click on the \"Deploy Model\" button on the project page, name your model, and click deploy. Cleanlab Studio will automatically train many types of ML models, using cutting-edge AutoML to find the best model for your dataset.\n",
    "\n",
    "\n",
    "<Video\n",
    "  width=\"1792\"\n",
    "  height=\"1010\"\n",
    "  src=\"./assets/inference-tutorial/deploy_model.mp4\"\n",
    "  autoPlay={false}\n",
    "  loop={false}\n",
    "  muted={true}\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Model in Production\n",
    "\n",
    "Now that you've deployed your model, you can use Cleanlab Studio's Python API to obtain predictions for new data points. For this tutorial, we've prepared several batches of samples to run inference on.\n",
    "\n",
    "Batches for text models (as we're using in this tutorial) must be provided as lists, NumPy arrays, or Pandas Series of strings. Batches for tabular models must be provided as Pandas DataFrames. For tabular data/models, prediction batches must use contain the same column(s) as the project was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Tablet Portfolio for iPad Tablets\\nTablet Port...\n",
       "1     Factory-Reconditioned Milwaukee 2471-81 12-Vol...\n",
       "2     Microsoft Zune Armor Case - The Metal Case (Bl...\n",
       "3     90W AC Power Adapter/Battery Charger for HP Pa...\n",
       "4     Golda\\nAs Israel's prime minister from 1969 to...\n",
       "                            ...                        \n",
       "95    HQRP 2.0Ah Power Tools Battery for DeWalt DE90...\n",
       "96    L-Tryptophan - 100 Grams (3.53 Oz) - 99+% Pure...\n",
       "97    Beba Toy\\nThe Beba Toy is the &#x201C;World&#x...\n",
       "98    Coby TFTV3925 39-Inch 1080p 60Hz LCD HDTV (Bla...\n",
       "99    Mokingtop Fashion New 6 Pieces Babys Girls Hea...\n",
       "Name: text, Length: 100, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and prepare example test data\n",
    "batch = pd.read_csv(\"https://cleanlab-public.s3.amazonaws.com/StudioDemoDatasets/amazon-products/amazon_products_inference_batch_0.csv\")\n",
    "batch_text = batch[\"text\"]\n",
    "batch_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model ID](./assets/inference-tutorial/model_id.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tablet Portfolio for iPad Tablets\\nTablet Port...</td>\n",
       "      <td>Computers_and_Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Factory-Reconditioned Milwaukee 2471-81 12-Vol...</td>\n",
       "      <td>Tools_and_Home_Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microsoft Zune Armor Case - The Metal Case (Bl...</td>\n",
       "      <td>Other_Electronics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Tablet Portfolio for iPad Tablets\\nTablet Port...   \n",
       "1  Factory-Reconditioned Milwaukee 2471-81 12-Vol...   \n",
       "2  Microsoft Zune Armor Case - The Metal Case (Bl...   \n",
       "\n",
       "                  predictions  \n",
       "0   Computers_and_Accessories  \n",
       "1  Tools_and_Home_Improvement  \n",
       "2           Other_Electronics  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model from Studio\n",
    "# you can find your model ID in the models table on the dashboard!\n",
    "model_id = \"<YOUR_MODEL_ID>\"\n",
    "model = studio.get_model(model_id)\n",
    "\n",
    "predictions = model.predict(batch_text)\n",
    "display(pd.DataFrame({\"text\": batch_text, \"predictions\": predictions}).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also obtain the predicted class probabilities for each data point that quantify model confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Automotive</th>\n",
       "      <th>Baby</th>\n",
       "      <th>Books</th>\n",
       "      <th>CDs_and_Vinyl</th>\n",
       "      <th>Camera_and_Photo</th>\n",
       "      <th>Cellphones_and_Accessories</th>\n",
       "      <th>Clothing</th>\n",
       "      <th>Computers_and_Accessories</th>\n",
       "      <th>Grocery_and_Gourmet_Food</th>\n",
       "      <th>Health_and_Beauty</th>\n",
       "      <th>...</th>\n",
       "      <th>Movies_and_TV</th>\n",
       "      <th>Musical_Instruments</th>\n",
       "      <th>Office_Products</th>\n",
       "      <th>Other_Electronics</th>\n",
       "      <th>Pet_Supplies</th>\n",
       "      <th>Shoes</th>\n",
       "      <th>Sports_and_Outdoors</th>\n",
       "      <th>Tools_and_Home_Improvement</th>\n",
       "      <th>Toys_and_Games</th>\n",
       "      <th>Video_Games</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.81058</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.008199</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.001213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows \u00d7 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Automotive      Baby     Books  CDs_and_Vinyl  Camera_and_Photo  \\\n",
       "0    0.005268  0.001317  0.000023       0.000014          0.000998   \n",
       "\n",
       "   Cellphones_and_Accessories  Clothing  Computers_and_Accessories  \\\n",
       "0                    0.000585  0.006329                    0.81058   \n",
       "\n",
       "   Grocery_and_Gourmet_Food  Health_and_Beauty  ...  Movies_and_TV  \\\n",
       "0                  0.000131           0.000149  ...       0.000041   \n",
       "\n",
       "   Musical_Instruments  Office_Products  Other_Electronics  Pet_Supplies  \\\n",
       "0             0.000491         0.009481           0.006538      0.000207   \n",
       "\n",
       "      Shoes  Sports_and_Outdoors  Tools_and_Home_Improvement  Toys_and_Games  \\\n",
       "0  0.002799             0.008199                    0.001068        0.000057   \n",
       "\n",
       "   Video_Games  \n",
       "0     0.001213  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_text = batch_text[0]\n",
    "prediction, pred_probs = model.predict([input_text[0]],return_pred_proba=True)\n",
    "display(pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(*Optional*) Since our test data here happen to be labeled, we can evaluate the accuracy\u00a0of the model predictions against these given labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n"
     ]
    }
   ],
   "source": [
    "accuracy = sum(predictions==batch['categoryLabel'])/len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>It's also possible to use our <a href=\"https://studio.cleanlab.ai/\">Web UI</a> to get predictions</summary>\n",
    "\n",
    "If you would like to get predictions without writing code, simply go to [https://studio.cleanlab.ai/](https://studio.cleanlab.ai/) and follow these steps:\n",
    "1. Click \"View model\" for the model you created\n",
    "2. Click \"Predict new labels\"\n",
    "3. Upload a CSV containing the examples you want predictions for\n",
    "    1. For text models, your CSV should have a single column\n",
    "    2. For tabular models, your CSV should contain all of your predictive columns\n",
    "4. Click \"Predict New Labels\"\n",
    "7. Wait for inference to complete\n",
    "8. Click \"Export\" for the query you made\n",
    "9. The exported CSV file will have the probabilitites of each class, along with the predicted label\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a model trained on reliable data that is an accurate text classifier! This deployed model is ready to be used in production for real-time queries.\n",
    "You can read about how ML deployed with Cleanlab Studio can be more accurate than even fine-tuned OpenAI LLMs for classifying texts like [product reviews](https://cleanlab.ai/blog/model-deployment/) or [legal judgements](https://cleanlab.ai/blog/studio-model-deployment-legal/).\n",
    "\n",
    "While we demonstrated text data here, Cleanlab Studio can similarly auto-train and deploy ML models for other data modalities as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e5bd469d13e6ac3463822d1cb85078d2b0f986df9366ef2fd39097878badfc56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}