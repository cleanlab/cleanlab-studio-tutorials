{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Issues in Regression Datasets (Erroneous Values in Numerical Data) \n",
    "\n",
    "<head>\n",
    "  <meta name=\"title\" content=\"Automatically Detect Erroneous Values in Numerical Data via AI\"/>\n",
    "  <meta property=\"og:title\" content=\"Automatically Detect Erroneous Values in Numerical Data via AI\"/>\n",
    "  <meta name=\"twitter:title\" content=\"Automatically Detect Erroneous Values in Numerical Data via AI\" />\n",
    "  <meta name=\"image\" content=\"/img/regression.png\" />\n",
    "  <meta property=\"og:image\" content=\"/img/regression.png\" />\n",
    "  <meta name=\"description\" content=\"Catch numeric values that are likely incorrect (eg. due to noise from erroneous sensors, data entry/processing mistakes, imperfect human estimates).\"  />\n",
    "  <meta property=\"og:description\" content=\"Catch numeric values that are likely incorrect (eg. due to noise from erroneous sensors, data entry/processing mistakes, imperfect human estimates).\" />\n",
    "  <meta name=\"twitter:description\" content=\"Catch numeric values that are likely incorrect (eg. due to noise from erroneous sensors, data entry/processing mistakes, imperfect human estimates).\" />\n",
    "</head>\n",
    "\n",
    "This tutorial demonstrates how to use Cleanlab Studio's [Python API](/studio/quickstart/api/) to analyze a regression dataset.  In regression, the dataset labels correspond to a target (aka. outcome/dependent) variable and take continuous/numeric values (i.e. price, income, age) rather than discrete categories (for a similar tutorial on data with categorical labels, check out the [Tabular Quickstart](/studio/tutorials/cleanlab-studio-api/tabular_data_quickstart/)).\n",
    "\n",
    "![Visualizing errors in a regression dataset](./assets/regression-tutorial/thumbnail.png)\n",
    "\n",
    "Cleanlab Studio supports both text and tabular regression datasets. In this tutorial, we'll look at a tabular dataset where labels are students' final grades in a course (which may have data entry errors). This tutorial can be generally used to detect erroneous values in *any* numeric column of a dataset. \n",
    "\n",
    "Note: regression is currently only supported in the Python API in the generally-available version of Cleanlab Studio. If you require an interactive interface to improve your dataset, please [contact us](mailto:sales@cleanlab.ai) to discuss your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U cleanlab-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cleanlab_studio import Studio\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and Upload Dataset\n",
    "\n",
    "Our dataset for this tutorial is a collection of student grades and other information about each student. Suppose we are interested in detecting incorrect values (data entry errors) in students' `final_score`, which ranges from 0 to 100. In machine learning terminology, this can be considered a **regression** dataset, where the `final_score` column is the **label** for each row (student) in the table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset into Pandas DataFrame\n",
    "\n",
    "We'll load the dataset into a Pandas DataFrame from a CSV file hosted in S3. The CSV file contains the following columns:\n",
    "\n",
    "```\n",
    "stud_ID,exam_1,exam_2,exam_3,notes,final_score\n",
    "0,72,81,80,,73.3\n",
    "1,89,62,93,,83.8\n",
    "2,80,76,96,missed class frequently -10,78.6\n",
    "<id of student>,<grade on exam 1>,<grade on exam 2>,<grade on exam 3>,<optional notes>,<overall letter grade for student>\n",
    "...\n",
    "```\n",
    "\n",
    "You can similarly format any other tabular or text dataset and run the rest of this tutorial. Details on how to format your dataset can be found in [this guide](/studio/concepts/datasets/), which also outlines other format options. Cleanlab Studio works out-of-the-box for messy tabular datasets with arbitrary numeric/string columns that may contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stud_ID</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stud_ID  exam_1  exam_2  exam_3 notes  final_score\n",
       "0        0      72      81      80   NaN         73.3\n",
       "1        1      89      62      93   NaN         83.8\n",
       "2        2      97       0      94   NaN         73.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_url = \"https://cleanlab-public.s3.amazonaws.com/StudioDemoDatasets/student_grades_regression.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Dataset to Cleanlab Studio\n",
    "\n",
    "Use your API key to instantiate a `Studio` object, which can be used to analyze your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can find your API key by going to app.cleanlab.ai/upload,\n",
    "# clicking \"Upload via Python API\", and copying the API key there\n",
    "API_KEY = \"<insert your API key>\"\n",
    "\n",
    "# authenticate with your API key\n",
    "studio = Studio(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next load the dataset into Cleanlab Studio (more details/options can be found in [this guide](/studio/concepts/datasets/)). This may take a while for big datasets. We explicitly set the type for the `final_score` column to `float` here, since the label column must have type `float` for a [regression project](https://help.cleanlab.ai/studio/concepts/datasets/#regression) (otherwise specifying schemas is optional). See [this guide](/studio/concepts/datasets/#schema-updates) for more information on schema overrides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = studio.upload_dataset(\n",
    "    df,\n",
    "    dataset_name=\"Student Grades (regression)\",\n",
    "    schema_overrides=[{\"name\": \"final_score\", \"column_type\": \"float\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch a Project\n",
    "\n",
    "Let's now create a project using this dataset. A Cleanlab Studio project will automatically train ML models to provide AI-based analysis of your dataset.\n",
    "\n",
    "**Note:** By default Cleanlab Studio uses all columns provided as predictive features except the label column. Since our dataset contains a `stud_ID` column which is not a predictive feature of the output score, we explicitly specify the feature columns as well as the name of the label column, i.e. `final_score` column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = studio.create_project(\n",
    "    dataset_id=dataset_id,\n",
    "    project_name=\"Student Grades (regression) Project\",\n",
    "    modality=\"tabular\",\n",
    "    task_type=\"regression\",\n",
    "    model_type=\"regular\",\n",
    "    label_column=\"final_score\",\n",
    "    feature_columns=[\"exam_1\", \"exam_2\", \"exam_3\", \"notes\"],\n",
    ")\n",
    "print(f\"Project successfully created and training has begun! project_id: {project_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we specified `modality=\"tabular\"` because this tutorial uses a tabular dataset; you can specify `modality=\"text\"` if you're using a text dataset. See the documentation for [`create_project`](/studio/api/python/studio/#method-create_project) for the full set of options.\n",
    "\n",
    "Once the project has been launched successfully and you see your `project_id`, feel free to close this notebook. It will take some time for Cleanlab\u2019s AI to train on your data and analyze it. Come back after training is complete (you will receive an email) and continue with the notebook to review your results.\n",
    "\n",
    "You should only execute the above cell once per dataset. After launching the project, you can poll for its status to programmatically wait until the results are ready for review. Each project creates a [cleanset](/studio/concepts/cleanset/), an improved version of your original dataset that contains additional metadata for helping you clean up the data. The next code cell simply waits until this *cleanset* has been created.\n",
    "\n",
    "**Warning!** For big datasets, this next cell may take a long time to execute while Cleanlab's AI model is training. If your notebook has timed out during this process, you can resume work by re-running the below cell (which should return the `cleanset_id` instantly if the project has completed training). Do not re-run the above cell and create a new project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanset_id = studio.get_latest_cleanset_id(project_id)\n",
    "print(f\"cleanset_id: {cleanset_id}\")\n",
    "project_status = studio.wait_until_cleanset_ready(cleanset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the above cell completes execution, your project results are ready for review!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Cleanlab columns\n",
    "\n",
    "We can fetch the [Cleanlab columns](/studio/concepts/cleanlab_columns/) that contain the metadata of this *cleanset* using its `cleanset_id`. These columns have the same length as your original dataset and provide metadata about each individual data point, like what types of issues it exhibits and how severe these issues are.\n",
    "\n",
    "If at any point you want to re-run the remaining parts of this notebook (without creating another project), simply call `studio.download_cleanlab_columns(cleanset_id)` with the `cleanset_id` printed from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanlab_row_ID</th>\n",
       "      <th>corrected_label</th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>label_issue_score</th>\n",
       "      <th>suggested_label</th>\n",
       "      <th>is_near_duplicate</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_cluster_id</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>outlier_score</th>\n",
       "      <th>is_initially_unlabeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.779405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.952681</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.640746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.553077</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.985484</td>\n",
       "      <td>62.87463</td>\n",
       "      <td>False</td>\n",
       "      <td>0.578622</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.681494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.628423</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.662657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.521975</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cleanlab_row_ID  corrected_label  is_label_issue  label_issue_score  \\\n",
       "0                1              NaN           False           0.779405   \n",
       "1                2              NaN           False           0.640746   \n",
       "2                3              NaN            True           0.985484   \n",
       "3                4              NaN           False           0.681494   \n",
       "4                5              NaN           False           0.662657   \n",
       "\n",
       "   suggested_label  is_near_duplicate  near_duplicate_score  \\\n",
       "0              NaN               True              0.952681   \n",
       "1              NaN              False              0.553077   \n",
       "2         62.87463              False              0.578622   \n",
       "3              NaN              False              0.628423   \n",
       "4              NaN              False              0.521975   \n",
       "\n",
       "   near_duplicate_cluster_id  is_outlier  outlier_score  \\\n",
       "0                          0       False       0.000522   \n",
       "1                       <NA>       False       0.000351   \n",
       "2                       <NA>       False       0.000766   \n",
       "3                       <NA>       False       0.000755   \n",
       "4                       <NA>       False       0.000884   \n",
       "\n",
       "   is_initially_unlabeled  \n",
       "0                   False  \n",
       "1                   False  \n",
       "2                   False  \n",
       "3                   False  \n",
       "4                   False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleanlab_columns_df = studio.download_cleanlab_columns(cleanset_id)\n",
    "cleanlab_columns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review detected data issues "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae62094-1244-4cee-ad2b-030c23de2ff0",
   "metadata": {},
   "source": [
    "**Optional: Initialize helper methods to better visualize numeric and string columns based on colored values**\n",
    "\n",
    "",
    "Coloring helps us clearly understand data entry errors for this particular tutorial dataset, but is optional for your own datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Callable, Dict, Optional\n",
    "from IPython.core.display import HTML\n",
    "import matplotlib.colors\n",
    "\n",
    "\n",
    "def color_calc(value: float):\n",
    "    \"\"\"\n",
    "    Calculate color based on the given value. Intended for the range of 0 to 100. No error checking is done.\n",
    "\n",
    "    Parameters:\n",
    "    value (int or float): Value based on which the color is determined.\n",
    "\n",
    "    Returns:\n",
    "    str: Hexadecimal color code.\n",
    "    \"\"\"\n",
    "    if value <= 50:\n",
    "        r = 1.0\n",
    "        g = (value / 50) * 194.0 / 255.0 + 61.0 / 255.0\n",
    "        b = 61.0 / 255.0\n",
    "    else:\n",
    "        r = (100 - value) / 50\n",
    "        g = 1.0\n",
    "        b = 0.0\n",
    "    hex_color = matplotlib.colors.to_hex((r, g, b))\n",
    "    return hex_color\n",
    "\n",
    "\n",
    "def grade_to_color(value: float):\n",
    "    \"\"\"\n",
    "    Format numerical grade value with background color. Intended for the range of 0 to 100. No error checking is done.\n",
    "\n",
    "    Parameters:\n",
    "    value (int or float): Numerical grade value.\n",
    "\n",
    "    Returns:\n",
    "    str: HTML div string with background color based on grade value.\n",
    "    \"\"\"\n",
    "    hex_color = color_calc(value)\n",
    "    return (\n",
    "        f'<div style=\"background-color: {hex_color}; text-align: center;\">{value}</div>'\n",
    "    )\n",
    "\n",
    "\n",
    "def highlight_notes(note: str):\n",
    "    \"\"\"\n",
    "    Format notes with background color based on keywords. Notes are returned as is if no keywords are found.\n",
    "\n",
    "    Parameters:\n",
    "    note (str): Text of notes.\n",
    "\n",
    "    Returns:\n",
    "    str: HTML div string with background color based on keywords found in notes.\n",
    "    \"\"\"\n",
    "    if \"missed\" in note:\n",
    "        value = 40\n",
    "    elif \"cheated\" in note:\n",
    "        value = 0\n",
    "    elif \"great participation\" in note:\n",
    "        value = 100\n",
    "    else:\n",
    "        return note  # default (no color)\n",
    "\n",
    "    hex_color = color_calc(value)\n",
    "    return f'<div style=\"background-color: {hex_color};\">{note}</div>'\n",
    "\n",
    "\n",
    "_TUTORIAL_FORMATTERS = {\n",
    "    \"exam_1\": grade_to_color,\n",
    "    \"exam_2\": grade_to_color,\n",
    "    \"exam_3\": grade_to_color,\n",
    "    \"given_label\": grade_to_color,\n",
    "    \"suggested_label\": grade_to_color,\n",
    "    \"notes\": highlight_notes,\n",
    "}\n",
    "\n",
    "\n",
    "def display(df, formatters: Optional[Dict[str, Callable]] = None):\n",
    "    \"\"\"\n",
    "    Display DataFrame with formatted columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame to display.\n",
    "\n",
    "    Returns:\n",
    "    IPython.core.display.HTML: HTML representation of formatted DataFrame.\n",
    "    \"\"\"\n",
    "    if formatters is None:\n",
    "        formatters = {}\n",
    "    return HTML(df.to_html(escape=False, formatters=formatters, index=False))\n",
    "\n",
    "\n",
    "disable_pretty_print = (\n",
    "    False  # set to True to disable pretty printing when displaying DataFrames\n",
    ")\n",
    "\n",
    "optional_df_display_formatters = None if disable_pretty_print else _TUTORIAL_FORMATTERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details about all of the returned Cleanlab columns and their meanings can be found in [this guide](/studio/concepts/cleanlab_columns/). In this tutorial, we focus on columns related to label issues, outliers and near duplicates:\n",
    "- **is_label_issue** indicates that the original value in the column you chose as the class label appears incorrect for a particular row (perhaps due to data entry error, or accidental mislabeling). For such data, consider correcting this value to the `suggested_label` value if it seems more appropriate.\n",
    "- **label_issue_score** represents the severity of the label issue in each row (on a scale of 0-1 with 1 indicating the most severe instances of the issue).\n",
    "- **is_outlier** indicates that a particular row is an outlier in the dataset.\n",
    "- **outlier_score** represents the severity of the outlier issue in each row (on a scale of 0-1 with 1 indicating the most severe instances of the issue).\n",
    "- **is_near_duplicate** indicates that a particular row is a near(or exact) duplicate of another row in the dataset.\n",
    "- **near_duplicate_score** represents the severity of the near duplicate issue in each row (on a scale of 0-1 with 1 indicating the most severe instances of the issue).\n",
    "\n",
    "### Label issues\n",
    "Let's take a look at the label quality in our dataset. We first create a `given_label` column in our DataFrame to clearly indicate the class label originally assigned to each data point in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataset with the cleanlab columns\n",
    "combined_dataset_df = df.merge(cleanlab_columns_df, left_index=True, right_index=True)\n",
    "\n",
    "# Set a \"given_label\" column to the original label\n",
    "combined_dataset_df.rename(columns={\"final_score\": \"given_label\"}, inplace=True)\n",
    "\n",
    "# Store the column names of the dataset for visualization\n",
    "DATASET_COLUMNS = df.columns.drop(\"final_score\").tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see which data points are estimated to be mislabeled (i.e. have potentially erroneous values in the class label column), we filter by `is_label_issue`. We sort by `label_issue_score` to see which of these data points are *most likely* mislabeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>stud_ID</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>label_issue_score</th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>659</td>\n",
       "      <td><div style=\"background-color: #a8ff00; text-align: center;\">67</div></td>\n",
       "      <td><div style=\"background-color: #24ff00; text-align: center;\">93</div></td>\n",
       "      <td><div style=\"background-color: #24ff00; text-align: center;\">93</div></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff813d; text-align: center;\">17.4</div></td>\n",
       "      <td><div style=\"background-color: #51ff00; text-align: center;\">84.1853179932</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td><div style=\"background-color: #1aff00; text-align: center;\">95</div></td>\n",
       "      <td><div style=\"background-color: #ff3d3d; text-align: center;\">0</div></td>\n",
       "      <td><div style=\"background-color: #8fff00; text-align: center;\">72</div></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff3d3d; text-align: center;\">0.0</div></td>\n",
       "      <td><div style=\"background-color: #edff00; text-align: center;\">53.5097465515</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>318</td>\n",
       "      <td><div style=\"background-color: #ffdc3d; text-align: center;\">41</div></td>\n",
       "      <td><div style=\"background-color: #3dff00; text-align: center;\">88</div></td>\n",
       "      <td><div style=\"background-color: #0aff00; text-align: center;\">98</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed class frequently -10</div></td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff3d3d; text-align: center;\">0.0</div></td>\n",
       "      <td><div style=\"background-color: #97ff00; text-align: center;\">70.3309936523</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td><div style=\"background-color: #0fff00; text-align: center;\">97</div></td>\n",
       "      <td><div style=\"background-color: #47ff00; text-align: center;\">86</div></td>\n",
       "      <td><div style=\"background-color: #ebff00; text-align: center;\">54</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed homework frequently -10</div></td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff3d3d; text-align: center;\">0.0</div></td>\n",
       "      <td><div style=\"background-color: #c7ff00; text-align: center;\">61.021068573</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>367</td>\n",
       "      <td><div style=\"background-color: #70ff00; text-align: center;\">78</div></td>\n",
       "      <td><div style=\"background-color: #ff3d3d; text-align: center;\">0</div></td>\n",
       "      <td><div style=\"background-color: #47ff00; text-align: center;\">86</div></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff3d3d; text-align: center;\">0.0</div></td>\n",
       "      <td><div style=\"background-color: #e5ff00; text-align: center;\">55.161655426</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_ranked_by_label_issue_score = combined_dataset_df[\n",
    "    combined_dataset_df[\"is_label_issue\"]\n",
    "].sort_values(\"label_issue_score\", ascending=False)\n",
    "\n",
    "columns_to_display = DATASET_COLUMNS + [\n",
    "    \"label_issue_score\",\n",
    "    \"is_label_issue\",\n",
    "    \"given_label\",\n",
    "    \"suggested_label\",\n",
    "]\n",
    "display(\n",
    "    samples_ranked_by_label_issue_score.head(5)[columns_to_display],\n",
    "    formatters=optional_df_display_formatters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, looking at the first row above: the student recieved grades of 67, 93, and 93 on their exams, but ended up with a final grade of 17.4/100, which is certainly a data entry error!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "Let's take a look at the outliers detected in the dataset. To view the outliers, we again filter using `is_outlier` column and sort by `outlier_score` in descending order to view most likely outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>stud_ID</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>outlier_score</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>509</td>\n",
       "      <td><div style=\"background-color: #b2ff00; text-align: center;\">65</div></td>\n",
       "      <td><div style=\"background-color: #4cff00; text-align: center;\">85</div></td>\n",
       "      <td><div style=\"background-color: #66ff00; text-align: center;\">80</div></td>\n",
       "      <td><div style=\"background-color: #00ff00;\">great participation +10</div></td>\n",
       "      <td>0.168298</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #5bff00; text-align: center;\">82.2</div></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>613</td>\n",
       "      <td><div style=\"background-color: #24ff00; text-align: center;\">93</div></td>\n",
       "      <td><div style=\"background-color: #d6ff00; text-align: center;\">58</div></td>\n",
       "      <td><div style=\"background-color: #99ff00; text-align: center;\">70</div></td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>0.166990</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #53ff00; text-align: center;\">83.8</div></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>889</td>\n",
       "      <td><div style=\"background-color: #80ff00; text-align: center;\">75</div></td>\n",
       "      <td><div style=\"background-color: #2eff00; text-align: center;\">91</div></td>\n",
       "      <td><div style=\"background-color: #a3ff00; text-align: center;\">68</div></td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>0.166341</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #49ff00; text-align: center;\">85.7</div></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td><div style=\"background-color: #33ff00; text-align: center;\">90</div></td>\n",
       "      <td><div style=\"background-color: #a8ff00; text-align: center;\">67</div></td>\n",
       "      <td><div style=\"background-color: #75ff00; text-align: center;\">77</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed class frequently -10</div></td>\n",
       "      <td>0.155053</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #72ff00; text-align: center;\">77.6</div></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td><div style=\"background-color: #33ff00; text-align: center;\">90</div></td>\n",
       "      <td><div style=\"background-color: #a8ff00; text-align: center;\">67</div></td>\n",
       "      <td><div style=\"background-color: #75ff00; text-align: center;\">77</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed class frequently -10</div></td>\n",
       "      <td>0.155053</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #90ff00; text-align: center;\">71.7</div></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_ranked_by_outlier_score = combined_dataset_df[\n",
    "    combined_dataset_df[\"is_outlier\"]\n",
    "].sort_values(\"outlier_score\", ascending=False)\n",
    "\n",
    "columns_to_display = DATASET_COLUMNS + [\n",
    "    \"outlier_score\",\n",
    "    \"is_outlier\",\n",
    "    \"given_label\",\n",
    "    \"suggested_label\",\n",
    "]\n",
    "display(\n",
    "    samples_ranked_by_outlier_score.head(5)[columns_to_display],\n",
    "    formatters=optional_df_display_formatters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note that the student well or poorly in 2 out of 3 exams, whereas the performance is opposite in the third one. This most likely indicates an outlier issue either related to data entry or evaluation of the exam.\n",
    "\n",
    "### Near Duplicates\n",
    "For viewing near duplicates in the dataset, we filter the rows using `is_near_duplicate` column and then sort using `near_duplicate_score` as well as `near_duplicate_cluster_id`. The rows that belong to the same set of near duplicates have the same `near_duplicate_cluster_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>stud_ID</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>is_near_duplicate</th>\n",
       "      <th>near_duplicate_cluster_id</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td><div style=\"background-color: #70ff00; text-align: center;\">78</div></td>\n",
       "      <td><div style=\"background-color: #d6ff00; text-align: center;\">58</div></td>\n",
       "      <td><div style=\"background-color: #47ff00; text-align: center;\">86</div></td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td><div style=\"background-color: #50ff00; text-align: center;\">84.4</div></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>549</td>\n",
       "      <td><div style=\"background-color: #70ff00; text-align: center;\">78</div></td>\n",
       "      <td><div style=\"background-color: #d6ff00; text-align: center;\">58</div></td>\n",
       "      <td><div style=\"background-color: #47ff00; text-align: center;\">86</div></td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td><div style=\"background-color: #50ff00; text-align: center;\">84.3</div></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td><div style=\"background-color: #47ff00; text-align: center;\">86</div></td>\n",
       "      <td><div style=\"background-color: #66ff00; text-align: center;\">80</div></td>\n",
       "      <td><div style=\"background-color: #38ff00; text-align: center;\">89</div></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td><div style=\"background-color: #60ff00; text-align: center;\">81.2</div></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>953</td>\n",
       "      <td><div style=\"background-color: #47ff00; text-align: center;\">86</div></td>\n",
       "      <td><div style=\"background-color: #66ff00; text-align: center;\">80</div></td>\n",
       "      <td><div style=\"background-color: #38ff00; text-align: center;\">89</div></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td><div style=\"background-color: #59ff00; text-align: center;\">82.5</div></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td><div style=\"background-color: #8aff00; text-align: center;\">73</div></td>\n",
       "      <td><div style=\"background-color: #66ff00; text-align: center;\">80</div></td>\n",
       "      <td><div style=\"background-color: #1aff00; text-align: center;\">95</div></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td><div style=\"background-color: #62ff00; text-align: center;\">80.7</div></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>562</td>\n",
       "      <td><div style=\"background-color: #8aff00; text-align: center;\">73</div></td>\n",
       "      <td><div style=\"background-color: #66ff00; text-align: center;\">80</div></td>\n",
       "      <td><div style=\"background-color: #1aff00; text-align: center;\">95</div></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td><div style=\"background-color: #54ff00; text-align: center;\">83.5</div></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_ranked_by_near_duplicate_score = combined_dataset_df[\n",
    "    combined_dataset_df[\"is_near_duplicate\"]\n",
    "].sort_values([\"near_duplicate_score\", \"near_duplicate_cluster_id\"], ascending=False)\n",
    "\n",
    "columns_to_display = DATASET_COLUMNS + [\n",
    "    \"near_duplicate_score\",\n",
    "    \"is_near_duplicate\",\n",
    "    \"near_duplicate_cluster_id\",\n",
    "    \"given_label\",\n",
    "    \"suggested_label\",\n",
    "]\n",
    "display(\n",
    "    samples_ranked_by_near_duplicate_score.head(6)[columns_to_display],\n",
    "    formatters=optional_df_display_formatters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly note that some rows are duplicated in this dataset, which can affect the performance of model trained on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the dataset based on the detected issues\n",
    "\n",
    "Since the results of this analysis appear reasonable, let's use the Cleanlab columns to improve the quality of our dataset. For your own datasets, which actions you should take to remedy the detected issues will depend on what you are using the data for. No single action is going to be the best choice across all datasets, so we caution against blindly copying the actions we perform below. \n",
    "\n",
    "For data marked as `label_issue`, we create a new `corrected_label` column, which will be the given label for data without detected label issues, and the `suggested_label` for data with detected label issues. We are not using the results for outlier and near duplicates issues to improve the dataset, as that requires more careful consideration and domain expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_label = np.where(\n",
    "    combined_dataset_df[\"is_label_issue\"],\n",
    "    combined_dataset_df[\"suggested_label\"],\n",
    "    combined_dataset_df[\"given_label\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's actually make a new version of our dataset with these changes.\n",
    "\n",
    "We craft a new DataFrame from the original, applying corrections and exclusions, and then use this DataFrame to save the new dataset in a separate CSV file. The new dataset is a CSV file that looks just like our original dataset --- you can use it as a plug-in replacement to get more reliable results in your ML and Analytics pipelines, without any change in your existing modeling code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset_filename = \"improved_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the original dataset\n",
    "fixed_dataset = combined_dataset_df[DATASET_COLUMNS].copy()\n",
    "\n",
    "# Add the corrected label column\n",
    "fixed_dataset[\"final_score\"] = corrected_label\n",
    "\n",
    "# Save improved dataset to new CSV file\n",
    "fixed_dataset.to_csv(new_dataset_filename, index=False)\n",
    "print(f\"Adjusted dataset saved to {new_dataset_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}