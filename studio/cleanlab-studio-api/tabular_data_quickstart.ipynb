{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Issues in Structured/Tabular Datasets\n",
    "\n",
    "<head>\n",
    "  <meta name=\"title\" content=\"Automatically Find and Fix Issues in Any Tabular Dataset\"/>\n",
    "  <meta property=\"og:title\" content=\"Automatically Find and Fix Issues in Any Tabular Dataset\"/>\n",
    "  <meta name=\"twitter:title\" content=\"Automatically Find and Fix Issues in Any Tabular Dataset\" />\n",
    "  <meta name=\"image\" content=\"/img/tabularissues.png\" />\n",
    "  <meta property=\"og:image\" content=\"/img/tabularissues.png\" />\n",
    "  <meta name=\"description\" content=\"A quick tutorial on improving your structured data via Data-Centric AI.\"  />\n",
    "  <meta property=\"og:description\" content=\"A quick tutorial on improving your structured data via Data-Centric AI.\" />\n",
    "  <meta name=\"twitter:description\" content=\"A quick tutorial on improving your structured data via Data-Centric AI.\" />\n",
    "</head>\n",
    "\n",
    "This is the recommended quickstart tutorial for using Cleanlab Studio's [Python API](/studio/quickstart/api/) to analyze tabular datasets (Excel/database files with columns of numeric/string values).\n",
    "\n",
    "In this tutorial, we demonstrate the metadata Cleanlab Studio automatically generates for any classification dataset stored as a data table. This metadata (returned as [Cleanlab Columns](/studio/concepts/cleanlab_columns)) helps you discover various problems in your dataset and understand their severity. This entire notebook is run using the `cleanlab_studio` Python package, so you can audit your datasets programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import dependencies\n",
    "\n",
    "Make sure you have `wget` installed to run this tutorial.\n",
    "You can use pip to install all other packages required for this tutorial as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib cleanlab-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the dataset for this tutorial, which is stored as a standard data table in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://s.cleanlab.ai/grades-tabular-demo.csv -P data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSV file contains the following columns:\n",
    "\n",
    "```\n",
    "stud_ID,exam_1,exam_2,exam_3,notes,letter_grade\n",
    "f48f73,53,77,93,,C\n",
    "0bd4e7,81,64,80,great participation +10,B\n",
    "e1795d,74,88,97,,B\n",
    "<id of student>,<grade on exam 1>,<grade on exam 2>,<grade on exam 3>,<optional notes>,<overall letter grade for student>\n",
    "...\n",
    "```\n",
    "\n",
    "You can similarly format any other tabular dataset and run the rest of this tutorial. Details on how to format your dataset can be found in [this guide](/studio/concepts/datasets/), which also outlines other format options. Cleanlab Studio works out-of-the-box for messy tabular datasets with arbitrary numeric/string columns that may contain missing values.\n",
    "\n",
    "Our dataset for this tutorial is a collection of student grades and other information about each student. Suppose we are interested detecting incorrect values (data entry errors) in students' final `letter_grade`, which belongs to one of five categories: **A**, **B**, **C**, **D**, **F**. In machine learning terminology, this can be considered a **multi-class classification** dataset, where the `letter_grade` column is viewed as **class label** for each row (student) in the table.\n",
    "\n",
    "If you were say aiming to detect miscategorized products in an e-commerce dataset, you would select the product-category column as the class label. Cleanlab Studio can auto-detect erroneous values not only in categorical columns but also in any numeric column, as demonstrated in our [regression tutorial](/studio/tutorials/cleanlab-studio-api/regression/). Refer to our [data entry errors tutorial](/studio/tutorials/cleanlab-studio-api/data_entry/) for a general example of how to auto-detect errors in multiple heterogeneous columns of an arbitrary tabular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.getcwd()\n",
    "dataset_path = os.path.join(BASE_PATH, \"data/grades-tabular-demo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset into Cleanlab Studio\n",
    "\n",
    "Use your API key to instantiate a `Studio` object, which can be used to analyze your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab_studio import Studio\n",
    "\n",
    "# you can find your Cleanlab Studio API key by going to app.cleanlab.ai/upload,\n",
    "# clicking \"Upload via Python API\", and copying the API key there\n",
    "API_KEY = \"<insert your API key>\"\n",
    "\n",
    "# initialize studio object\n",
    "studio = Studio(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next load the dataset into Cleanlab Studio (more details/options can be found in [this guide](/studio/concepts/datasets/)). This may take a while for big datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = studio.upload_dataset(dataset_path, dataset_name=\"student-grades\")\n",
    "print(f\"Dataset ID: {dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch a Project\n",
    "\n",
    "Let's now create a project using this dataset. A Cleanlab Studio project will automatically train ML models to provide AI-based analysis of your dataset.\n",
    "\n",
    "By default Cleanlab Studio uses all columns as predictive features except the label column. But since `stud_ID` is not a predictive feature, we explicitly specify the columns that will be used as input variables for the model `(exam_1, exam_2, exam_3, notes)` columns in this dataset. We also specify the column containing the class labels for each data point (`letter_grade` column in this dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = studio.create_project(\n",
    "    dataset_id=dataset_id,\n",
    "    project_name=\"student-grades project\",\n",
    "    modality=\"tabular\",\n",
    "    task_type=\"multi-class\",\n",
    "    model_type=\"regular\",\n",
    "    label_column=\"letter_grade\",\n",
    "    feature_columns=['exam_1', 'exam_2', 'exam_3', 'notes']\n",
    "\n",
    ")\n",
    "print(f\"Project successfully created and training has begun! project_id: {project_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the project has been launched successfully and you see your `project_id` you can feel free to close this notebook. It will take some time for Cleanlab\u2019s AI to train on your data and analyze it. Come back after training is complete (you will receive an email) and continue with the notebook to review your results.\n",
    "\n",
    "You should only execute the above cell once per dataset. After launching the project, you can poll for its status to programmatically wait until the results are ready for review. Each project creates a [cleanset](/studio/concepts/cleanset/), an improved version of your original dataset that contains additional metadata for helping you clean up the data. The next code cell simply waits until this *cleanset* has been created.\n",
    "\n",
    "**Warning!** For big datasets, this next cell may take a long time to execute while Cleanlab's AI model is training. If your notebook has timed out during this process, then you can resume work by re-running the below cell (which should return the `cleanset_id` instantly if the project has completed training). Do not re-run the above cell and create a new project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanset_id = studio.get_latest_cleanset_id(project_id)\n",
    "print(f\"cleanset_id: {cleanset_id}\")\n",
    "project_status = studio.poll_cleanset_status(cleanset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the above cell completes execution, your project results are ready for review!  At this point, you can optionally view your project in the [Cleanlab Studio web interface](https://app.cleanlab.ai/) and interactively improve your dataset. However this tutorial will stick with a fully programmatic workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Cleanlab columns\n",
    "\n",
    "We can fetch the [Cleanlab columns](/studio/concepts/cleanlab_columns/) that contain the metadata of this *cleanset* using its `cleanset_id`. These columns have the same length as your original dataset and provide metadata about each individual data point, like what types of issues it exhibits and severe these issues are.\n",
    "\n",
    "If at any point you want to re-run the remaining parts of this notebook (without creating another project), simply call `studio.download_cleanlab_columns(cleanset_id)` with the `cleanset_id` printed from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanlab_row_ID</th>\n",
       "      <th>corrected_label</th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>label_issue_score</th>\n",
       "      <th>suggested_label</th>\n",
       "      <th>suggested_label_confidence_score</th>\n",
       "      <th>is_ambiguous</th>\n",
       "      <th>ambiguous_score</th>\n",
       "      <th>is_well_labeled</th>\n",
       "      <th>is_near_duplicate</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_cluster_id</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>outlier_score</th>\n",
       "      <th>is_initially_unlabeled</th>\n",
       "      <th>has_rare_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.178143</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.740559</td>\n",
       "      <td>False</td>\n",
       "      <td>0.848316</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.431745</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.154428</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.766985</td>\n",
       "      <td>False</td>\n",
       "      <td>0.756479</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.125321</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.185642</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.753580</td>\n",
       "      <td>False</td>\n",
       "      <td>0.722060</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.550396</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.021067</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.296633</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.629907</td>\n",
       "      <td>False</td>\n",
       "      <td>0.887160</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.458981</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.039498</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.329882</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.516878</td>\n",
       "      <td>False</td>\n",
       "      <td>0.933320</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.107241</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.033416</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cleanlab_row_ID corrected_label  is_label_issue  label_issue_score  \\\n",
       "0                1            <NA>           False           0.178143   \n",
       "1                2            <NA>           False           0.154428   \n",
       "2                3            <NA>           False           0.185642   \n",
       "3                4            <NA>           False           0.296633   \n",
       "4                5            <NA>           False           0.329882   \n",
       "\n",
       "  suggested_label  suggested_label_confidence_score  is_ambiguous  \\\n",
       "0            <NA>                          0.740559         False   \n",
       "1            <NA>                          0.766985         False   \n",
       "2            <NA>                          0.753580         False   \n",
       "3            <NA>                          0.629907         False   \n",
       "4            <NA>                          0.516878         False   \n",
       "\n",
       "   ambiguous_score  is_well_labeled  is_near_duplicate  near_duplicate_score  \\\n",
       "0         0.848316            False              False              0.431745   \n",
       "1         0.756479            False              False              0.001234   \n",
       "2         0.722060            False              False              0.550396   \n",
       "3         0.887160            False              False              0.458981   \n",
       "4         0.933320            False              False              0.107241   \n",
       "\n",
       "   near_duplicate_cluster_id  is_outlier  outlier_score  \\\n",
       "0                       <NA>       False       0.019050   \n",
       "1                       <NA>       False       0.125321   \n",
       "2                       <NA>       False       0.021067   \n",
       "3                       <NA>       False       0.039498   \n",
       "4                       <NA>       False       0.033416   \n",
       "\n",
       "   is_initially_unlabeled  has_rare_class  \n",
       "0                   False           False  \n",
       "1                   False           False  \n",
       "2                   False           False  \n",
       "3                   False           False  \n",
       "4                   False           False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanlab_columns_df = studio.download_cleanlab_columns(cleanset_id)\n",
    "cleanlab_columns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50441390-da47-4eca-8549-4c1360cb03cd",
   "metadata": {},
   "source": [
    "**Optional: Initialize visualization helper functions**\n",
    "\n",
    "",
    "We define some rule-based coloring functions below to better visualize the numeric and string columns in this dataset.\n",
    "Coloring helps us clearly understand data entry errors for this particular tutorial dataset, but is optional for your own datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Callable, Dict, Optional\n",
    "from IPython.core.display import HTML\n",
    "import matplotlib.colors\n",
    "\n",
    "def color_calc(value: int):\n",
    "    \"\"\"\n",
    "    Calculate color based on the given value. Intended for the range of 0 to 100. No error checking is done.\n",
    "    \n",
    "    Parameters:\n",
    "    value (int or float): Value based on which the color is determined.\n",
    "    \n",
    "    Returns:\n",
    "    str: Hexadecimal color code.\n",
    "    \"\"\"\n",
    "    if value <= 50:\n",
    "        r = 1.0\n",
    "        g = (value / 50) * 194.0 / 255.0 + 61.0 / 255.0\n",
    "        b = 61.0 / 255.0\n",
    "    else:\n",
    "        r = (100 - value) / 50\n",
    "        g = 1.0\n",
    "        b = 0.0\n",
    "    hex_color = matplotlib.colors.to_hex((r, g, b))\n",
    "    return hex_color\n",
    "\n",
    "def grade_to_color(value: int):\n",
    "    \"\"\"\n",
    "    Format numerical grade value with background color. Intended for the range of 0 to 100. No error checking is done.\n",
    "    \n",
    "    Parameters:\n",
    "    value (int or float): Numerical grade value.\n",
    "    \n",
    "    Returns:\n",
    "    str: HTML div string with background color based on grade value.\n",
    "    \"\"\"\n",
    "    hex_color = color_calc(value)\n",
    "    return f'<div style=\"background-color: {hex_color}; text-align: center;\">{value}</div>'\n",
    "\n",
    "def letter_grade_to_color(grade: str):\n",
    "    \"\"\"\n",
    "    Format letter grade with background color to match the numerical grade. No error checking is done.\n",
    "    \n",
    "    Parameters:\n",
    "    grade (str): Letter grade.\n",
    "    \n",
    "    Returns:\n",
    "    str: HTML div string with background color based on letter grade.\n",
    "    \"\"\"\n",
    "    grade_map = {'A': 100, 'B': 75, 'C': 50, 'D': 25, 'F': 0}\n",
    "    value = grade_map.get(grade, 0)  # default to 0 if grade is not found\n",
    "    hex_color = color_calc(value)\n",
    "    return f'<div style=\"background-color: {hex_color}; text-align: center;\">{grade}</div>'\n",
    "\n",
    "def highlight_notes(note: str):\n",
    "    \"\"\"\n",
    "    Format notes with background color based on keywords. Notes are returned as is if no keywords are found.\n",
    "    \n",
    "    Parameters:\n",
    "    note (str): Text of notes.\n",
    "    \n",
    "    Returns:\n",
    "    str: HTML div string with background color based on keywords found in notes.\n",
    "    \"\"\"\n",
    "    if 'missed' in note:\n",
    "        value = 40\n",
    "    elif 'cheated' in note:\n",
    "        value = 0\n",
    "    elif 'great participation' in note:\n",
    "        value = 100\n",
    "    else:\n",
    "        return note # default (no color)\n",
    "\n",
    "    hex_color = color_calc(value)\n",
    "    return f'<div style=\"background-color: {hex_color};\">{note}</div>'\n",
    "\n",
    "_TUTORIAL_FORMATTERS = {\n",
    "    'exam_1': grade_to_color,\n",
    "    'exam_2': grade_to_color,\n",
    "    'exam_3': grade_to_color,\n",
    "    'given_label': letter_grade_to_color,\n",
    "    'suggested_label': letter_grade_to_color,\n",
    "    'notes': highlight_notes\n",
    "}\n",
    "    \n",
    "\n",
    "def display(df, formatters: Optional[Dict[str, Callable]] = None):\n",
    "    \"\"\"\n",
    "    Display DataFrame with formatted columns.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame to display.\n",
    "    \n",
    "    Returns:\n",
    "    IPython.core.display.HTML: HTML representation of formatted DataFrame.\n",
    "    \"\"\"\n",
    "    if formatters is None:\n",
    "        formatters = {}\n",
    "    return HTML(df.to_html(escape=False, formatters=formatters, index=False))\n",
    "\n",
    "\n",
    "disable_pretty_print = False  # set to True to disable pretty printing when displaying DataFrames\n",
    "\n",
    "optional_df_display_formatters = None if disable_pretty_print else _TUTORIAL_FORMATTERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review detected data issues \n",
    "\n",
    "Details about all of the returned Cleanlab columns and their meanings can be found in [this guide](/studio/concepts/cleanlab_columns/). Here we briefly showcase some of the Cleanlab columns that correspond to issues detected in our tutorial dataset:\n",
    "- **Label issue** indicates the original value in the column you chose as the class label appears incorrect for this row (perhaps due to data entry error, or accidental mislabeling). For such data, consider correcting this value to the `suggested_label` value if it seems more appropriate.\n",
    "- **Ambiguous** indicates this data point is a *borderline case*, which might be appropriately described by more than one class label or none of the options at all. Multiple people might disagree on how to label this data point, so you might consider refining your annotation instructions to clarify how to handle data points like this if your data are human-labeled.\n",
    "- **Outlier** indicates this row is very different from the rest of the rows in your dataset (looks atypical). The presence of outliers may indicate problems in your data sources, consider deleting such data from your dataset if appropriate.\n",
    "\n",
    "The rows exhibiting each type of issue are indicated with boolean values in the respective `is_<issue>` column, and the severity of this issue in each row is quantified in the respective `<issue>_score` column (on a scale of 0-1 with 1 indicating the most severe instances of the issue).\n",
    "\n",
    "Let's go through some of the Cleanlab columns and types of data issues, starting with label issues. We first create a `given_label` column in our dataframe to clearly indicate the class label originally assigned to each data point in this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Combine the dataset with the cleanlab columns\n",
    "combined_dataset_df = df.merge(cleanlab_columns_df, left_index=True, right_index=True)\n",
    "\n",
    "# Set a \"given_label\" column to the original label\n",
    "combined_dataset_df.rename(columns={\"letter_grade\": \"given_label\"}, inplace=True)\n",
    "\n",
    "# Store the column names of the dataset for visualization\n",
    "DATASET_COLUMNS = df.columns.drop(\"letter_grade\").tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding label issues\n",
    "\n",
    "To see which data points are estimated to be mislabeled (i.e. have potentially erroneous values in the class label column), we filter by `is_label_issue`. We sort by `label_issue_score` to see which of these data points are *most likely* mislabeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>stud_ID</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>label_issue_score</th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ee538b</td>\n",
       "      <td><div style=\"background-color: #00ff00; text-align: center;\">100</div></td>\n",
       "      <td><div style=\"background-color: #00ff00; text-align: center;\">100</div></td>\n",
       "      <td><div style=\"background-color: #05ff00; text-align: center;\">99</div></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967053</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff3d3d; text-align: center;\">F</div></td>\n",
       "      <td><div style=\"background-color: #00ff00; text-align: center;\">A</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>db4bcf</td>\n",
       "      <td><div style=\"background-color: #8fff00; text-align: center;\">72</div></td>\n",
       "      <td><div style=\"background-color: #24ff00; text-align: center;\">93</div></td>\n",
       "      <td><div style=\"background-color: #0aff00; text-align: center;\">98</div></td>\n",
       "      <td><div style=\"background-color: #00ff00;\">great participation +10</div></td>\n",
       "      <td>0.960134</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff3d3d; text-align: center;\">F</div></td>\n",
       "      <td><div style=\"background-color: #00ff00; text-align: center;\">A</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8a0a87</td>\n",
       "      <td><div style=\"background-color: #adff00; text-align: center;\">66</div></td>\n",
       "      <td><div style=\"background-color: #ff3d3d; text-align: center;\">0</div></td>\n",
       "      <td><div style=\"background-color: #70ff00; text-align: center;\">78</div></td>\n",
       "      <td><div style=\"background-color: #ff3d3d;\">cheated on exam, gets 0pts</div></td>\n",
       "      <td>0.957181</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #00ff00; text-align: center;\">A</div></td>\n",
       "      <td><div style=\"background-color: #ff3d3d; text-align: center;\">F</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0bdad5</td>\n",
       "      <td><div style=\"background-color: #94ff00; text-align: center;\">71</div></td>\n",
       "      <td><div style=\"background-color: #ff3d3d; text-align: center;\">0</div></td>\n",
       "      <td><div style=\"background-color: #5cff00; text-align: center;\">82</div></td>\n",
       "      <td><div style=\"background-color: #ff3d3d;\">cheated on exam, gets 0pts</div></td>\n",
       "      <td>0.944614</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #00ff00; text-align: center;\">A</div></td>\n",
       "      <td><div style=\"background-color: #ff3d3d; text-align: center;\">F</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34ccdd</td>\n",
       "      <td><div style=\"background-color: #33ff00; text-align: center;\">90</div></td>\n",
       "      <td><div style=\"background-color: #00ff00; text-align: center;\">100</div></td>\n",
       "      <td><div style=\"background-color: #38ff00; text-align: center;\">89</div></td>\n",
       "      <td><div style=\"background-color: #00ff00;\">great participation +10</div></td>\n",
       "      <td>0.944509</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff3d3d; text-align: center;\">F</div></td>\n",
       "      <td><div style=\"background-color: #00ff00; text-align: center;\">A</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_ranked_by_label_issue_score = combined_dataset_df.sort_values(\"label_issue_score\", ascending=False)\n",
    "\n",
    "columns_to_display = DATASET_COLUMNS + [\"label_issue_score\", \"is_label_issue\", \"given_label\", \"suggested_label\"]\n",
    "display(samples_ranked_by_label_issue_score.head(5)[columns_to_display], formatters=optional_df_display_formatters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in each of these rows, the `given_label` (i.e. final letter grade) really does seem wrong. Data entry and labeling is an error-prone process and mistakes are made! Luckily we can easily correct these data points by just using Cleanlab's `suggested_label` above, which seems like a much more suitable final `letter_grade` value in most cases.\n",
    "\n",
    "While the boolean flags above can help estimate the overall label error rate, the numeric scores help decide what data to prioritize for review. You can alternatively ignore these boolean `is_label_issue` flags and filter the data by thresholding the `label_issue_score` yourself (if say you find the default thresholds produce false positives/negatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ambiguous samples\n",
    "\n",
    "Next, let's look at the ambiguous examples in the dataset. Many of these students perform well in at least 2 out of 3 subjects, and their grade is brought down by poor performance in one of the subjects or missing homework frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>stud_ID</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>ambiguous_score</th>\n",
       "      <th>is_ambiguous</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9f7f44</td>\n",
       "      <td><div style=\"background-color: #c7ff00; text-align: center;\">61</div></td>\n",
       "      <td><div style=\"background-color: #b2ff00; text-align: center;\">65</div></td>\n",
       "      <td><div style=\"background-color: #00ff00; text-align: center;\">100</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed homework frequently -10</div></td>\n",
       "      <td>0.983134</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff9e3d; text-align: center;\">D</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600f0b</td>\n",
       "      <td><div style=\"background-color: #e6ff00; text-align: center;\">55</div></td>\n",
       "      <td><div style=\"background-color: #94ff00; text-align: center;\">71</div></td>\n",
       "      <td><div style=\"background-color: #0aff00; text-align: center;\">98</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed homework frequently -10</div></td>\n",
       "      <td>0.975925</td>\n",
       "      <td>False</td>\n",
       "      <td><div style=\"background-color: #00ff00; text-align: center;\">A</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5d086b</td>\n",
       "      <td><div style=\"background-color: #5cff00; text-align: center;\">82</div></td>\n",
       "      <td><div style=\"background-color: #1fff00; text-align: center;\">94</div></td>\n",
       "      <td><div style=\"background-color: #05ff00; text-align: center;\">99</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed class frequently -10</div></td>\n",
       "      <td>0.972961</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #80ff00; text-align: center;\">B</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5b2f76</td>\n",
       "      <td><div style=\"background-color: #05ff00; text-align: center;\">99</div></td>\n",
       "      <td><div style=\"background-color: #47ff00; text-align: center;\">86</div></td>\n",
       "      <td><div style=\"background-color: #1aff00; text-align: center;\">95</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed class frequently -10</div></td>\n",
       "      <td>0.972619</td>\n",
       "      <td>False</td>\n",
       "      <td><div style=\"background-color: #80ff00; text-align: center;\">B</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5b2d9a</td>\n",
       "      <td><div style=\"background-color: #1fff00; text-align: center;\">94</div></td>\n",
       "      <td><div style=\"background-color: #1aff00; text-align: center;\">95</div></td>\n",
       "      <td><div style=\"background-color: #33ff00; text-align: center;\">90</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed class frequently -10</div></td>\n",
       "      <td>0.961089</td>\n",
       "      <td>False</td>\n",
       "      <td><div style=\"background-color: #80ff00; text-align: center;\">B</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a93747</td>\n",
       "      <td><div style=\"background-color: #00ff00; text-align: center;\">100</div></td>\n",
       "      <td><div style=\"background-color: #66ff00; text-align: center;\">80</div></td>\n",
       "      <td><div style=\"background-color: #70ff00; text-align: center;\">78</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed class frequently -10</div></td>\n",
       "      <td>0.952505</td>\n",
       "      <td>False</td>\n",
       "      <td><div style=\"background-color: #ffff3d; text-align: center;\">C</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42155a</td>\n",
       "      <td><div style=\"background-color: #e0ff00; text-align: center;\">56</div></td>\n",
       "      <td><div style=\"background-color: #66ff00; text-align: center;\">80</div></td>\n",
       "      <td><div style=\"background-color: #6bff00; text-align: center;\">79</div></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.952427</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff3d3d; text-align: center;\">F</div></td>\n",
       "      <td><div style=\"background-color: #ffff3d; text-align: center;\">C</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>e8901f</td>\n",
       "      <td><div style=\"background-color: #9eff00; text-align: center;\">69</div></td>\n",
       "      <td><div style=\"background-color: #33ff00; text-align: center;\">90</div></td>\n",
       "      <td><div style=\"background-color: #47ff00; text-align: center;\">86</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed homework frequently -10</div></td>\n",
       "      <td>0.949782</td>\n",
       "      <td>False</td>\n",
       "      <td><div style=\"background-color: #ffff3d; text-align: center;\">C</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>b2a3ca</td>\n",
       "      <td><div style=\"background-color: #d1ff00; text-align: center;\">59</div></td>\n",
       "      <td><div style=\"background-color: #1fff00; text-align: center;\">94</div></td>\n",
       "      <td><div style=\"background-color: #66ff00; text-align: center;\">80</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed homework frequently -10</div></td>\n",
       "      <td>0.944547</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #80ff00; text-align: center;\">B</div></td>\n",
       "      <td><div style=\"background-color: #ff9e3d; text-align: center;\">D</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>612ebd</td>\n",
       "      <td><div style=\"background-color: #b2ff00; text-align: center;\">65</div></td>\n",
       "      <td><div style=\"background-color: #61ff00; text-align: center;\">81</div></td>\n",
       "      <td><div style=\"background-color: #80ff00; text-align: center;\">75</div></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.944378</td>\n",
       "      <td>False</td>\n",
       "      <td><div style=\"background-color: #ffff3d; text-align: center;\">C</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_ranked_by_ambiguous_score = combined_dataset_df.sort_values(\"ambiguous_score\", ascending=False)\n",
    "\n",
    "columns_to_display = DATASET_COLUMNS + [\"ambiguous_score\", \"is_ambiguous\", \"given_label\", \"suggested_label\"]\n",
    "display(samples_ranked_by_ambiguous_score.head(10)[columns_to_display], formatters=optional_df_display_formatters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "Next, let's look at the outlier examples in the dataset. Many of these students fall right on the border between two final letter grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>stud_ID</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>outlier_score</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4787de</td>\n",
       "      <td><div style=\"background-color: #8aff00; text-align: center;\">73</div></td>\n",
       "      <td><div style=\"background-color: #52ff00; text-align: center;\">84</div></td>\n",
       "      <td><div style=\"background-color: #a3ff00; text-align: center;\">68</div></td>\n",
       "      <td><div style=\"background-color: #00ff00;\">great participation +10</div></td>\n",
       "      <td>0.180820</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff9e3d; text-align: center;\">D</div></td>\n",
       "      <td><div style=\"background-color: #80ff00; text-align: center;\">B</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228dc0</td>\n",
       "      <td><div style=\"background-color: #b2ff00; text-align: center;\">65</div></td>\n",
       "      <td><div style=\"background-color: #4cff00; text-align: center;\">85</div></td>\n",
       "      <td><div style=\"background-color: #66ff00; text-align: center;\">80</div></td>\n",
       "      <td><div style=\"background-color: #00ff00;\">great participation +10</div></td>\n",
       "      <td>0.179532</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #80ff00; text-align: center;\">B</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93af9d</td>\n",
       "      <td><div style=\"background-color: #7aff00; text-align: center;\">76</div></td>\n",
       "      <td><div style=\"background-color: #99ff00; text-align: center;\">70</div></td>\n",
       "      <td><div style=\"background-color: #8aff00; text-align: center;\">73</div></td>\n",
       "      <td><div style=\"background-color: #00ff00;\">great participation +10</div></td>\n",
       "      <td>0.170726</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #80ff00; text-align: center;\">B</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8bfb9a</td>\n",
       "      <td><div style=\"background-color: #80ff00; text-align: center;\">75</div></td>\n",
       "      <td><div style=\"background-color: #2eff00; text-align: center;\">91</div></td>\n",
       "      <td><div style=\"background-color: #a3ff00; text-align: center;\">68</div></td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>0.170343</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #80ff00; text-align: center;\">B</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fd8db2</td>\n",
       "      <td><div style=\"background-color: #33ff00; text-align: center;\">90</div></td>\n",
       "      <td><div style=\"background-color: #a8ff00; text-align: center;\">67</div></td>\n",
       "      <td><div style=\"background-color: #75ff00; text-align: center;\">77</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed class frequently -10</div></td>\n",
       "      <td>0.165090</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff9e3d; text-align: center;\">D</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7f6511</td>\n",
       "      <td><div style=\"background-color: #33ff00; text-align: center;\">90</div></td>\n",
       "      <td><div style=\"background-color: #a8ff00; text-align: center;\">67</div></td>\n",
       "      <td><div style=\"background-color: #75ff00; text-align: center;\">77</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed class frequently -10</div></td>\n",
       "      <td>0.165090</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff9e3d; text-align: center;\">D</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>b4a1fe</td>\n",
       "      <td><div style=\"background-color: #f5ff00; text-align: center;\">52</div></td>\n",
       "      <td><div style=\"background-color: #1aff00; text-align: center;\">95</div></td>\n",
       "      <td><div style=\"background-color: #8fff00; text-align: center;\">72</div></td>\n",
       "      <td><div style=\"background-color: #00ff00;\">great participation +10</div></td>\n",
       "      <td>0.161698</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #80ff00; text-align: center;\">B</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>e1ac6f</td>\n",
       "      <td><div style=\"background-color: #24ff00; text-align: center;\">93</div></td>\n",
       "      <td><div style=\"background-color: #d6ff00; text-align: center;\">58</div></td>\n",
       "      <td><div style=\"background-color: #99ff00; text-align: center;\">70</div></td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>0.161023</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff9e3d; text-align: center;\">D</div></td>\n",
       "      <td><div style=\"background-color: #80ff00; text-align: center;\">B</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8d904d</td>\n",
       "      <td><div style=\"background-color: #8aff00; text-align: center;\">73</div></td>\n",
       "      <td><div style=\"background-color: #8aff00; text-align: center;\">73</div></td>\n",
       "      <td><div style=\"background-color: #7aff00; text-align: center;\">76</div></td>\n",
       "      <td><div style=\"background-color: #ffd83d;\">missed class frequently -10</div></td>\n",
       "      <td>0.160402</td>\n",
       "      <td>True</td>\n",
       "      <td><div style=\"background-color: #ff9e3d; text-align: center;\">D</div></td>\n",
       "      <td><NA></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10ed39</td>\n",
       "      <td><div style=\"background-color: #57ff00; text-align: center;\">83</div></td>\n",
       "      <td><div style=\"background-color: #94ff00; text-align: center;\">71</div></td>\n",
       "      <td><div style=\"background-color: #99ff00; text-align: center;\">70</div></td>\n",
       "      <td><div style=\"background-color: #00ff00;\">great participation +10</div></td>\n",
       "      <td>0.154319</td>\n",
       "      <td>False</td>\n",
       "      <td><div style=\"background-color: #ff9e3d; text-align: center;\">D</div></td>\n",
       "      <td><div style=\"background-color: #80ff00; text-align: center;\">B</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_ranked_by_outlier_score = combined_dataset_df.sort_values(\"outlier_score\", ascending=False)\n",
    "\n",
    "columns_to_display = DATASET_COLUMNS + [\"outlier_score\", \"is_outlier\", \"given_label\", \"suggested_label\"]\n",
    "display(samples_ranked_by_outlier_score.head(10)[columns_to_display], formatters=optional_df_display_formatters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Near duplicates\n",
    "\n",
    "Now let's look at near duplicates. Some of these examples have really almost identical, but the `given_label` is different. Note that the near duplicate data points each have an associated `near_duplicate_cluster_id` integer.  Data points that share the same IDs are near duplicates of each other, so you can use this column to find the near duplicates of any data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 42 sets of near duplicate rows in the dataset.\n"
     ]
    }
   ],
   "source": [
    "n_near_duplicate_sets = len(set(combined_dataset_df.loc[combined_dataset_df[\"near_duplicate_cluster_id\"].notna(), \"near_duplicate_cluster_id\"]))\n",
    "print(f\"There are {n_near_duplicate_sets} sets of near duplicate rows in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the near duplicates with cluster IDs 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>stud_ID</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>is_near_duplicate</th>\n",
       "      <th>given_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>745c23</td>\n",
       "      <td>89</td>\n",
       "      <td>95</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.89761</td>\n",
       "      <td>True</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6be392</td>\n",
       "      <td>89</td>\n",
       "      <td>95</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.89761</td>\n",
       "      <td>True</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "near_duplicate_cluster_id = 0  # play with this value to see other sets of near duplicates\n",
    "selected_samples_by_near_duplicate_cluster_id = combined_dataset_df.query(\"near_duplicate_cluster_id == @near_duplicate_cluster_id\")\n",
    "\n",
    "columns_to_display = [\"stud_ID\",\"exam_1\",\"exam_2\",\"exam_3\",\"notes\", \"near_duplicate_score\", \"is_near_duplicate\", \"given_label\"]\n",
    "display(selected_samples_by_near_duplicate_cluster_id[columns_to_display])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>stud_ID</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>is_near_duplicate</th>\n",
       "      <th>given_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24d6f2</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>97</td>\n",
       "      <td>cheated on exam, gets 0pts</td>\n",
       "      <td>0.953227</td>\n",
       "      <td>True</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7630c7</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>99</td>\n",
       "      <td>cheated on exam, gets 0pts</td>\n",
       "      <td>0.949133</td>\n",
       "      <td>True</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>d4d286</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>cheated on exam, gets 0pts</td>\n",
       "      <td>0.953227</td>\n",
       "      <td>True</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1c1ee0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>96</td>\n",
       "      <td>cheated on exam, gets 0pts</td>\n",
       "      <td>0.938130</td>\n",
       "      <td>True</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "near_duplicate_cluster_id = 1  # play with this value to see other sets of near duplicates\n",
    "selected_samples_by_near_duplicate_cluster_id = combined_dataset_df.query(\"near_duplicate_cluster_id == @near_duplicate_cluster_id\")\n",
    "\n",
    "columns_to_display = [\"stud_ID\",\"exam_1\",\"exam_2\",\"exam_3\",\"notes\", \"near_duplicate_score\", \"is_near_duplicate\", \"given_label\"]\n",
    "display(selected_samples_by_near_duplicate_cluster_id[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the dataset based on the detected issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the results of this analysis appear reasonable, let's use the Cleanlab columns to improve the quality of our dataset. For your own datasets, which actions you should take to remedy the detected issues will depend on what you are using the data for. No single action is going to be the best choice across all datasets, so we caution against blindly copying the actions we perform below. \n",
    "\n",
    "For data marked as `label_issue`, we create a new `corrected_label` column, which will be the given label for data without detected label issues, and the `suggested_label` for data with detected label issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_label = np.where(combined_dataset_df[\"is_label_issue\"],\n",
    "                           combined_dataset_df[\"suggested_label\"],\n",
    "                           combined_dataset_df[\"given_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data marked as outlier or ambiguous, we will exclude them from our dataset here for demonstration purposes. Here we create a boolean vector `rows_to_exclude` to track which data points will be excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_exclude = combined_dataset_df[\"is_outlier\"] | combined_dataset_df[\"is_ambiguous\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each set of near duplicates, we only want to keep one of the data points that share a common `near_duplicate_cluster_id` (so that the resulting dataset will no longer contain any near duplicates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_duplicates_to_exclude = combined_dataset_df['is_near_duplicate'] & combined_dataset_df['near_duplicate_cluster_id'].duplicated(keep='first')\n",
    "rows_to_exclude |= near_duplicates_to_exclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the total amount of excluded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding 114 examples (out of 941)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Excluding {rows_to_exclude.sum()} examples (out of {len(combined_dataset_df)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's actually make a new version of our dataset with these changes.\n",
    "\n",
    "We craft a new dataframe from the original, applying corrections and exclusions, and then use this dataframe to save the new dataset in a separate CSV file. The new dataset is a CSV file that looks just like our original dataset -- you can use it as a plug-in replacement to get more reliable results in your ML and Analytics pipelines, without any change in your existing modeling code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset_filename = \"improved_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted dataset saved to improved_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Fetch the original dataset\n",
    "fixed_dataset = combined_dataset_df[DATASET_COLUMNS].copy()\n",
    "\n",
    "# Add the corrected label column \n",
    "fixed_dataset[\"letter_grade\"] = corrected_label\n",
    "\n",
    "# Automatically exclude selected rows\n",
    "fixed_dataset = fixed_dataset[~rows_to_exclude]\n",
    "\n",
    "# Save improved dataset to new CSV file\n",
    "fixed_dataset.to_csv(new_dataset_filename, index=False)\n",
    "print(f\"Adjusted dataset saved to {new_dataset_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Cleanlab Studio is not just for labeled datasets. You can follow this tutorial to auto-detect erroneous values in *any* categorical column of a table, as well as impute all missing values in this column, by selecting it as the label column in your Cleanlab Studio Project. Refer to our [data entry errors tutorial](/studio/tutorials/cleanlab-studio-api/data_entry/) for a general example of auto-detecting errors (and imputing missing values) across multiple heterogeneous columns of an arbitrary tabular dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}