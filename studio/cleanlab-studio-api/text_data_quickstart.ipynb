{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Issues in Text Datasets\n",
    "\n",
    "<head>\n",
    "  <meta name=\"title\" content=\"Automatically Find and Fix Issues in Any Text Dataset\"/>\n",
    "  <meta property=\"og:title\" content=\"Automatically Find and Fix Issues in Any Text Dataset\"/>\n",
    "  <meta name=\"twitter:title\" content=\"Automatically Find and Fix Issues in Any Text Dataset\" />\n",
    "  <meta name=\"image\" content=\"/img/textissues.png\" />\n",
    "  <meta property=\"og:image\" content=\"/img/textissues.png\" />\n",
    "  <meta name=\"description\" content=\"A quick tutorial on improving your existing data via Data-Centric AI.\"  />\n",
    "  <meta property=\"og:description\" content=\"A quick tutorial on improving your existing data via Data-Centric AI.\" />\n",
    "  <meta name=\"twitter:description\" content=\"A quick tutorial on improving your existing data via Data-Centric AI.\" />\n",
    "</head>\n",
    "\n",
    "This is the recommended quickstart tutorial for analyzing text datasets via the Cleanlab Studio's [Python API](/studio/quickstart/api/).\n",
    "\n",
    "In this tutorial, we demonstrate the metadata Cleanlab Studio automatically generates for any text classification dataset. This metadata (returned as [Cleanlab Columns](/studio/concepts/cleanlab_columns)) helps you discover various problems in your dataset and understand their severity. This entire notebook is run using the `cleanlab_studio` Python package, so you can audit your datasets programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import dependencies\n",
    "\n",
    "Make sure you have `wget` installed to run this tutorial. You can use pip to install all other packages required for this tutorial as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install cleanlab-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch and view dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the dataset for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/\n",
    "!wget -nc https://cleanlab-public.s3.amazonaws.com/Datasets/banking-text-quickstart-v1.csv -O data/banking-text-quickstart.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll use a variant of the [BANKING77](https://paperswithcode.com/dataset/banking77-oos) text dataset. This is a **multi-class classification** dataset where customer service requests are labeled as belonging to one of *K* classes (intent categories).\n",
    "\n",
    "We can view the first few rows of our dataset below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.getcwd()\n",
    "dataset_path = os.path.join(BASE_PATH, \"data/banking-text-quickstart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i need to cancel my recent transfer as soon as possible. i made an error there. please help before it goes through.</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is there a fee when i thought there would be no fees?</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why can't my beneficiary access my account?</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>does it cost extra to send out more than one card?</td>\n",
       "      <td>getting_spare_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can i change my pin at an atm?</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  text  \\\n",
       "0  i need to cancel my recent transfer as soon as possible. i made an error there. please help before it goes through.   \n",
       "1                                                            why is there a fee when i thought there would be no fees?   \n",
       "2                                                                          why can't my beneficiary access my account?   \n",
       "3                                                                   does it cost extra to send out more than one card?   \n",
       "4                                                                                       can i change my pin at an atm?   \n",
       "\n",
       "                      label  \n",
       "0           cancel_transfer  \n",
       "1  card_payment_fee_charged  \n",
       "2   beneficiary_not_allowed  \n",
       "3        getting_spare_card  \n",
       "4                change_pin  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(dataset_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used in the tutorial is stored in a standard CSV file containing the following columns:\n",
    "\n",
    "```\n",
    "text,label\n",
    "<a text example>,<a class label>\n",
    "\"<a text example with quotes, to escape commas as column separators>\",<another class label>\n",
    "...\n",
    "```\n",
    "\n",
    "You can similarly format any other text dataset and run the rest of this tutorial. Details on how to format your dataset can be found in [this guide](/studio/concepts/datasets/), which also outlines other format options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset into Cleanlab Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our dataset, let's load it into Cleanlab Studio and conduct our analysis. Use your API key to instantiate a `studio` object, which analyzes your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab_studio import Studio\n",
    "\n",
    "# you can find your Cleanlab Studio API key by going to studio.cleanlab.ai/upload,\n",
    "# clicking \"Upload via Python API\", and copying the API key there\n",
    "API_KEY = \"<insert your API key>\"\n",
    "\n",
    "# initialize studio object\n",
    "studio = Studio(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into Cleanlab Studio (more details/options can be found in [this guide](/studio/concepts/datasets/)). This may take a while for big datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_id = studio.upload_dataset(dataset_path, dataset_name=\"banking-text-quickstart\")\n",
    "print(f\"Dataset ID: {dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch a Project\n",
    "\n",
    "A Cleanlab Studio project automatically trains ML models to provide AI-based analysis of your dataset. Let's launch one.\n",
    "\n",
    "**Note**: For our `label_column` and `text_column` specified below, they happened to be called `label` and `text` for this example. The values for these arguments should be the name of the columns pertaining to your label and containing the text field in your dataset. If you have multiple text columns, please merge them into a single column as demonstrated in our [FAQ](/studio/FAQ/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = studio.create_project(\n",
    "    dataset_id=dataset_id,\n",
    "    project_name=\"banking-text-quickstart-project\",\n",
    "    modality=\"text\",\n",
    "    task_type=\"multi-class\",\n",
    "    model_type=\"regular\",\n",
    "    label_column=\"label\",\n",
    "    text_column=\"text\",\n",
    ")\n",
    "print(f\"Project successfully created and training has begun! project_id: {project_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the project has been launched successfully and you see your `project_id` you can feel free to close this notebook. It will take some time for Cleanlab\u2019s AI to train on your data and analyze it. Come back after training is complete (you will receive an email) and continue with the notebook to review your results.\n",
    "\n",
    "You should only execute the above cell once per dataset. After launching the project, you can poll for its status to programmatically wait until the results are ready for review. Each project creates a [cleanset](/studio/concepts/cleanset/), an improved version of your original dataset that contains additional metadata for helping you clean up the data. The next code cell simply waits until this [cleanset](/studio/concepts/cleanset) has been created.\n",
    "\n",
    "**Warning!** For big datasets, this next cell may take a long time to execute while Cleanlab's AI model is training. If your Jupyter notebook has timed out during this process, you can resume work by re-running the below cell (which should return instantly if the project has completed training). **Do not** create a new project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleanset_id = studio.get_latest_cleanset_id(project_id)\n",
    "print(f\"cleanset_id: {cleanset_id}\")\n",
    "project_status = studio.wait_until_cleanset_ready(cleanset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the above cell completes execution, your project results are ready for review!  At this point, you can optionally view your project in the [Cleanlab Studio web interface](https://studio.cleanlab.ai/) and interactively improve your dataset. However this tutorial will stick with a fully programmatic workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Cleanlab columns\n",
    "\n",
    "We can fetch [Cleanlab columns](/studio/concepts/cleanlab_columns/) that store metadata for this [cleanset](/studio/concepts/cleanset) using its `cleanset_id`. These columns have the same length as your original dataset and provide metadata about each individual data point, like what types of issues it exhibits and how severely.\n",
    "\n",
    "If at any point you want to re-run the remaining parts of this notebook (without creating another project), simply call `studio.download_cleanlab_columns(cleanset_id)` with the `cleanset_id` printed from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanlab_row_ID</th>\n",
       "      <th>corrected_label</th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>label_issue_score</th>\n",
       "      <th>suggested_label</th>\n",
       "      <th>suggested_label_confidence_score</th>\n",
       "      <th>is_ambiguous</th>\n",
       "      <th>ambiguous_score</th>\n",
       "      <th>is_well_labeled</th>\n",
       "      <th>is_near_duplicate</th>\n",
       "      <th>...</th>\n",
       "      <th>non_english_score</th>\n",
       "      <th>predicted_language</th>\n",
       "      <th>is_toxic</th>\n",
       "      <th>toxic_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>bias_score</th>\n",
       "      <th>is_biased</th>\n",
       "      <th>gender_bias_score</th>\n",
       "      <th>racial_bias_score</th>\n",
       "      <th>sexual_orientation_bias_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.250695</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.581173</td>\n",
       "      <td>False</td>\n",
       "      <td>0.850463</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.101501</td>\n",
       "      <td>0.326050</td>\n",
       "      <td>0.122986</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122986</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.207495</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.648213</td>\n",
       "      <td>False</td>\n",
       "      <td>0.842312</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.184326</td>\n",
       "      <td>0.134735</td>\n",
       "      <td>0.395068</td>\n",
       "      <td>False</td>\n",
       "      <td>0.395068</td>\n",
       "      <td>0.232788</td>\n",
       "      <td>0.144897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.155370</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.731616</td>\n",
       "      <td>False</td>\n",
       "      <td>0.780281</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008784</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.061584</td>\n",
       "      <td>0.159088</td>\n",
       "      <td>0.259082</td>\n",
       "      <td>False</td>\n",
       "      <td>0.259082</td>\n",
       "      <td>0.093872</td>\n",
       "      <td>0.025330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.399957</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.391870</td>\n",
       "      <td>False</td>\n",
       "      <td>0.895436</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.181763</td>\n",
       "      <td>0.377625</td>\n",
       "      <td>0.241504</td>\n",
       "      <td>False</td>\n",
       "      <td>0.241504</td>\n",
       "      <td>0.131836</td>\n",
       "      <td>0.013489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.258581</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.571155</td>\n",
       "      <td>False</td>\n",
       "      <td>0.837926</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058934</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.115234</td>\n",
       "      <td>0.543762</td>\n",
       "      <td>0.381641</td>\n",
       "      <td>False</td>\n",
       "      <td>0.381641</td>\n",
       "      <td>0.112732</td>\n",
       "      <td>0.012970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cleanlab_row_ID corrected_label  is_label_issue  label_issue_score  \\\n",
       "0                1            <NA>           False           0.250695   \n",
       "1                2            <NA>           False           0.207495   \n",
       "2                3            <NA>           False           0.155370   \n",
       "3                4            <NA>           False           0.399957   \n",
       "4                5            <NA>           False           0.258581   \n",
       "\n",
       "  suggested_label  suggested_label_confidence_score  is_ambiguous  \\\n",
       "0            <NA>                          0.581173         False   \n",
       "1            <NA>                          0.648213         False   \n",
       "2            <NA>                          0.731616         False   \n",
       "3            <NA>                          0.391870         False   \n",
       "4            <NA>                          0.571155         False   \n",
       "\n",
       "   ambiguous_score  is_well_labeled  is_near_duplicate  ...  \\\n",
       "0         0.850463             True              False  ...   \n",
       "1         0.842312             True              False  ...   \n",
       "2         0.780281             True              False  ...   \n",
       "3         0.895436            False              False  ...   \n",
       "4         0.837926             True              False  ...   \n",
       "\n",
       "   non_english_score  predicted_language  is_toxic  toxic_score  \\\n",
       "0           0.004226                <NA>     False     0.101501   \n",
       "1           0.007218                <NA>     False     0.184326   \n",
       "2           0.008784                <NA>     False     0.061584   \n",
       "3           0.004739                <NA>     False     0.181763   \n",
       "4           0.058934                <NA>     False     0.115234   \n",
       "\n",
       "   sentiment_score  bias_score  is_biased  gender_bias_score  \\\n",
       "0         0.326050    0.122986      False           0.000000   \n",
       "1         0.134735    0.395068      False           0.395068   \n",
       "2         0.159088    0.259082      False           0.259082   \n",
       "3         0.377625    0.241504      False           0.241504   \n",
       "4         0.543762    0.381641      False           0.381641   \n",
       "\n",
       "   racial_bias_score  sexual_orientation_bias_score  \n",
       "0           0.122986                       0.000018  \n",
       "1           0.232788                       0.144897  \n",
       "2           0.093872                       0.025330  \n",
       "3           0.131836                       0.013489  \n",
       "4           0.112732                       0.012970  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanlab_columns_df = studio.download_cleanlab_columns(cleanset_id)\n",
    "cleanlab_columns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review data issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details about all of the Cleanlab columns and their meanings can be found in [this guide](/studio/concepts/cleanlab_columns/). Here we briefly showcase some of the Cleanlab columns that correspond to issues detected in our tutorial dataset:\n",
    "- **Label issue** indicates the given label of this data point is likely wrong. For such data, consider correcting their label to the `suggested_label` if it seems more appropriate.\n",
    "- **Ambiguous** indicates this data point does not clearly belong to any of the classes (e.g. a borderline case). Multiple human annotators might disagree on how to label this data point, so you might consider refining your annotation instructions to clarify how to handle data points like this.\n",
    "- **Outlier** indicates this data point is very different from the rest of the data (looks atypical). The presence of outliers may indicate problems in your data sources, consider deleting such data from your dataset if appropriate.\n",
    "- **Near duplicate** indicates there are other data points that are (exactly or nearly) identical to this data point. Duplicated data points can have an outsized impact on models/analytics, so consider deleting the extra copies from your dataset if appropriate.\n",
    "\n",
    "The data points exhibiting each type of issue are indicated with boolean values in the respective `is_<issue>` column, and the severity of this issue in each data point is quantified in the respective `<issue>_score` column (on a scale of 0-1 with 1 indicating the most severe instances of the issue).\n",
    "\n",
    "Let's go through some of the Cleanlab columns and types of data issues, starting with label issues (i.e. mislabeled data). We first create a `given_label` column in our dataframe to clearly indicate the original class label originally assigned to each data point (customer service request)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Combine the dataset with the cleanlab columns\n",
    "combined_dataset_df = df.merge(cleanlab_columns_df, left_index=True, right_index=True)\n",
    "\n",
    "# Set a \"given_label\" column to the original label\n",
    "combined_dataset_df.rename(columns={\"label\": \"given_label\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see which text examples are estimated to be mislabeled, we filter by `is_label_issue`. We sort by `label_issue_score` to see which of these data points are *most likely* mislabeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_issue_score</th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>why am i being charge a fee when using an atm?</td>\n",
       "      <td>0.857160</td>\n",
       "      <td>True</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>i was charged for getting cash.</td>\n",
       "      <td>0.837559</td>\n",
       "      <td>True</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>which currencies can i used to add funds to my account?</td>\n",
       "      <td>0.792916</td>\n",
       "      <td>True</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>how do i find my new pin?</td>\n",
       "      <td>0.788946</td>\n",
       "      <td>True</td>\n",
       "      <td>visa_or_mastercard</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>can i change my pin on holiday?</td>\n",
       "      <td>0.773169</td>\n",
       "      <td>True</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        text  \\\n",
       "874           why am i being charge a fee when using an atm?   \n",
       "988                          i was charged for getting cash.   \n",
       "490  which currencies can i used to add funds to my account?   \n",
       "77                                 how do i find my new pin?   \n",
       "8                            can i change my pin on holiday?   \n",
       "\n",
       "     label_issue_score  is_label_issue              given_label  \\\n",
       "874           0.857160            True     card_about_to_expire   \n",
       "988           0.837559            True     card_about_to_expire   \n",
       "490           0.792916            True          cancel_transfer   \n",
       "77            0.788946            True       visa_or_mastercard   \n",
       "8             0.773169            True  beneficiary_not_allowed   \n",
       "\n",
       "                    suggested_label  \n",
       "874        card_payment_fee_charged  \n",
       "988        card_payment_fee_charged  \n",
       "490  supported_cards_and_currencies  \n",
       "77                       change_pin  \n",
       "8                        change_pin  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_ranked_by_label_issue_score = combined_dataset_df.query(\"is_label_issue\").sort_values(\"label_issue_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"text\", \"label_issue_score\", \"is_label_issue\", \"given_label\", \"suggested_label\"]\n",
    "display(samples_ranked_by_label_issue_score.head(5)[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in each of these examples, the `given_label` really does seem wrong (the annotated intent in the original dataset does not appear appropriate for the customer request). Data labeling is an error-prone process and annotators make mistakes! Luckily we can easily correct these data points by just using Cleanlab's `suggested_label` above, which seems like a much more suitable label in most cases.\n",
    "\n",
    "While the boolean flags above can help estimate the overall label error rate, the numeric scores help decide what data to prioritize for review. You can alternatively ignore these boolean `is_label_issue` flags and filter the data by thresholding the `label_issue_score` yourself (if say you find the default thresholds produce false positives/negatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the ambiguous examples detected in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ambiguous_score</th>\n",
       "      <th>is_ambiguous</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>i just made a top-up but it shows as pending! i use your service all the time and have never had a problem before. why does it keep showing up as pending?</td>\n",
       "      <td>0.989361</td>\n",
       "      <td>True</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>my money didnt go through after i transferred.</td>\n",
       "      <td>0.985214</td>\n",
       "      <td>True</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>lost_or_stolen_phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>how do i avoid charges in the future</td>\n",
       "      <td>0.981678</td>\n",
       "      <td>True</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>hi,  one of payment is still coming as pending for which i have already paid by card. i guess it did not processed, could you please check and update me.</td>\n",
       "      <td>0.975506</td>\n",
       "      <td>True</td>\n",
       "      <td>lost_or_stolen_phone</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>the card payment didn't work</td>\n",
       "      <td>0.974473</td>\n",
       "      <td>True</td>\n",
       "      <td>change_pin</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                           text  \\\n",
       "652  i just made a top-up but it shows as pending! i use your service all the time and have never had a problem before. why does it keep showing up as pending?   \n",
       "337                                                                                                              my money didnt go through after i transferred.   \n",
       "783                                                                                                                        how do i avoid charges in the future   \n",
       "898   hi,  one of payment is still coming as pending for which i have already paid by card. i guess it did not processed, could you please check and update me.   \n",
       "841                                                                                                                                the card payment didn't work   \n",
       "\n",
       "     ambiguous_score  is_ambiguous               given_label  \\\n",
       "652         0.989361          True           cancel_transfer   \n",
       "337         0.985214          True   beneficiary_not_allowed   \n",
       "783         0.981678          True  card_payment_fee_charged   \n",
       "898         0.975506          True      lost_or_stolen_phone   \n",
       "841         0.974473          True                change_pin   \n",
       "\n",
       "          suggested_label  \n",
       "652                  <NA>  \n",
       "337  lost_or_stolen_phone  \n",
       "783                  <NA>  \n",
       "898                  <NA>  \n",
       "841                  <NA>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_ranked_by_ambiguous_score = combined_dataset_df.query(\"is_ambiguous\").sort_values(\"ambiguous_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"text\", \"ambiguous_score\", \"is_ambiguous\", \"given_label\", \"suggested_label\"]\n",
    "display(samples_ranked_by_ambiguous_score.head(5)[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the outliers detected in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>outlier_score</th>\n",
       "      <th>is_empty_text</th>\n",
       "      <th>text_num_characters</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>p</td>\n",
       "      <td>0.989873</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>getting_spare_card</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>la trasferenza al mio conto non \u00e8 stata consentita.</td>\n",
       "      <td>0.969794</td>\n",
       "      <td>False</td>\n",
       "      <td>51</td>\n",
       "      <td>True</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>750 credit score</td>\n",
       "      <td>0.966779</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>getting_spare_card</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>my sc</td>\n",
       "      <td>0.964187</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>404Error&lt;body&gt;&lt;p&gt;InvalidUsername&lt;/p&gt;&lt;p&gt; InvalidPIN&lt;/p&gt;&lt;/body&gt;</td>\n",
       "      <td>0.963091</td>\n",
       "      <td>False</td>\n",
       "      <td>61</td>\n",
       "      <td>True</td>\n",
       "      <td>change_pin</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              text  \\\n",
       "180                                                              p   \n",
       "770            la trasferenza al mio conto non \u00e8 stata consentita.   \n",
       "676                                               750 credit score   \n",
       "528                                                          my sc   \n",
       "755  404Error<body><p>InvalidUsername</p><p> InvalidPIN</p></body>   \n",
       "\n",
       "     outlier_score  is_empty_text  text_num_characters  is_outlier  \\\n",
       "180       0.989873          False                    1        True   \n",
       "770       0.969794          False                   51        True   \n",
       "676       0.966779          False                   16        True   \n",
       "528       0.964187          False                    5        True   \n",
       "755       0.963091          False                   61        True   \n",
       "\n",
       "                 given_label suggested_label  \n",
       "180       getting_spare_card            <NA>  \n",
       "770  beneficiary_not_allowed            <NA>  \n",
       "676       getting_spare_card            <NA>  \n",
       "528  apple_pay_or_google_pay            <NA>  \n",
       "755               change_pin            <NA>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_ranked_by_outlier_score = combined_dataset_df.query(\"is_outlier\").sort_values(\"outlier_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"text\", \"outlier_score\", \"is_empty_text\", \"text_num_characters\", \"is_outlier\", \"given_label\", \"suggested_label\"]\n",
    "display(samples_ranked_by_outlier_score.head(5)[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the near duplicates detected in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 sets of near duplicate texts in the dataset.\n"
     ]
    }
   ],
   "source": [
    "n_near_duplicate_sets = len(set(combined_dataset_df.loc[combined_dataset_df[\"near_duplicate_cluster_id\"].notna(), \"near_duplicate_cluster_id\"]))\n",
    "print(f\"There are {n_near_duplicate_sets} sets of near duplicate texts in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the near duplicate data points each have an associated `near_duplicate_cluster_id` integer.  Data points that share the same IDs are near duplicates of each other, so you can use this column to find the near duplicates of any data point. And remember the near duplicates also include *exact* duplicates as well (which have `near_duplicate_score` = 1).\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_cluster_id</th>\n",
       "      <th>is_near_duplicate</th>\n",
       "      <th>given_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>what happens after my card expires?</td>\n",
       "      <td>0.894769</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>what will happen after my card expires?</td>\n",
       "      <td>0.894769</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>i have one other credit card from the us. do you take it?</td>\n",
       "      <td>0.914963</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>i have one other credit card from the us. do you take that?</td>\n",
       "      <td>0.914963</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>which type of card will i receive?</td>\n",
       "      <td>0.978388</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>visa_or_mastercard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>what type of card will i receive?</td>\n",
       "      <td>0.978388</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>visa_or_mastercard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>i can't use the app because i got mugged yesterday and they took everything. please help.</td>\n",
       "      <td>0.909358</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>lost_or_stolen_phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>i can't use the app because i got mugged yesterday and they took everything. i need some help.</td>\n",
       "      <td>0.909358</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>lost_or_stolen_phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>what do i do if my phone is stolen?</td>\n",
       "      <td>0.962170</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>lost_or_stolen_phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>what do i do if my phone was stolen?</td>\n",
       "      <td>0.962170</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>lost_or_stolen_phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>which currencies do you accept for adding money?</td>\n",
       "      <td>0.975470</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>what currencies do you accept for adding money?</td>\n",
       "      <td>0.975470</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>will i get visa or mastercard?</td>\n",
       "      <td>0.884869</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>visa_or_mastercard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>would i get a visa or mastercard?</td>\n",
       "      <td>0.884869</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>visa_or_mastercard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>my card is going to expire, what do i do?</td>\n",
       "      <td>0.917732</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>my card is about to expire, what do i do?</td>\n",
       "      <td>0.917732</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>can i top up using my apple watch?</td>\n",
       "      <td>0.879197</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>can i use my apple watch to top up?</td>\n",
       "      <td>0.879197</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>i'd prefer a mastercard.</td>\n",
       "      <td>0.919696</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>visa_or_mastercard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>i would prefer a mastercard.</td>\n",
       "      <td>0.919696</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>visa_or_mastercard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>what to do if my card is about to expire?</td>\n",
       "      <td>0.945380</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>what do i do if my card is about to expire?</td>\n",
       "      <td>0.945380</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>which atms allow me to change my pin?</td>\n",
       "      <td>0.921094</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>what atms will allow me to change my pin?</td>\n",
       "      <td>0.921094</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>i paid with my card and i was charged a fee</td>\n",
       "      <td>0.929191</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>i paid with card and i was charged a fee</td>\n",
       "      <td>0.929191</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                               text  \\\n",
       "54                                                              what happens after my card expires?   \n",
       "250                                                         what will happen after my card expires?   \n",
       "127                                       i have one other credit card from the us. do you take it?   \n",
       "759                                     i have one other credit card from the us. do you take that?   \n",
       "710                                                              which type of card will i receive?   \n",
       "197                                                               what type of card will i receive?   \n",
       "921       i can't use the app because i got mugged yesterday and they took everything. please help.   \n",
       "350  i can't use the app because i got mugged yesterday and they took everything. i need some help.   \n",
       "374                                                             what do i do if my phone is stolen?   \n",
       "965                                                            what do i do if my phone was stolen?   \n",
       "396                                                which currencies do you accept for adding money?   \n",
       "932                                                 what currencies do you accept for adding money?   \n",
       "549                                                                  will i get visa or mastercard?   \n",
       "423                                                               would i get a visa or mastercard?   \n",
       "431                                                       my card is going to expire, what do i do?   \n",
       "445                                                       my card is about to expire, what do i do?   \n",
       "596                                                              can i top up using my apple watch?   \n",
       "721                                                             can i use my apple watch to top up?   \n",
       "947                                                                        i'd prefer a mastercard.   \n",
       "718                                                                    i would prefer a mastercard.   \n",
       "864                                                       what to do if my card is about to expire?   \n",
       "753                                                     what do i do if my card is about to expire?   \n",
       "804                                                           which atms allow me to change my pin?   \n",
       "808                                                       what atms will allow me to change my pin?   \n",
       "813                                                     i paid with my card and i was charged a fee   \n",
       "877                                                        i paid with card and i was charged a fee   \n",
       "\n",
       "     near_duplicate_score  near_duplicate_cluster_id  is_near_duplicate  \\\n",
       "54               0.894769                          0               True   \n",
       "250              0.894769                          0               True   \n",
       "127              0.914963                          1               True   \n",
       "759              0.914963                          1               True   \n",
       "710              0.978388                          2               True   \n",
       "197              0.978388                          2               True   \n",
       "921              0.909358                          3               True   \n",
       "350              0.909358                          3               True   \n",
       "374              0.962170                          4               True   \n",
       "965              0.962170                          4               True   \n",
       "396              0.975470                          5               True   \n",
       "932              0.975470                          5               True   \n",
       "549              0.884869                          6               True   \n",
       "423              0.884869                          6               True   \n",
       "431              0.917732                          7               True   \n",
       "445              0.917732                          7               True   \n",
       "596              0.879197                          8               True   \n",
       "721              0.879197                          8               True   \n",
       "947              0.919696                          9               True   \n",
       "718              0.919696                          9               True   \n",
       "864              0.945380                         10               True   \n",
       "753              0.945380                         10               True   \n",
       "804              0.921094                         11               True   \n",
       "808              0.921094                         11               True   \n",
       "813              0.929191                         12               True   \n",
       "877              0.929191                         12               True   \n",
       "\n",
       "                        given_label  \n",
       "54             card_about_to_expire  \n",
       "250            card_about_to_expire  \n",
       "127  supported_cards_and_currencies  \n",
       "759  supported_cards_and_currencies  \n",
       "710              visa_or_mastercard  \n",
       "197              visa_or_mastercard  \n",
       "921            lost_or_stolen_phone  \n",
       "350            lost_or_stolen_phone  \n",
       "374            lost_or_stolen_phone  \n",
       "965            lost_or_stolen_phone  \n",
       "396  supported_cards_and_currencies  \n",
       "932  supported_cards_and_currencies  \n",
       "549              visa_or_mastercard  \n",
       "423              visa_or_mastercard  \n",
       "431            card_about_to_expire  \n",
       "445            card_about_to_expire  \n",
       "596         apple_pay_or_google_pay  \n",
       "721         apple_pay_or_google_pay  \n",
       "947              visa_or_mastercard  \n",
       "718              visa_or_mastercard  \n",
       "864            card_about_to_expire  \n",
       "753            card_about_to_expire  \n",
       "804                      change_pin  \n",
       "808         beneficiary_not_allowed  \n",
       "813        card_payment_fee_charged  \n",
       "877        card_payment_fee_charged  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the combined dataset by near_duplicate_cluster_id\n",
    "sorted_combined_dataset_df = combined_dataset_df[combined_dataset_df['is_near_duplicate']].sort_values(by=\"near_duplicate_cluster_id\")\n",
    "\n",
    "columns_to_display = [\"text\", \"near_duplicate_score\", 'near_duplicate_cluster_id', \"is_near_duplicate\", \"given_label\"]\n",
    "\n",
    "sorted_combined_dataset_df[columns_to_display]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanlab Studio can also detect potential problems in any text in your dataset, such as the occurrence of toxic language, personally identifiable information (PII), or nonsensical language (e.g. HTML/XML tags and other random strings contaminating text descriptions). The following Cleanlab columns are specific to the text fields in your dataset (see [here](/studio/concepts/cleanlab_columns/#columns-specific-to-text-data) for details).\n",
    "\n",
    "Similar to above, the `is_<issue>` column contains boolean values indicating if a text field has been identified to exhibit a particular issue, and the `<issue>_score` column contains numeric scores between 0 and 1 indicating the severity of this particular issue (1 indicates the most severe instance of the issue).\n",
    "\n",
    "Let's take a closer look at some text issues that have been flagged in our dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::note\n",
    "Text issues detection is currently only provided for *text* modality projects running in *regular* mode.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text that contains **toxic language** may have elements of hateful speech and language others may find harmful or aggressive. Identifying toxic language is vital in tasks such as content moderation and LLM training/evaluation, where appropriate action should be taken to ensure safe platforms, chatbots, or other applications depending on this dataset.\n",
    "\n",
    "Here are some examples in this dataset detected to contain toxic language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic_score</th>\n",
       "      <th>is_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>help me change my pin your garbage app is broken, the most pathetic bank and absolute worst customer service ever</td>\n",
       "      <td>0.851074</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>i'm really sick of your stupid requirements, just issue me the damn credit card!</td>\n",
       "      <td>0.832520</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>some f-ing lowlife mugged me, they stole everything including my phone. i can't use your app anymore, what can i do?</td>\n",
       "      <td>0.825195</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                     text  \\\n",
       "852     help me change my pin your garbage app is broken, the most pathetic bank and absolute worst customer service ever   \n",
       "773                                      i'm really sick of your stupid requirements, just issue me the damn credit card!   \n",
       "416  some f-ing lowlife mugged me, they stole everything including my phone. i can't use your app anymore, what can i do?   \n",
       "\n",
       "     toxic_score  is_toxic  \n",
       "852     0.851074      True  \n",
       "773     0.832520      True  \n",
       "416     0.825195      True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toxic_samples = combined_dataset_df.query(\"is_toxic\").sort_values(\"toxic_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"text\", \"toxic_score\", \"is_toxic\"]\n",
    "display(toxic_samples.head(5)[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Personally Identifiable Information (PII)** is information that could be used to identify an individual or is otherwise sensitive. Exposing PII can compromise an individual's security and hence should be safeguarded and anonymized/removed if discovered in publicly shared data.\n",
    "\n",
    "Cleanlab's [PII detection](/studio/concepts/cleanlab_columns/#personally-identifiable-information-pii) also returns two extra columns, `PII_items` and `PII_types`, which list the specific PII detected in the text and its type. Possible types of PII that can be detected are detailed in the [guide](/studio/concepts/cleanlab_columns/#personally-identifiable-information-pii) and scored according to how sensitive each type of information is.\n",
    "\n",
    "Here are some examples of PII detected in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>PII_score</th>\n",
       "      <th>is_PII</th>\n",
       "      <th>PII_types</th>\n",
       "      <th>PII_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>my card number is 4012888888881881 how do I know if it is mastercard or visa?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"credit card\"]</td>\n",
       "      <td>[\"4012888888881881\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>i just replaced my phone, do i have to make a new account? my username is gavdlin@gmail.com new phone number is 212-978-1213</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"email\", \"phone number\"]</td>\n",
       "      <td>[\"gavdlin@gmail.com\", \"212-978-1213\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>i no longer have my phone number +44 20 8356 1167, what should i do?</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"phone number\"]</td>\n",
       "      <td>[\"+44 20 8356 1167\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>i wish to cancel a transfer sent to judmunz@yahoo.com</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"email\"]</td>\n",
       "      <td>[\"judmunz@yahoo.com\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>i want to choose a new pin, name on account is alvin weber and dob 2/10/1967</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"date of birth\"]</td>\n",
       "      <td>[\"2/10/1967\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             text  \\\n",
       "68                                                  my card number is 4012888888881881 how do I know if it is mastercard or visa?   \n",
       "235  i just replaced my phone, do i have to make a new account? my username is gavdlin@gmail.com new phone number is 212-978-1213   \n",
       "485                                                          i no longer have my phone number +44 20 8356 1167, what should i do?   \n",
       "760                                                                         i wish to cancel a transfer sent to judmunz@yahoo.com   \n",
       "243                                                  i want to choose a new pin, name on account is alvin weber and dob 2/10/1967   \n",
       "\n",
       "     PII_score  is_PII                  PII_types  \\\n",
       "68         1.0    True            [\"credit card\"]   \n",
       "235        0.5    True  [\"email\", \"phone number\"]   \n",
       "485        0.5    True           [\"phone number\"]   \n",
       "760        0.5    True                  [\"email\"]   \n",
       "243        0.4    True          [\"date of birth\"]   \n",
       "\n",
       "                                 PII_items  \n",
       "68                    [\"4012888888881881\"]  \n",
       "235  [\"gavdlin@gmail.com\", \"212-978-1213\"]  \n",
       "485                   [\"+44 20 8356 1167\"]  \n",
       "760                  [\"judmunz@yahoo.com\"]  \n",
       "243                          [\"2/10/1967\"]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PII_samples = combined_dataset_df.query(\"is_PII\").sort_values(\"PII_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"text\", \"PII_score\", \"is_PII\", \"PII_types\", \"PII_items\"]\n",
    "display(PII_samples.head(5)[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-English** text includes text written in a foreign language or containing nonsensical characters (such as HTML/XML tags, identifiers, hashes, random characters). These are important to identify and remove in situations where we want to ensure the text fields in our data are understandable (e.g. if they are text descriptions intended to be read).\n",
    "\n",
    "If a text datapoint is detected to be non-English, Cleanlab Studio will predicted its language in the `predicted_language` column. If an alternative langauge cannot be predicted (this could either represent that the text contains more than one langauge, or that it contains nonsensical characters), the `predicted_language` will contain a null value.\n",
    "\n",
    "Here are some non-English examples detected in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>non_english_score</th>\n",
       "      <th>is_non_english</th>\n",
       "      <th>predicted_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>p</td>\n",
       "      <td>0.991476</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>404Error&lt;body&gt;&lt;p&gt;InvalidUsername&lt;/p&gt;&lt;p&gt; InvalidPIN&lt;/p&gt;&lt;/body&gt;</td>\n",
       "      <td>0.979175</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>la trasferenza al mio conto non \u00e8 stata consentita.</td>\n",
       "      <td>0.866523</td>\n",
       "      <td>True</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>qu\u00e9 necesito hacer para cancelar una transacci\u00f3n?</td>\n",
       "      <td>0.828047</td>\n",
       "      <td>True</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              text  \\\n",
       "180                                                              p   \n",
       "755  404Error<body><p>InvalidUsername</p><p> InvalidPIN</p></body>   \n",
       "770            la trasferenza al mio conto non \u00e8 stata consentita.   \n",
       "220              qu\u00e9 necesito hacer para cancelar una transacci\u00f3n?   \n",
       "\n",
       "     non_english_score  is_non_english predicted_language  \n",
       "180           0.991476            True               <NA>  \n",
       "755           0.979175            True               <NA>  \n",
       "770           0.866523            True            Italian  \n",
       "220           0.828047            True            Spanish  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "non_english_samples = combined_dataset_df.query(\"is_non_english\").sort_values(\"non_english_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"text\", \"non_english_score\", \"is_non_english\", \"predicted_language\"]\n",
    "display(non_english_samples.head(5)[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Informal** text contains casual language, slang, or poor writing such as improper grammar or spelling. It's presence may be noteworthy if you are expecting the text in your dataset to be well-written.\n",
    "\n",
    "Here are some examples of informal text detected in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>informal_score</th>\n",
       "      <th>spelling_issue_score</th>\n",
       "      <th>grammar_issue_score</th>\n",
       "      <th>slang_issue_score</th>\n",
       "      <th>is_informal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>my sc</td>\n",
       "      <td>0.701533</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.615330</td>\n",
       "      <td>0.888503</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>google pay top up not working.</td>\n",
       "      <td>0.700279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.881408</td>\n",
       "      <td>0.869290</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>which atm's am i able to change my pin?</td>\n",
       "      <td>0.694062</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.811346</td>\n",
       "      <td>0.868254</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>i do i top up from my apple watch?</td>\n",
       "      <td>0.674827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.925408</td>\n",
       "      <td>0.761659</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>google play top up help?</td>\n",
       "      <td>0.671472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807158</td>\n",
       "      <td>0.871522</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text  informal_score  \\\n",
       "528                                    my sc        0.701533   \n",
       "720           google pay top up not working.        0.700279   \n",
       "192  which atm's am i able to change my pin?        0.694062   \n",
       "564       i do i top up from my apple watch?        0.674827   \n",
       "476                 google play top up help?        0.671472   \n",
       "\n",
       "     spelling_issue_score  grammar_issue_score  slang_issue_score  is_informal  \n",
       "528              0.500000             0.615330           0.888503         True  \n",
       "720              0.000000             0.881408           0.869290         True  \n",
       "192              0.111111             0.811346           0.868254         True  \n",
       "564              0.000000             0.925408           0.761659         True  \n",
       "476              0.000000             0.807158           0.871522         True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "informal_samples = combined_dataset_df.query(\"is_informal\").sort_values(\"informal_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"text\", \"informal_score\", \"spelling_issue_score\", \"grammar_issue_score\", \"slang_issue_score\", \"is_informal\"]\n",
    "display(informal_samples.head(5)[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the dataset based on the detected issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the results of this analysis appear reasonable, let's use the Cleanlab columns to improve the quality of our dataset. For your own datasets, which actions you should take to remedy the detected issues will depend on what you are using the data for. No action may be the best choice for certain datasets, we caution against blindly copying the actions we perform below.\n",
    "\n",
    "For data marked as `label_issue`, we create a new `corrected_label` column, which will be the given label for data without detected label issues, and the `suggested_label` for data with detected label issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_label = np.where(combined_dataset_df[\"is_label_issue\"],\n",
    "                           combined_dataset_df[\"suggested_label\"],\n",
    "                           combined_dataset_df[\"given_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data marked as outlier or ambiguous, we will simply exclude them from our dataset. Here we create a boolean vector `rows_to_exclude` to track which data points will be excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an exclude column to keep track of the excluded data\n",
    "rows_to_exclude = combined_dataset_df[\"is_outlier\"] | combined_dataset_df[\"is_ambiguous\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each set of near duplicates, we only want to keep one of the data points that share a common `near_duplicate_cluster_id` (so that the resulting dataset will no longer contain any near duplicates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_duplicates_to_exclude = combined_dataset_df['is_near_duplicate'] & combined_dataset_df['near_duplicate_cluster_id'].duplicated(keep='first')\n",
    "\n",
    "rows_to_exclude |= near_duplicates_to_exclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note we didn't exclude the data with text issues here but you might want to in your applications. We can check the total amount of excluded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding 34 text examples (out of 1000)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Excluding {rows_to_exclude.sum()} text examples (out of {len(combined_dataset_df)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's actually make a new version of our dataset with these changes. \n",
    "\n",
    "We craft a new dataframe from the original, applying corrections and exclusions, and then use this dataframe to save the new dataset in a separate CSV file. The new dataset is a CSV file that has the same format as our original dataset -- you can use it as a plug-in replacement to get more reliable results in your ML and Analytics pipelines, without any change in your existing modeling code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset_filename = \"improved_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted dataset saved to improved_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Fetch the original dataset\n",
    "fixed_dataset = combined_dataset_df[[\"text\"]].copy()\n",
    "\n",
    "# Add the corrected label column \n",
    "fixed_dataset[\"label\"] = corrected_label\n",
    "\n",
    "# Automatically exclude selected rows\n",
    "fixed_dataset = fixed_dataset[~rows_to_exclude]\n",
    "\n",
    "# Check if the file exists before saving\n",
    "if os.path.exists(new_dataset_filename):\n",
    "    raise ValueError(f\"File {new_dataset_filename} already exists. Cannot overwite so please delete it first, or specify a different new_dataset_filename.\")\n",
    "else:\n",
    "    # Save the adjusted dataset to a CSV file\n",
    "    fixed_dataset.to_csv(new_dataset_filename, index=False)\n",
    "    print(f\"Adjusted dataset saved to {new_dataset_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to curate a text dataset for better LLM fine-tuning, here\u2019s an [example](https://github.com/cleanlab/cleanlab-tools/blob/main/fine_tuning_classification/fine_tuning_LLM_with_noisy_labels.ipynb).\n",
    "\n",
    "If you are interested in building AI Assistants connected to your company\u2019s data sources and other Retrieval-Augmented Generation applications, [reach out](https://cleanlab.ai/sales/) to learn how Cleanlab can help."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}