{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Issues in (Unsupervised) Datasets Without Labels\n",
    "\n",
    "<head>\n",
    "  <meta name=\"title\" content=\"How to detect issues in datasets without labels (unsupervised learning)\"/>\n",
    "  <meta property=\"og:title\" content=\"How to detect issues in datasets without labels (unsupervised learning)\"/>\n",
    "  <meta name=\"twitter:title\" content=\"How to detect issues in datasets without labels (unsupervised learning)\" />\n",
    "  <meta name=\"image\" content=\"/img/reviewsissues.png\" />\n",
    "  <meta property=\"og:image\" content=\"/img/reviewsissues.png\" />\n",
    "  <meta name=\"description\" content=\"Cleanlab is not just for labeled data, curate many other types of data as well.\"  />\n",
    "  <meta property=\"og:description\" content=\"Cleanlab is not just for labeled data, curate many other types of data as well.\" />\n",
    "  <meta name=\"twitter:description\" content=\"Cleanlab is not just for labeled data, curate many other types of data as well.\" />\n",
    "</head>\n",
    "\n",
    "This tutorial demonstrates how to use Cleanlab Studio's [Python API](/studio/quickstart/api/) to analyze and find issues in datasets without labels. This can be useful if you don't have a single column in your dataset that you want to predict values for but still want to find issues such as low-quality/unsafe image or text content (e.g. NSFW or blurry images, toxic or unreadable text). In machine learning nomenclature, working with such data is called *unsupervised learning* (because there is no supervised label to predict).\n",
    "\n",
    "Cleanlab Studio supports analyzing data without labels for text and image modalities. In this tutorial, we'll look at a text dataset consisting of Tweets about airlines. This tutorial can be generally used to detect issues in *any* text column of a dataset or collection of images.\n",
    "\n",
    "Note: analyzing data without labels is currently only supported in the Python API. If you require an interactive interface to improve your unsupervised dataset, please [contact us](mailto:sales@cleanlab.ai) to discuss your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U cleanlab-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from cleanlab_studio import Studio\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and Upload Dataset\n",
    "\n",
    "Our dataset for this tutorial is a collection of Tweets directed at various airlines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "We'll load the dataset into a Pandas DataFrame from a CSV file hosted in S3. The CSV file contains the following columns:\n",
    "```\n",
    "tweet_id,text\n",
    "0,@VirginAmerica What @dhepburn said.\n",
    "1,@VirginAmerica plus you've added commercials to the experience... tacky.\n",
    "<id of tweet>,<tweet text>\n",
    "```\n",
    "You can similarly format any other text or image dataset and run the rest of this tutorial. Details on how to format your dataset can be found in [this guide](/studio/concepts/datasets/), which also outlines other format options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id  \\\n",
       "0         0   \n",
       "1         1   \n",
       "2         2   \n",
       "\n",
       "                                                                       text  \n",
       "0                                       @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials to the experience... tacky.  \n",
       "2   @VirginAmerica I didn't today... Must mean I need to take another trip!  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_url = \"https://cleanlab-public.s3.amazonaws.com/StudioDemoDatasets/tweets-tutorial.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset into Cleanlab Studio\n",
    "\n",
    "First instantiate a `Studio` object, which can be used to analyze your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can find your API key by going to studio.cleanlab.ai/upload, \n",
    "# clicking \"Upload via Python API\", and copying the API key there\n",
    "API_KEY = \"<insert your API key>\"\n",
    "\n",
    "studio = Studio(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next load the dataset into Cleanlab Studio (more details/options can be found in [this guide](/studio/concepts/datasets/)). This may take a while for big datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_id = studio.upload_dataset(df, dataset_name=\"Tweets (no-labels)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch a Project\n",
    "\n",
    "Let's now create a project using this dataset. A Cleanlab Studio project will automatically train ML models to provide AI-based analysis of your dataset.\n",
    "\n",
    "Here, we explicitly set the `task_type` parameter to `unsupervised` to specify that there is *no* supervised ML training task to run. If you would like to run supervised ML training and detect label errors in a labeled dataset or **annotate unlabeled data**, instead choose another ML task type (e.g. `\"multi-class\"`, `\"multi-label\"`, or `\"regression\"`; see [this guide](/studio/concepts/projects/#machine-learning-task--dataset-type) for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = studio.create_project(\n",
    "    dataset_id=dataset_id,\n",
    "    project_name=\"Tweets (no-labels) Project\",\n",
    "    modality=\"text\",\n",
    "    task_type=\"unsupervised\",\n",
    "    model_type=\"regular\",  # text issue detection is currently only available in Regular mode\n",
    "    label_column=None,\n",
    ")\n",
    "print(f\"Project successfully created and training has begun! project_id: {project_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we specified `modality=\"text\"` because this tutorial uses a text dataset; you can specify `modality=\"image\"` if you're using a image dataset. See the documentation for [`create_project`](/studio/api/python/studio/#method-create_project) for the full set of options.\n",
    "\n",
    "Once the project has been launched successfully and you see your `project_id`, feel free to close this notebook. It will take some time for Cleanlab\u2019s AI to train on your data and analyze it. Come back after training is complete (you will receive an email) and continue with the notebook to review your results.\n",
    "\n",
    "You should only execute the above cell once per dataset. After launching the project, you can poll for its status to programmatically wait until the results are ready for review. Each project creates a [cleanset](/studio/concepts/cleanset/), an improved version of your original dataset that contains additional metadata for helping you clean up the data. The next code cell simply waits until this *cleanset* has been created.\n",
    "\n",
    "**Warning!** For big datasets, this next cell may take a long time to execute while Cleanlab's AI model is training. If your notebook has timed out during this process, you can resume work by re-running the below cell (which should return the `cleanset_id` instantly if the project has completed training). Do not re-run the above cell and create a new project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanset_id = studio.get_latest_cleanset_id(project_id)\n",
    "print(f\"cleanset_id: {cleanset_id}\")\n",
    "project_status = studio.wait_until_cleanset_ready(cleanset_id, show_cleanset_link=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the above cell completes execution, your project results are ready for review!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Cleanlab columns\n",
    "\n",
    "We can fetch the [Cleanlab columns](/studio/concepts/cleanlab_columns/) that contain the metadata of this *cleanset* using its `cleanset_id`. These columns have the same length as your original dataset and provide metadata about each individual data point, like what types of issues it exhibits and how severe these issues are.\n",
    "\n",
    "If at any point you want to re-run the remaining parts of this notebook (without creating another project), simply call `studio.download_cleanlab_columns(cleanset_id)` with the `cleanset_id` printed from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanlab_row_ID</th>\n",
       "      <th>is_near_duplicate</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_cluster_id</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>outlier_score</th>\n",
       "      <th>is_empty_text</th>\n",
       "      <th>text_num_characters</th>\n",
       "      <th>is_PII</th>\n",
       "      <th>PII_score</th>\n",
       "      <th>...</th>\n",
       "      <th>non_english_score</th>\n",
       "      <th>predicted_language</th>\n",
       "      <th>is_toxic</th>\n",
       "      <th>toxic_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>bias_score</th>\n",
       "      <th>is_biased</th>\n",
       "      <th>gender_bias_score</th>\n",
       "      <th>racial_bias_score</th>\n",
       "      <th>sexual_orientation_bias_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.399615</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.580445</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490506</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.083435</td>\n",
       "      <td>0.834229</td>\n",
       "      <td>0.380908</td>\n",
       "      <td>False</td>\n",
       "      <td>0.380908</td>\n",
       "      <td>0.152832</td>\n",
       "      <td>0.018829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.415263</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.569778</td>\n",
       "      <td>False</td>\n",
       "      <td>72</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081569</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.612305</td>\n",
       "      <td>0.142975</td>\n",
       "      <td>0.351074</td>\n",
       "      <td>False</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>0.351074</td>\n",
       "      <td>0.001138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.370318</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.609644</td>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071165</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.108826</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.159546</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159546</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.281063</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.705755</td>\n",
       "      <td>False</td>\n",
       "      <td>126</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126798</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.651855</td>\n",
       "      <td>0.145264</td>\n",
       "      <td>0.333789</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333789</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.018372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.538334</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.476579</td>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>0.320312</td>\n",
       "      <td>0.164673</td>\n",
       "      <td>0.413330</td>\n",
       "      <td>False</td>\n",
       "      <td>0.209766</td>\n",
       "      <td>0.413330</td>\n",
       "      <td>0.029282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cleanlab_row_ID  is_near_duplicate  near_duplicate_score  \\\n",
       "0                1              False              0.399615   \n",
       "1                2              False              0.415263   \n",
       "2                3              False              0.370318   \n",
       "3                4              False              0.281063   \n",
       "4                5              False              0.538334   \n",
       "\n",
       "   near_duplicate_cluster_id  is_outlier  outlier_score  is_empty_text  \\\n",
       "0                       <NA>       False       0.580445          False   \n",
       "1                       <NA>       False       0.569778          False   \n",
       "2                       <NA>       False       0.609644          False   \n",
       "3                       <NA>       False       0.705755          False   \n",
       "4                       <NA>       False       0.476579          False   \n",
       "\n",
       "   text_num_characters  is_PII  PII_score  ... non_english_score  \\\n",
       "0                   35    True        0.2  ...          0.490506   \n",
       "1                   72    True        0.2  ...          0.081569   \n",
       "2                   71    True        0.2  ...          0.071165   \n",
       "3                  126    True        0.2  ...          0.126798   \n",
       "4                   55    True        0.2  ...          0.059800   \n",
       "\n",
       "  predicted_language  is_toxic  toxic_score  sentiment_score  bias_score  \\\n",
       "0               <NA>     False     0.083435         0.834229    0.380908   \n",
       "1               <NA>     False     0.612305         0.142975    0.351074   \n",
       "2               <NA>     False     0.108826         0.573975    0.159546   \n",
       "3               <NA>     False     0.651855         0.145264    0.333789   \n",
       "4               <NA>     False     0.320312         0.164673    0.413330   \n",
       "\n",
       "   is_biased  gender_bias_score  racial_bias_score  \\\n",
       "0      False           0.380908           0.152832   \n",
       "1      False           0.014209           0.351074   \n",
       "2      False           0.000000           0.159546   \n",
       "3      False           0.333789           0.281250   \n",
       "4      False           0.209766           0.413330   \n",
       "\n",
       "  sexual_orientation_bias_score  \n",
       "0                      0.018829  \n",
       "1                      0.001138  \n",
       "2                      0.000110  \n",
       "3                      0.018372  \n",
       "4                      0.029282  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanlab_columns_df = studio.download_cleanlab_columns(cleanset_id)\n",
    "cleanlab_columns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review detected data issues \n",
    "\n",
    "Details about all of the Cleanlab columns and their meanings can be found in [this guide](/studio/concepts/cleanlab_columns/). Here we briefly showcase some of the Cleanlab columns that correspond to issues detected in our tutorial dataset. Since our dataset only has a text column, this tutorial focuses on issues specific to text fields such as the occurence of personally identifiable information (PII) and toxic language (see [here](/studio/concepts/cleanlab_columns/#columns-specific-to-text-data) for details).\n",
    "\n",
    "The data points exhibiting each type of issue are indicated with boolean values in the respective `is_<issue>` column, and the severity of this issue in each data point is quantified in the respective `<issue>_score` column (on a scale of 0-1 with 1 indicating the most severe instances of the issue).\n",
    "\n",
    "Let's take a closer look at some issues flagged in our dataset. We merged the columns from our original dataset with the Cleanlab columns (metadata) produced by Cleanlab Studio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Combine the dataset with the cleanlab columns\n",
    "combined_dataset_df = df.merge(cleanlab_columns_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Personally Identifiable Information (PII)** is information that could be used to identify an individual or is otherwise sensitive. Exposing PII can compromise an individual's security and hence should be safeguarded and anonymized/removed if discovered in publicly shared data.\n",
    "\n",
    "Cleanlab's [PII detection](https://help.cleanlab.ai/studio/concepts/cleanlab_columns/#personally-identifiable-information-pii) also returns two extra columns, `PII_items` and `PII_types`, which list the specific PII detected in the text and its type. Possible types of PII that can be detected are detailed in the [guide](https://help.cleanlab.ai/studio/concepts/cleanlab_columns/#personally-identifiable-information-pii) and scored according to how sensitive each type of information is.\n",
    "\n",
    "Here are some examples of PII detected in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>PII_score</th>\n",
       "      <th>is_PII</th>\n",
       "      <th>PII_types</th>\n",
       "      <th>PII_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>407</td>\n",
       "      <td>@VirginAmerica FYI the info@virginamerica.com email address you say to contact in password reset emails doesn't exist. Emails bounce.</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"Twitter username\", \"email\"]</td>\n",
       "      <td>[\"@VirginAmerica\", \"info@virginamerica.com\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3377</th>\n",
       "      <td>3377</td>\n",
       "      <td>@united Need to track lost luggage being shipped to me. Need ph # for human. Not automated 800-335-2247.</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"Twitter username\", \"phone number\"]</td>\n",
       "      <td>[\"@united\", \"800-335-2247\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>742</td>\n",
       "      <td>@united I send you an urgent message via eservice@united.com.  BG0KWM   Narayanan. Please respond ASAP. Also, NO local United Tel # @ KUL</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"Twitter username\", \"email\"]</td>\n",
       "      <td>[\"@united\", \"eservice@united.com\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>3872</td>\n",
       "      <td>@united  delayed about 8 hours because of missed connections due to mechanical issues on 1st flight. rebooked, but please call me 9148445695</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"Twitter username\", \"phone number\"]</td>\n",
       "      <td>[\"@united\", \"9148445695\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>960</td>\n",
       "      <td>@united iCloud it is not there yet -- PLEASE HELP 917 703 1472</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"Twitter username\", \"phone number\"]</td>\n",
       "      <td>[\"@united\", \"917 703 1472\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id  \\\n",
       "407        407   \n",
       "3377      3377   \n",
       "742        742   \n",
       "3872      3872   \n",
       "960        960   \n",
       "\n",
       "                                                                                                                                              text  \\\n",
       "407          @VirginAmerica FYI the info@virginamerica.com email address you say to contact in password reset emails doesn't exist. Emails bounce.   \n",
       "3377                                      @united Need to track lost luggage being shipped to me. Need ph # for human. Not automated 800-335-2247.   \n",
       "742      @united I send you an urgent message via eservice@united.com.  BG0KWM   Narayanan. Please respond ASAP. Also, NO local United Tel # @ KUL   \n",
       "3872  @united  delayed about 8 hours because of missed connections due to mechanical issues on 1st flight. rebooked, but please call me 9148445695   \n",
       "960                                                                                 @united iCloud it is not there yet -- PLEASE HELP 917 703 1472   \n",
       "\n",
       "      PII_score  is_PII                             PII_types  \\\n",
       "407         0.5    True         [\"Twitter username\", \"email\"]   \n",
       "3377        0.5    True  [\"Twitter username\", \"phone number\"]   \n",
       "742         0.5    True         [\"Twitter username\", \"email\"]   \n",
       "3872        0.5    True  [\"Twitter username\", \"phone number\"]   \n",
       "960         0.5    True  [\"Twitter username\", \"phone number\"]   \n",
       "\n",
       "                                         PII_items  \n",
       "407   [\"@VirginAmerica\", \"info@virginamerica.com\"]  \n",
       "3377                   [\"@united\", \"800-335-2247\"]  \n",
       "742             [\"@united\", \"eservice@united.com\"]  \n",
       "3872                     [\"@united\", \"9148445695\"]  \n",
       "960                    [\"@united\", \"917 703 1472\"]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PII_samples = combined_dataset_df.query(\"is_PII\").sort_values(\"PII_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"tweet_id\", \"text\", \"PII_score\", \"is_PII\", \"PII_types\", \"PII_items\"]\n",
    "display(PII_samples.head(5)[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text that contains **toxic language** may have elements of hateful speech and language others may find harmful or aggressive. Identifying toxic language is vital in tasks such as content moderation and LLM training/evaluation, where appropriate action should be taken to ensure safe platforms, chatbots, or other applications depending on this dataset.\n",
    "\n",
    "Here are some examples in this dataset detected to contain toxic language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic_score</th>\n",
       "      <th>is_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>1197</td>\n",
       "      <td>@united you are the worst airline in the world! From your crap website to your worthless app to your Late Flight flight. You SUCK! Just shut down.</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>2122</td>\n",
       "      <td>@united I hope your corporate office is ready to deal with the rage created by your shitty service and bullshit pilots. #UnitedAirlinesSucks</td>\n",
       "      <td>0.904785</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>2039</td>\n",
       "      <td>@united thanks for letting me sleep at DIA to ensure you ruin as much of my vacation as possible. Wait, no, fuck you. #unitedairlinessucks</td>\n",
       "      <td>0.894531</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>2566</td>\n",
       "      <td>@united no. U guys suck. I'll never fly with u again. And ur supervisors suck too.</td>\n",
       "      <td>0.894043</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>1374</td>\n",
       "      <td>@united after a Cancelled Flighted flight, and 2 delays, you lost my luggage AGAIN! You're the WORST! Disgraceful! Awful company, horrible service!</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id  \\\n",
       "1197      1197   \n",
       "2122      2122   \n",
       "2039      2039   \n",
       "2566      2566   \n",
       "1374      1374   \n",
       "\n",
       "                                                                                                                                                     text  \\\n",
       "1197   @united you are the worst airline in the world! From your crap website to your worthless app to your Late Flight flight. You SUCK! Just shut down.   \n",
       "2122         @united I hope your corporate office is ready to deal with the rage created by your shitty service and bullshit pilots. #UnitedAirlinesSucks   \n",
       "2039           @united thanks for letting me sleep at DIA to ensure you ruin as much of my vacation as possible. Wait, no, fuck you. #unitedairlinessucks   \n",
       "2566                                                                   @united no. U guys suck. I'll never fly with u again. And ur supervisors suck too.   \n",
       "1374  @united after a Cancelled Flighted flight, and 2 delays, you lost my luggage AGAIN! You're the WORST! Disgraceful! Awful company, horrible service!   \n",
       "\n",
       "      toxic_score  is_toxic  \n",
       "1197     0.912598      True  \n",
       "2122     0.904785      True  \n",
       "2039     0.894531      True  \n",
       "2566     0.894043      True  \n",
       "1374     0.890625      True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toxic_samples = combined_dataset_df.query(\"is_toxic\").sort_values(\"toxic_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"tweet_id\", \"text\", \"toxic_score\", \"is_toxic\"]\n",
    "display(toxic_samples.head(5)[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outlier** indicates this data point is very different from the rest of the data (looks atypical). The presence of outliers may indicate problems in your data sources, consider deleting such data from your dataset if appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>outlier_score</th>\n",
       "      <th>text_num_characters</th>\n",
       "      <th>is_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>@united The Opal Dragon book The Dragon (ALI) has woven his murdering ways from the Philippines to Australia http://t.co/N2fvElcYgz</td>\n",
       "      <td>0.885225</td>\n",
       "      <td>131</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@VirginAmerica did you know that suicide is the second leading cause of death among teens 10-24</td>\n",
       "      <td>0.885063</td>\n",
       "      <td>95</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>@VirginAmerica Man of steel flies to more cities though...and with more frequency too.</td>\n",
       "      <td>0.851450</td>\n",
       "      <td>86</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>.@united It's worth saying that, if you litter in Singapore, you get caned. \"But there are rules\" says @united</td>\n",
       "      <td>0.842480</td>\n",
       "      <td>110</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>@united welcome to our world, that's a snow world today. @GooseBayAirport Goose Bay, Labrador, Canada. http://t.co/4kI6Xr67nk</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>125</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>@VirginAmerica Your back of seat entertainment system does not accept credit cards that  have an apostrophe in the surname. #apostrophefail</td>\n",
       "      <td>0.836217</td>\n",
       "      <td>139</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>@united SATURDAY this morning Man dies from Ebola http://t.co/hXVVIS0VWw</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>72</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>@united So what does someone with severe anxiety do when the one person who can help him isn't next to him?</td>\n",
       "      <td>0.832567</td>\n",
       "      <td>107</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>@united Hello we are doing a world record attempt on the amount of ball point pens in a collection please could you help with a pen?</td>\n",
       "      <td>0.830536</td>\n",
       "      <td>132</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Bruh \u201c@VirginAmerica: @giannilee Turn down for what. #VXSafetyDance\u201d</td>\n",
       "      <td>0.829851</td>\n",
       "      <td>68</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             text  \\\n",
       "2292          @united The Opal Dragon book The Dragon (ALI) has woven his murdering ways from the Philippines to Australia http://t.co/N2fvElcYgz   \n",
       "10                                                @VirginAmerica did you know that suicide is the second leading cause of death among teens 10-24   \n",
       "469                                                        @VirginAmerica Man of steel flies to more cities though...and with more frequency too.   \n",
       "2811                               .@united It's worth saying that, if you litter in Singapore, you get caned. \"But there are rules\" says @united   \n",
       "1817                @united welcome to our world, that's a snow world today. @GooseBayAirport Goose Bay, Labrador, Canada. http://t.co/4kI6Xr67nk   \n",
       "418   @VirginAmerica Your back of seat entertainment system does not accept credit cards that  have an apostrophe in the surname. #apostrophefail   \n",
       "2357                                                                     @united SATURDAY this morning Man dies from Ebola http://t.co/hXVVIS0VWw   \n",
       "677                                   @united So what does someone with severe anxiety do when the one person who can help him isn't next to him?   \n",
       "2296         @united Hello we are doing a world record attempt on the amount of ball point pens in a collection please could you help with a pen?   \n",
       "361                                                                          Bruh \u201c@VirginAmerica: @giannilee Turn down for what. #VXSafetyDance\u201d   \n",
       "\n",
       "      outlier_score  text_num_characters  is_outlier  \n",
       "2292       0.885225                  131        True  \n",
       "10         0.885063                   95        True  \n",
       "469        0.851450                   86        True  \n",
       "2811       0.842480                  110        True  \n",
       "1817       0.837079                  125        True  \n",
       "418        0.836217                  139        True  \n",
       "2357       0.832924                   72        True  \n",
       "677        0.832567                  107        True  \n",
       "2296       0.830536                  132        True  \n",
       "361        0.829851                   68        True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_ranked_by_outlier_score = combined_dataset_df.query(\"is_outlier\").sort_values(\"outlier_score\", ascending=False)\n",
    "\n",
    "columns_to_display = [\"text\", \"outlier_score\", \"text_num_characters\", \"is_outlier\"]\n",
    "display(samples_ranked_by_outlier_score.head(10)[columns_to_display])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Near duplicate** indicates there are other data points that are (exactly or nearly) identical to this data point. Duplicated data points can have an outsized impact on models/analytics, so consider deleting the extra copies from your dataset if appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 sets of near duplicate texts in the dataset.\n"
     ]
    }
   ],
   "source": [
    "n_near_duplicate_sets = len(set(combined_dataset_df.loc[combined_dataset_df[\"near_duplicate_cluster_id\"].notna(), \"near_duplicate_cluster_id\"]))\n",
    "print(f\"There are {n_near_duplicate_sets} sets of near duplicate texts in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_cluster_id</th>\n",
       "      <th>is_near_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@VirginAmerica Thanks!</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>@VirginAmerica thanks!</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>@VirginAmerica thanks so much!</td>\n",
       "      <td>0.912910</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>@VirginAmerica Thank you!!</td>\n",
       "      <td>0.938341</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>@VirginAmerica Thanks!</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>@united THIS IS THE  YEAR FOR VAN GOGH FANS TO VISIT EUROPE\\nhttp://t.co/e1EOfthgAJ</td>\n",
       "      <td>0.921737</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>@United Airlines Cancelled Flights OC FLL #flight today. $700 to switch. No notice no apology. We are done flying #UnitedAirlines.</td>\n",
       "      <td>0.989779</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>@United Airlines Cancelled Flights OC FLL #flight today. $700 to switch. No notice no apology. Done flying #UnitedAirlines.</td>\n",
       "      <td>0.989779</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>@SouthwestAir sent!</td>\n",
       "      <td>0.940663</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>@SouthwestAir sent</td>\n",
       "      <td>0.940663</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows \u00d7 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    text  \\\n",
       "14                                                                                                                @VirginAmerica Thanks!   \n",
       "193                                                                                                               @VirginAmerica thanks!   \n",
       "231                                                                                                       @VirginAmerica thanks so much!   \n",
       "281                                                                                                           @VirginAmerica Thank you!!   \n",
       "331                                                                                                               @VirginAmerica Thanks!   \n",
       "...                                                                                                                                  ...   \n",
       "3462                                                 @united THIS IS THE  YEAR FOR VAN GOGH FANS TO VISIT EUROPE\\nhttp://t.co/e1EOfthgAJ   \n",
       "4176  @United Airlines Cancelled Flights OC FLL #flight today. $700 to switch. No notice no apology. We are done flying #UnitedAirlines.   \n",
       "4181         @United Airlines Cancelled Flights OC FLL #flight today. $700 to switch. No notice no apology. Done flying #UnitedAirlines.   \n",
       "4366                                                                                                                 @SouthwestAir sent!   \n",
       "4481                                                                                                                  @SouthwestAir sent   \n",
       "\n",
       "      near_duplicate_score  near_duplicate_cluster_id  is_near_duplicate  \n",
       "14                1.000000                          0               True  \n",
       "193               1.000000                          0               True  \n",
       "231               0.912910                          0               True  \n",
       "281               0.938341                          0               True  \n",
       "331               1.000000                          0               True  \n",
       "...                    ...                        ...                ...  \n",
       "3462              0.921737                         16               True  \n",
       "4176              0.989779                         17               True  \n",
       "4181              0.989779                         17               True  \n",
       "4366              0.940663                         18               True  \n",
       "4481              0.940663                         18               True  \n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the combined dataset by near_duplicate_cluster_id\n",
    "sorted_combined_dataset_df = combined_dataset_df[combined_dataset_df['is_near_duplicate']].sort_values(by=\"near_duplicate_cluster_id\")\n",
    "\n",
    "columns_to_display = [\"text\", \"near_duplicate_score\", 'near_duplicate_cluster_id', \"is_near_duplicate\"]\n",
    "\n",
    "sorted_combined_dataset_df[columns_to_display]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the near duplicate data points each have an associated `near_duplicate_cluster_id` integer.  Data points that share the same IDs are near duplicates of each other, so you can use this column to find the near duplicates of any data point. And remember the near duplicates also include *exact* duplicates as well (which have `near_duplicate_score` = 1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above only showcases a small subset of all the different types of issues and metadata that Cleanlab Studio can provide for an unsupervised dataset with no labels. See [this guide](/studio/concepts/cleanlab_columns/) for the full set of issues that Cleanlab Studio audits your data for to help you prevent problems.\n",
    "\n",
    "![Visualizing issues in an unsupervised text dataset](./assets/unsupervised-tutorial/reviewsissues.png)\n",
    "\n",
    "## Using these results\n",
    "\n",
    "Depending on your goal, you may want to take some steps to improve your dataset based on these results (i.e. by removing text detected to be low-quality or unsafe from your dataset). Alternatively, you might use the Cleanlab-generated metadata to better understand your dataset (e.g. understanding the prevalence of toxic language). Determining how to use the results of these analyses will vary based on your dataset and use case. Remember that Cleanlab Studio can also auto-detect low-quality or unsafe **images** as well. If you'd like to discuss your use case, please [contact us](mailto:sales@cleanlab.ai).\n",
    "\n",
    "![Visualizing issues in an unsupervised image dataset](./assets/unsupervised-tutorial/unsupervisedimageissues.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}