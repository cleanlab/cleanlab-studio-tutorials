{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f278ba-441a-470a-99c1-54cbd6f8cee5",
   "metadata": {},
   "source": [
    "# Using TLM via the OpenAI library to score the trustworthiness of: structured outputs, function calling, messages, and more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79715fec-e568-407b-b2f6-11aba262c9ed",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to integrate your VPC installation of Cleanlab's Trustworthy Language Model (TLM) into existing GenAI apps. You will learn how to assess the trustworthiness of OpenAI model responses, directly through the [OpenAI library](https://github.com/openai/openai-python). Existing OpenAI users: you can obtain real-time trustworthiness scores for every OpenAI response, without changing your code.\n",
    "\n",
    "Using TLM via the [OpenAI library](https://github.com/openai/openai-python) enables you to leverage OpenAI's features, while reliably scoring the trustworthiness of each response to automatically catch errors/hallucinations made by OpenAI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc04d5",
   "metadata": {},
   "source": [
    "![Getting TLM trustworthiness scores from using OpenAI API](./assets/tlm-structured-outputs/tlm-openai-api.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38dc41",
   "metadata": {},
   "source": [
    "In this tutorial, we use OpenAI's structured outputs feature to perform multi-label classification (i.e. document tagging) with trustworthiness scores from TLM. The same method can be used to score the trustworthiness of any type of output from OpenAI (not just structured outputs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce124e52-f9c4-4110-b844-3fe05a84adb8",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c07e776-adf9-4246-8a98-7d19d2fcb422",
   "metadata": {},
   "source": [
    "The Python packages required for this tutorial can be installed using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c356e4-6b02-4864-a5ff-926d991de162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (1.77.0)\n",
      "Collecting openai\n",
      "  Downloading openai-1.78.0-py3-none-any.whl (680 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.4/680.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: sniffio in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: certifi in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/Kelsey/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.77.0\n",
      "    Uninstalling openai-1.77.0:\n",
      "      Successfully uninstalled openai-1.77.0\n",
      "Successfully installed openai-1.78.0\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9bc6a28-1873-4b02-8624-16faffca9108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from openai import OpenAI\n",
    "import ast\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e18a67a-8575-43bb-9e53-74385d6fbc6a",
   "metadata": {},
   "source": [
    "## Fetch example Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65018bf-464e-4c8c-abe2-7e72c517918d",
   "metadata": {},
   "source": [
    "This tutorial uses a modified version of the [Alexa intent detection dataset](https://huggingface.co/datasets/AmazonScience/massive). \n",
    "\n",
    "Each text sample contains several statements that could correspond to multiple intents (for example controlling devices, asking for information etc). The label corresponding to each example specifies what the intent of that statement is, where there could be more than one intent corresponding to each sample. Let's take a look at the dataset below:\n",
    "\n",
    "In this tutorial, we will only run the LLM inference on 50 randomly sampled examples of this dataset as a demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43273fc-c518-46fe-b6dd-f34215552fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘massive_multilabel_classification.csv’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://cleanlab-public.s3.us-east-1.amazonaws.com/Datasets/massive_multilabel_classification.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a73bec43-dee1-473a-a926-318b1a9c11d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lets have a chat</td>\n",
       "      <td>[general_quirky]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are meeting scheduled for today</td>\n",
       "      <td>[calendar_query]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>erase all the events. resume my audio book from karl pilkington. tell me the profession of celebrity</td>\n",
       "      <td>[calendar_remove, play_audiobook, qa_factoid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thirty minute reminder on meeting for tuesday</td>\n",
       "      <td>[calendar_set]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have a nine am meeting on wednesday send me a reminder</td>\n",
       "      <td>[calendar_set]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   text  \\\n",
       "0                                                                                      lets have a chat   \n",
       "1                                                                  what are meeting scheduled for today   \n",
       "2  erase all the events. resume my audio book from karl pilkington. tell me the profession of celebrity   \n",
       "3                                                         thirty minute reminder on meeting for tuesday   \n",
       "4                                              i have a nine am meeting on wednesday send me a reminder   \n",
       "\n",
       "                                          labels  \n",
       "0                               [general_quirky]  \n",
       "1                               [calendar_query]  \n",
       "2  [calendar_remove, play_audiobook, qa_factoid]  \n",
       "3                                 [calendar_set]  \n",
       "4                                 [calendar_set]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"massive_multilabel_classification.csv\")\n",
    "data[\"labels\"] = data[\"labels\"].apply(ast.literal_eval)\n",
    "data = data.sample(50, random_state=123).reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f87254-771e-4674-aad9-1a83f08a0343",
   "metadata": {},
   "source": [
    "### Configuring API access to the TLM backend service\n",
    "\n",
    "This demo assumes that you have access to the deployed TLM backend service at the URL `http://localhost:8080/api`. You may set this up by port forwarding to your local machine as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16155f0c-f8bf-4f22-a404-a0db294de7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update your kubeconfig with credentials from the deployed cluster\n",
    "ENVIRONMENT_NAME=enterprise\n",
    "az aks get-credentials --resource-group tlm-$ENVIRONMENT_NAME-rg --name tlm-$ENVIRONMENT_NAME-cluster --overwrite-existing\n",
    "\n",
    "# Port forward the backend service to your local machine\n",
    "kubectl port-forward service/tlm-chat-backend 8080:8080 -n tlm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987f7149-3539-4210-b2e9-8926f3ac3ea5",
   "metadata": {},
   "source": [
    "You are welcome to expose the TLM API however you prefer, depending on the unique needs of your networking environment. Simply replace the base URL when instantiating the OpenAI Python client later in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba57c0-ea98-4d35-9b6e-41b8313a3f8c",
   "metadata": {},
   "source": [
    "## Obtain LLM Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94989f63-ade7-4a01-95bd-bea936f6cfce",
   "metadata": {},
   "source": [
    "First, we need to get a list of all possible classes from the given dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "763c6dcd-6a18-4833-bf94-898f1a000836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['general_quirky', 'calendar_query', 'calendar_remove',\n",
       "       'play_audiobook', 'qa_factoid'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_classes = data[\"labels\"].explode().unique()\n",
    "multilabel_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d927d3bf-b5a9-456b-abdc-e5135ca0a557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['general_quirky', 'calendar_query', 'calendar_remove',\n",
       "       'play_audiobook', 'qa_factoid', 'calendar_set', 'email_query',\n",
       "       'alarm_remove', 'social_post', 'recommendation_movies', 'qa_stock',\n",
       "       'alarm_query', 'lists_createoradd', 'iot_hue_lightchange',\n",
       "       'news_query', 'social_query', 'weather_query', 'qa_definition',\n",
       "       'iot_hue_lightoff', 'iot_hue_lightup', 'play_game',\n",
       "       'email_sendemail', 'audio_volume_mute', 'takeaway_order',\n",
       "       'lists_query', 'audio_volume_down', 'datetime_query',\n",
       "       'lists_remove', 'music_query', 'recommendation_events',\n",
       "       'cooking_recipe', 'datetime_convert', 'play_music',\n",
       "       'music_likeness', 'general_joke', 'qa_maths', 'qa_currency',\n",
       "       'email_addcontact'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf4eadf-13de-44fb-8128-b51d5e575991",
   "metadata": {},
   "source": [
    "### Prompt OpenAI "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38fc4d5-f768-430e-94f4-8eba529591ef",
   "metadata": {},
   "source": [
    "Then, we can instantiate the OpenAI client, pointing the `base_url` to TLM, which allows us to also get the trustworthiness score associated with each response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549220e5-0530-4342-af89-538a7965e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the VPC installation of TLM does not authenticate requests, but the OpenAI client requires an API key, so we pass a fake value here\n",
    "client = OpenAI(\n",
    "    api_key=\"test\",\n",
    "    base_url=\"http://localhost:8080/api\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1bbaa6-691c-4192-94ce-64c465abfb00",
   "metadata": {},
   "source": [
    "Here is an example of how we can prompt OpenAI with one sample text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5efa2ff4-1b9b-4562-b74d-c431d8db4d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what are meeting scheduled for today'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = data['text'][1]\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e8792d0-fa34-4824-8dc8-27bda83d9258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Classify the following text, using these labels for guidance: {multilabel_classes}. The text is: {sample_text}\"}  \n",
    "        ],\n",
    "    extra_body={\n",
    "        \"tlm\": {\n",
    "            \"quality_preset\": \"low\"\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9ae09aa-50ad-42ac-9dc3-d67152c0e963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedChatCompletion[NoneType](id='chat-cmpl-ac3fa423e31f4fc9', choices=[ParsedChoice[NoneType](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[NoneType](content='The text \"what are meeting scheduled for today\" can be classified under the label **\\'calendar_query\\'**.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, parsed=None, name=None), tlm={'score': 0.5979667890547007, 'metadata': {'result': {'score': 0.5979667890547007, 'completion': {'role': 'assistant', 'content': 'The text \"what are meeting scheduled for today\" can be classified under the label **\\'calendar_query\\'**.', 'logprobs': [{'logprob': -0.00033725024, 'token': 'The'}, {'logprob': -0.613089, 'token': ' text'}, {'logprob': -0.15458047, 'token': ' \"'}, {'logprob': -1.9361265e-07, 'token': 'what'}, {'logprob': 0.0, 'token': ' are'}, {'logprob': -0.061979678, 'token': ' meeting'}, {'logprob': -7.89631e-07, 'token': ' scheduled'}, {'logprob': 0.0, 'token': ' for'}, {'logprob': 0.0, 'token': ' today'}, {'logprob': -4.8425554e-06, 'token': '\"'}, {'logprob': -0.534421, 'token': ' can'}, {'logprob': -0.00018018014, 'token': ' be'}, {'logprob': -0.0001373897, 'token': ' classified'}, {'logprob': -0.6934206, 'token': ' under'}, {'logprob': -3.035214e-05, 'token': ' the'}, {'logprob': -4.465658e-05, 'token': ' label'}, {'logprob': -0.29585376, 'token': ' **'}, {'logprob': -0.31349698, 'token': \"'\"}, {'logprob': -4.3202e-07, 'token': 'calendar'}, {'logprob': 0.0, 'token': '_query'}, {'logprob': -5.8245798e-05, 'token': \"'\"}, {'logprob': -0.0031777136, 'token': '**'}, {'logprob': -0.06677501, 'token': '.'}], 'top_logprobs': [[{'logprob': -0.00033725024, 'token': 'The'}, {'logprob': -8.125338, 'token': 'This'}, {'logprob': -10.625338, 'token': 'Based'}], [{'logprob': -0.613089, 'token': ' text'}, {'logprob': -0.863089, 'token': ' appropriate'}, {'logprob': -3.863089, 'token': ' most'}], [{'logprob': -0.15458047, 'token': ' \"'}, {'logprob': -2.0295806, 'token': ' can'}, {'logprob': -5.4045806, 'token': ' fits'}], [{'logprob': -1.9361265e-07, 'token': 'what'}, {'logprob': -15.625, 'token': 'What'}, {'logprob': -17.125, 'token': ' what'}], [{'logprob': 0.0, 'token': ' are'}, {'logprob': -18.0, 'token': ' is'}, {'logprob': -18.875, 'token': 'are'}], [{'logprob': -0.061979678, 'token': ' meeting'}, {'logprob': -2.8119798, 'token': ' meetings'}, {'logprob': -11.436979, 'token': ' the'}], [{'logprob': -7.89631e-07, 'token': ' scheduled'}, {'logprob': -14.875001, 'token': ' schedule'}, {'logprob': -15.625001, 'token': 'scheduled'}], [{'logprob': 0.0, 'token': ' for'}, {'logprob': -24.125, 'token': 'for'}, {'logprob': -24.125, 'token': ' fo'}], [{'logprob': 0.0, 'token': ' today'}, {'logprob': -18.5, 'token': \" today's\"}, {'logprob': -20.875, 'token': ' tonight'}], [{'logprob': -4.8425554e-06, 'token': '\"'}, {'logprob': -12.500005, 'token': '?\"'}, {'logprob': -13.750005, 'token': '”'}], [{'logprob': -0.534421, 'token': ' can'}, {'logprob': -1.784421, 'token': ' fits'}, {'logprob': -1.909421, 'token': ' falls'}], [{'logprob': -0.00018018014, 'token': ' be'}, {'logprob': -8.62518, 'token': ' best'}, {'logprob': -15.50018, 'token': ' most'}], [{'logprob': -0.0001373897, 'token': ' classified'}, {'logprob': -9.000137, 'token': ' categorized'}, {'logprob': -11.250137, 'token': ' best'}], [{'logprob': -0.6934206, 'token': ' under'}, {'logprob': -0.6934206, 'token': ' as'}, {'logprob': -8.56842, 'token': ' using'}], [{'logprob': -3.035214e-05, 'token': ' the'}, {'logprob': -11.0000305, 'token': ' **'}, {'logprob': -11.5000305, 'token': ':'}], [{'logprob': -4.465658e-05, 'token': ' label'}, {'logprob': -10.250045, 'token': ' following'}, {'logprob': -11.625045, 'token': ' category'}], [{'logprob': -0.29585376, 'token': ' **'}, {'logprob': -1.5458537, 'token': ':'}, {'logprob': -3.5458539, 'token': \" '\"}], [{'logprob': -0.31349698, 'token': \"'\"}, {'logprob': -1.313497, 'token': 'calendar'}, {'logprob': -8.938497, 'token': '\"'}], [{'logprob': -4.3202e-07, 'token': 'calendar'}, {'logprob': -15.375, 'token': ' calendar'}, {'logprob': -15.875, 'token': 'cal'}], [{'logprob': 0.0, 'token': '_query'}, {'logprob': -17.25, 'token': ' query'}, {'logprob': -18.625, 'token': '_q'}], [{'logprob': -5.8245798e-05, 'token': \"'\"}, {'logprob': -10.125058, 'token': \".'\"}, {'logprob': -11.000058, 'token': \"'.\"}], [{'logprob': -0.0031777136, 'token': '**'}, {'logprob': -5.7531776, 'token': '**,'}, {'logprob': -17.503178, 'token': '*.'}], [{'logprob': -0.06677501, 'token': '.'}, {'logprob': -2.816775, 'token': ' as'}, {'logprob': -5.566775, 'token': ' since'}]]}}}})], created=1747249077, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007eeb76-9324-44a4-b08c-a2994d6e9e53",
   "metadata": {},
   "source": [
    "The returned object matches what OpenAI would ordinarily return, except it has an additional `tlm` field from TLM with extra information like the trustworthiness `score` and other `metadata`. This way you can use TLM as a drop-in replacement for OpenAI in any application (and will still get back the same responses you'd get directly from OpenAI).  Let's parse the predictions and trustworthiness score from the returned response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6d555f0-a01e-4e9f-9628-3a7d093fca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: The text \"what are meeting scheduled for today\" can be classified under the label **'calendar_query'**.\n",
      "TLM Score: 0.5979667890547007\n"
     ]
    }
   ],
   "source": [
    "response = completion.choices[0].message.content\n",
    "tlm_score = completion.choices[0].tlm[\"score\"]\n",
    "\n",
    "print(f\"LLM Response: {response}\")\n",
    "print(f\"TLM Score: {tlm_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb4ff8-2982-4542-9693-9960583e5c8e",
   "metadata": {},
   "source": [
    "### Batch Prompt on a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453680cb-1bc0-4381-8b43-f405de8366af",
   "metadata": {},
   "source": [
    "Here, we define a quick helper function that allows us to process multiple texts in parallel, which will speed up prompting the LLM on an entire dataset. The helper function also parses and collects the predictions and trustworthiness score in a DataFrame for easy downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4433f2d-a4db-4909-b523-731ac6227b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Classify the following text, using these labels for guidance: {multilabel_classes}. The text is: {text}\"}],\n",
    "        extra_body={\n",
    "            \"tlm\": {\n",
    "                \"quality_preset\": \"low\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"response\": completion.choices[0].message.content,\n",
    "        \"tlm_score\": completion.choices[0].tlm[\"score\"],\n",
    "    }\n",
    "\n",
    "def classify_texts_batch(texts, batch_size=5, max_threads=3, sleep_time=10):\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        \n",
    "        with ThreadPoolExecutor(max_threads) as executor:\n",
    "            futures = [executor.submit(classify_text, text) for text in batch]\n",
    "            batch_results = [f.result() for f in futures]\n",
    "        \n",
    "        results.extend(batch_results)\n",
    "\n",
    "        # sleep to prevent hitting rate limits\n",
    "        if i + batch_size < len(texts):\n",
    "            time.sleep(sleep_time)\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "662bbbeb-f335-4f0c-8b0c-230b078ccdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'The text \"lets have a chat\" can be classified as **\\'general_quirky\\'**.',\n",
       " 'tlm_score': 0.6696376884111997}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_text(data[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "786fe8b7-dada-4ec6-81cd-5e1643c12b59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [43:13<00:00, 259.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>tlm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The text \"lets have a chat\" can be classified under the label: **general_quirky**.</td>\n",
       "      <td>0.504260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The text \"what are meeting scheduled for today\" is best classified under the label **'calendar_query'**.</td>\n",
       "      <td>0.576897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The provided text can be classified into the following labels based on its components:\\n\\n1. \"erase all the events.\" - This corresponds to **calendar_remove**.\\n2. \"resume my audio book from karl pilkington.\" - This corresponds to **play_audiobook**.\\n3. \"tell me the profession of celebrity.\" - This corresponds to **qa_factoid**.\\n\\nGiven the several distinct intents in the text, multiple classifications apply.</td>\n",
       "      <td>0.328716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The text can be classified as 'calendar_set' since it refers to setting a reminder for a meeting.</td>\n",
       "      <td>0.598410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The appropriate label for the text \"i have a nine am meeting on wednesday send me a reminder\" would be **'calendar_set'**.</td>\n",
       "      <td>0.680641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                         response  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                              The text \"lets have a chat\" can be classified under the label: **general_quirky**.   \n",
       "1                                                                                                                                                                                                                                                                                                                        The text \"what are meeting scheduled for today\" is best classified under the label **'calendar_query'**.   \n",
       "2  The provided text can be classified into the following labels based on its components:\\n\\n1. \"erase all the events.\" - This corresponds to **calendar_remove**.\\n2. \"resume my audio book from karl pilkington.\" - This corresponds to **play_audiobook**.\\n3. \"tell me the profession of celebrity.\" - This corresponds to **qa_factoid**.\\n\\nGiven the several distinct intents in the text, multiple classifications apply.   \n",
       "3                                                                                                                                                                                                                                                                                                                               The text can be classified as 'calendar_set' since it refers to setting a reminder for a meeting.   \n",
       "4                                                                                                                                                                                                                                                                                                      The appropriate label for the text \"i have a nine am meeting on wednesday send me a reminder\" would be **'calendar_set'**.   \n",
       "\n",
       "   tlm_score  \n",
       "0   0.504260  \n",
       "1   0.576897  \n",
       "2   0.328716  \n",
       "3   0.598410  \n",
       "4   0.680641  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = classify_texts_batch(data[\"text\"], batch_size=5)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfbd4ec7-c993-43be-bfda-0673601dce0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b6aacf-2768-45ca-bd10-4eaff37693d8",
   "metadata": {},
   "source": [
    "## Examine Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ce86f-3085-4c90-aca4-964b1a3fe867",
   "metadata": {},
   "source": [
    "We have now obtained the predictions and trustworthiness score for each given text. Let's examine the results in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0c9198d-d26c-422c-b11f-6adec3fed116",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results = pd.concat([data, results], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3732335f-9bb2-47f0-83da-936b2c66ca09",
   "metadata": {},
   "source": [
    "### High Trustworthiness Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb3a4f-2c56-427a-88c5-a8345830cfcd",
   "metadata": {},
   "source": [
    "The responses with the highest trustworthiness scores represent texts where TLM is the most confident that it has predicted the correct intents.\n",
    "\n",
    "We can see below that the predictions for the samples below match the ground truth labels and are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "946e78ca-980d-4078-8564-01496fdfdf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>response</th>\n",
       "      <th>tlm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>get me latest updates from facebook. turn on favorite songs. who am i meeting today. where jackie chan currently live</td>\n",
       "      <td>[social_query, play_music, calendar_query, qa_factoid]</td>\n",
       "      <td>The text can be classified under the following labels:\\n\\n1. \"social_query\" - for \"get me latest updates from facebook.\"\\n2. \"play_music\" - for \"turn on favorite songs.\"\\n3. \"calendar_query\" - for \"who am i meeting today.\"\\n4. \"qa_factoid\" - for \"where jackie chan currently live.\"\\n\\nSo, the appropriate labels are: ['social_query', 'play_music', 'calendar_query', 'qa_factoid'].</td>\n",
       "      <td>0.83354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>what movie can i watch tonight on the theater here in boston</td>\n",
       "      <td>[recommendation_events]</td>\n",
       "      <td>The appropriate label for the provided text is: **recommendation_movies**</td>\n",
       "      <td>0.82275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>delete alarm. when will the world end. can you please add an item to my grocery list</td>\n",
       "      <td>[alarm_remove, general_quirky, lists_createoradd]</td>\n",
       "      <td>The text can be classified into the following labels:\\n\\n1. **alarm_remove** - \"delete alarm\"\\n2. **qa_factoid** - \"when will the world end\"\\n3. **lists_createoradd** - \"can you please add an item to my grocery list\"\\n\\nTherefore, the relevant labels for the provided text are: ['alarm_remove', 'qa_factoid', 'lists_createoradd'].</td>\n",
       "      <td>0.78355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                     text  \\\n",
       "34  get me latest updates from facebook. turn on favorite songs. who am i meeting today. where jackie chan currently live   \n",
       "44                                                           what movie can i watch tonight on the theater here in boston   \n",
       "37                                   delete alarm. when will the world end. can you please add an item to my grocery list   \n",
       "\n",
       "                                                    labels  \\\n",
       "34  [social_query, play_music, calendar_query, qa_factoid]   \n",
       "44                                 [recommendation_events]   \n",
       "37       [alarm_remove, general_quirky, lists_createoradd]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                        response  \\\n",
       "34  The text can be classified under the following labels:\\n\\n1. \"social_query\" - for \"get me latest updates from facebook.\"\\n2. \"play_music\" - for \"turn on favorite songs.\"\\n3. \"calendar_query\" - for \"who am i meeting today.\"\\n4. \"qa_factoid\" - for \"where jackie chan currently live.\"\\n\\nSo, the appropriate labels are: ['social_query', 'play_music', 'calendar_query', 'qa_factoid'].   \n",
       "44                                                                                                                                                                                                                                                                                                                     The appropriate label for the provided text is: **recommendation_movies**   \n",
       "37                                                    The text can be classified into the following labels:\\n\\n1. **alarm_remove** - \"delete alarm\"\\n2. **qa_factoid** - \"when will the world end\"\\n3. **lists_createoradd** - \"can you please add an item to my grocery list\"\\n\\nTherefore, the relevant labels for the provided text are: ['alarm_remove', 'qa_factoid', 'lists_createoradd'].   \n",
       "\n",
       "    tlm_score  \n",
       "34    0.83354  \n",
       "44    0.82275  \n",
       "37    0.78355  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results.sort_values(\"tlm_score\", ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639fa71-b7f2-480b-b00b-40fec010338f",
   "metadata": {},
   "source": [
    "### Low Trustworthiness Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25664160-d35f-421b-99b7-ec8e2bd4d200",
   "metadata": {},
   "source": [
    "The responses with the lowest trustworthiness scores indicate outputs we are least confident are good.\n",
    "\n",
    "Results with low trustworthiness scores would benefit most from manual review, especially if we need almost all outputs across the dataset to be correct.\n",
    "\n",
    "For examples with the lowest trustworthiness scores in our dataset shown below, you can see that the predictions tend to be incorrect or could use further review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5f546f4-c2a0-4501-b94f-109c0e0a237c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>response</th>\n",
       "      <th>tlm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>answer to pawel's email. tell me the recipe of. olly tweet apple that the iphone doesn't work</td>\n",
       "      <td>[email_sendemail, cooking_recipe, social_post]</td>\n",
       "      <td>The text contains various components that suggest it could fit multiple categories. However, the most relevant classifications are:\\n\\n- **email_sendemail**: It mentions \"answer to pawel's email,\" indicating an intention to communicate via email.\\n- **cooking_recipe**: The phrase \"tell me the recipe of\" indicates a request for a recipe.\\n- **social_post**: The phrase \"olly tweet apple that the iphone doesn't work\" implies an action related to social media (specifically tweeting).\\n\\nGiven these observations, the text can be classified primarily under:\\n1. **email_sendemail**\\n2. **cooking_recipe**\\n3. **social_post** \\n\\nIf only one label is to be chosen, **email_sendemail** would be the most appropriate due to the actionable intent indicated.</td>\n",
       "      <td>0.302665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>erase all the events. resume my audio book from karl pilkington. tell me the profession of celebrity</td>\n",
       "      <td>[calendar_remove, play_audiobook, qa_factoid]</td>\n",
       "      <td>The provided text can be classified into the following labels based on its components:\\n\\n1. \"erase all the events.\" - This corresponds to **calendar_remove**.\\n2. \"resume my audio book from karl pilkington.\" - This corresponds to **play_audiobook**.\\n3. \"tell me the profession of celebrity.\" - This corresponds to **qa_factoid**.\\n\\nGiven the several distinct intents in the text, multiple classifications apply.</td>\n",
       "      <td>0.328716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>start a competitive crossword for us. set a reminder in one hour for my bread to bake. tell me the percentage of the chance of rain in seattle washington for today. open saga</td>\n",
       "      <td>[play_game, calendar_set, weather_query, play_game]</td>\n",
       "      <td>The text contains multiple tasks that can be classified into different categories. Here’s a breakdown of each task:\\n\\n1. \"start a competitive crossword for us.\" - This could be categorized under **general_quirky** since it refers to starting a fun activity.\\n2. \"set a reminder in one hour for my bread to bake.\" - This can be classified as **calendar_set** since it involves setting a reminder.\\n3. \"tell me the percentage of the chance of rain in seattle washington for today.\" - This is best classified under **weather_query** as it involves asking for weather information.\\n4. \"open saga\" - This doesn't neatly fit into the provided categories, but could be seen as initiating an action related to **play_game** if \"saga\" refers to a game.\\n\\nConsidering these classifications, the primary categories relevant to the provided text would be:\\n\\n- general_quirky\\n- calendar_set\\n- weather_query\\n- (potentially play_game)\\n\\nIf only one label is needed, I would suggest **general_quirky** as it captures the overall essence of the text while acknowledging the additional categories.</td>\n",
       "      <td>0.359532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                              text  \\\n",
       "31                                                                                   answer to pawel's email. tell me the recipe of. olly tweet apple that the iphone doesn't work   \n",
       "2                                                                             erase all the events. resume my audio book from karl pilkington. tell me the profession of celebrity   \n",
       "16  start a competitive crossword for us. set a reminder in one hour for my bread to bake. tell me the percentage of the chance of rain in seattle washington for today. open saga   \n",
       "\n",
       "                                                 labels  \\\n",
       "31       [email_sendemail, cooking_recipe, social_post]   \n",
       "2         [calendar_remove, play_audiobook, qa_factoid]   \n",
       "16  [play_game, calendar_set, weather_query, play_game]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          response  \\\n",
       "31                                                                                                                                                                                                                                                                                                                                               The text contains various components that suggest it could fit multiple categories. However, the most relevant classifications are:\\n\\n- **email_sendemail**: It mentions \"answer to pawel's email,\" indicating an intention to communicate via email.\\n- **cooking_recipe**: The phrase \"tell me the recipe of\" indicates a request for a recipe.\\n- **social_post**: The phrase \"olly tweet apple that the iphone doesn't work\" implies an action related to social media (specifically tweeting).\\n\\nGiven these observations, the text can be classified primarily under:\\n1. **email_sendemail**\\n2. **cooking_recipe**\\n3. **social_post** \\n\\nIf only one label is to be chosen, **email_sendemail** would be the most appropriate due to the actionable intent indicated.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   The provided text can be classified into the following labels based on its components:\\n\\n1. \"erase all the events.\" - This corresponds to **calendar_remove**.\\n2. \"resume my audio book from karl pilkington.\" - This corresponds to **play_audiobook**.\\n3. \"tell me the profession of celebrity.\" - This corresponds to **qa_factoid**.\\n\\nGiven the several distinct intents in the text, multiple classifications apply.   \n",
       "16  The text contains multiple tasks that can be classified into different categories. Here’s a breakdown of each task:\\n\\n1. \"start a competitive crossword for us.\" - This could be categorized under **general_quirky** since it refers to starting a fun activity.\\n2. \"set a reminder in one hour for my bread to bake.\" - This can be classified as **calendar_set** since it involves setting a reminder.\\n3. \"tell me the percentage of the chance of rain in seattle washington for today.\" - This is best classified under **weather_query** as it involves asking for weather information.\\n4. \"open saga\" - This doesn't neatly fit into the provided categories, but could be seen as initiating an action related to **play_game** if \"saga\" refers to a game.\\n\\nConsidering these classifications, the primary categories relevant to the provided text would be:\\n\\n- general_quirky\\n- calendar_set\\n- weather_query\\n- (potentially play_game)\\n\\nIf only one label is needed, I would suggest **general_quirky** as it captures the overall essence of the text while acknowledging the additional categories.   \n",
       "\n",
       "    tlm_score  \n",
       "31   0.302665  \n",
       "2    0.328716  \n",
       "16   0.359532  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results.sort_values(\"tlm_score\").head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922df4fa-409c-40f3-8b8a-73ba2f5ee313",
   "metadata": {},
   "source": [
    "## Using Different Quality Presets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396b996-da06-4102-9ef9-8a74f7cf24cb",
   "metadata": {},
   "source": [
    "You can use TLM with different [quality presets](/tlm/tutorials/tlm_advanced/#quality-presets) by specifying the preset after the model name. \n",
    "\n",
    "For example, in this example below we specify `model=\"gpt-4o-low\"` to use TLM on `low` quality preset (for lower cost/latency). If unspecified, the default quality preset used is `medium`.\n",
    "\n",
    "Currently, only `base`, `low`, and `medium` presets are supported when using TLM via the OpenAI library. Read more about quality presets [here](/tlm/api/python/tlm/#class-tlmoptions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "561a4cc9-e835-40e8-adc5-abcecb09db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = data['text'][0]\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-low\",\n",
    "    messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Classify the following text, using these labels for guidance: {multilabel_classes}. The text is: {sample_text}\"}  \n",
    "        ],\n",
    "    extra_body={\n",
    "        \"tlm\": {\n",
    "            \"quality_preset\": \"low\"\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396b996-da06-4102-9ef9-8a74f7cf24cd",
   "metadata": {},
   "source": [
    "We re-emphasize that you can use TLM via the [OpenAI library](https://github.com/openai/openai-python) to score the trustworthiness of *any* type of OpenAI output (not just structured outputs).\n",
    "Beyond structured outputs, we recommend using TLM via the [OpenAI library](https://github.com/openai/openai-python) for LLM applications involving: function calling, system prompts and multiple user/assistant messages, as well as other advanced features offered by OpenAI but not most LLM APIs.\n",
    "\n",
    "For questions about the OpenAI API, refer to the documentation linked from [their library](https://github.com/openai/openai-python)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
