{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9094c19e",
   "metadata": {},
   "source": [
    "# Scoring the Trustworthiness of Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88183279",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to score the trustworthiness of structured outputs from LLMs using the OpenAI Chat Completions API. With minimal code changes, you can evaluate both the overall trustworthiness scores for each LLM response, and granular per-field scores for each component of structured responses (e.g., individual fields in JSON/dictionary outputs).\n",
    "\n",
    "Before starting this tutorial, we recommed you first complete our basic tutorial on [Using TLM with the Chat Completions API](/tlm/tutorials/tlm_chat_completion/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9130de",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d56a90",
   "metadata": {},
   "source": [
    "This tutorial requires a TLM API key. Get one [here](https://tlm.cleanlab.ai/). While this tutorial uses your own OpenAI account to generate structured outputs, you can alternatively use TLM without an OpenAI account to [both generate structured outputs and score their trustworthiness](/tlm/tutorials/tlm_chat_completion/#workflow-3-use-cleanlab-to-generate-and-score-responses).\n",
    "\n",
    "The Python packages required for this tutorial can be installed using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade cleanlab-tlm openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3beb9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CLEANLAB_TLM_API_KEY\"] = \"<Cleanlab TLM API key>\"  # Get your free API key from: https://tlm.cleanlab.ai/\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<OpenAI API key>\"  # For using OpenAI client library to generate structured outputs, you can use TLM for this instead too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73a8502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from openai import OpenAI\n",
    "from pydantic import create_model\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from cleanlab_tlm.utils.chat_completions import TLMChatCompletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42f14a6",
   "metadata": {},
   "source": [
    "## Fetch Dataset: PII Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164cb50b",
   "metadata": {},
   "source": [
    "This tutorial uses a PII (Personally Identifiable Information) extraction dataset. \n",
    "\n",
    "Each text sample contains various types of personal information embedded within natural language text. The task is to extract different categories of PII from the text. Each example contains multiple types of PII that need to be identified and classified into specific categories including names (FIRSTNAME, LASTNAME), dates (DATE), and account numbers (ACCOUNTNUMBER). \n",
    "\n",
    "Let's take a look at the dataset below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22035d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://cleanlab-public.s3.us-east-1.amazonaws.com/Datasets/pii_extraction.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be2345d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We would like to do a follow-up meeting with S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Melvin, the password of your study support acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Americo, we need a report on how seasonality a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear parents, our annual school trip is schedu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In relation to the filed litigation, we hereby...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         source_text\n",
       "0  We would like to do a follow-up meeting with S...\n",
       "1  Melvin, the password of your study support acc...\n",
       "2  Americo, we need a report on how seasonality a...\n",
       "3  Dear parents, our annual school trip is schedu...\n",
       "4  In relation to the filed litigation, we hereby..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"pii_extraction.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f5299",
   "metadata": {},
   "source": [
    "## Obtain LLM Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb64c74",
   "metadata": {},
   "source": [
    "### Define structured output schema\n",
    "\n",
    "We know that the 4 PII fields that we want to extract are: `['FIRSTNAME', 'LASTNAME', 'DATE', 'ACCOUNTNUMBER']`\n",
    "\n",
    "Using that, we can create a Pydantic model to represent our PII extraction schema. Each field is optional and can be None if that entity type is not found in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14582cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pii_entities = ['FIRSTNAME', 'LASTNAME', 'DATE', 'ACCOUNTNUMBER']\n",
    "fields = {name: (Optional[str], None) for name in pii_entities}\n",
    "\n",
    "PII = create_model(\"PII\", **fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe117d0",
   "metadata": {},
   "source": [
    "### Prompt OpenAI for responses + TLM for trust scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c948ccaa",
   "metadata": {},
   "source": [
    "Here, we utilize OpenAI's Chat Completions API to extract PII from the text. We will also add a TLM decorator to that call to then automatically use TLM to evaluate the trustworthiness of those extractions, and appends the trust score to the response returned by OpenAI.\n",
    "\n",
    "The decorator allows us to first use OpenAI to identify and parse PII, then use TLM to assess the reliability of each extracted field with minimal setup. For more information view our [TLM for Chat Completions tutorial](/tlm/tutorials/tlm_chat_completion/#workflow-2-make-your-existing-code-also-produce-trust-scores-via-decorator).\n",
    "\n",
    "If you don't have an OpenAI account, you can use your TLM account to both generate the structured outputs and score their trustworthiness, as shown [here](/tlm/tutorials/tlm_chat_completion/#workflow-3-use-cleanlab-to-generate-and-score-responses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de071630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def add_trust_scoring(tlm_instance):\n",
    "    \"\"\"Decorator factory that creates a trust scoring decorator.\"\"\"\n",
    "    def trust_score_decorator(fn):\n",
    "        @functools.wraps(fn)\n",
    "        def wrapper(**kwargs):\n",
    "            response = fn(**kwargs)\n",
    "            score_result = tlm_instance.score(response=response, **kwargs)\n",
    "            response.tlm_metadata = score_result\n",
    "            return response\n",
    "        return wrapper\n",
    "    return trust_score_decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44831d46",
   "metadata": {},
   "source": [
    "First initialize a `TLMChatCompletion` object (note that we specify that we want `per_field_score` in the `log` to obtain granular trust scores for each field in the structured output), then we can decorate our OpenAI Chat Completions function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba946c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tlm = TLMChatCompletion(options={\"log\": [\"per_field_score\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7093098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "client.chat.completions.parse = add_trust_scoring(tlm)(client.chat.completions.parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef0f95",
   "metadata": {},
   "source": [
    "After you decorate OpenAI\u2019s Chat Completions function, all of your existing Chat Completions API code will automatically compute trust scores as well (zero change needed in other code).\n",
    "Let's run OpenAI on one text sample to generate structured outputs and score their trustworthiness with TLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3cfa7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We would like to do a follow-up meeting with Sierra Green regarding her recent surgery. The proposed date is August 13, 2013 at our clinic in West Nash.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = data[\"source_text\"][0]\n",
    "sample_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2abd54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.parse(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Extract PII information from the following text, return null if the entity is not found: {sample_text}\"}  \n",
    "        ],\n",
    "    response_format=PII,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a1223",
   "metadata": {},
   "source": [
    "The returned object matches what OpenAI would ordinarily return, except it has an additional `tlm_metadata` field from TLM with extra information like the trustworthiness score and per-field scores. Our decorated function serves as a drop-in replacement for OpenAI in any application (and will still return the same responses you'd get directly from OpenAI alone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4a36888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted PII Information: FIRSTNAME='Sierra' LASTNAME='Green' DATE='August 13, 2013' ACCOUNTNUMBER=None\n",
      "Trustworthiness Score: 0.9890\n",
      "Per-field Trustworthiness Scores: {'ACCOUNTNUMBER': {'explanation': 'There is no mention of any account number or similar identifier in the text, so null is appropriate.', 'score': 1.0}, 'DATE': {'explanation': \"The text specifies the proposed date as 'August 13, 2013', which matches the extracted date exactly.\", 'score': 1.0}, 'FIRSTNAME': {'explanation': \"The text explicitly mentions 'Sierra Green', so the first name 'Sierra' is clearly identified.\", 'score': 1.0}, 'LASTNAME': {'explanation': \"The text explicitly mentions 'Sierra Green', so the last name 'Green' is clearly identified.\", 'score': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Extracted PII Information: {completion.choices[0].message.parsed}\")\n",
    "print(f\"Trustworthiness Score: {completion.tlm_metadata['trustworthiness_score']:.4f}\")\n",
    "print(f\"Per-field Trustworthiness Scores: {completion.tlm_metadata['log']['per_field_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb2c1e",
   "metadata": {},
   "source": [
    "### Run a dataset of many examples\n",
    "\n",
    "Here, we define a quick helper function that allows us to process multiple text samples in parallel, which will speed up prompting the LLM over a dataset. The helper function also collects the LLM outputs and trustworthiness score in a formatted DataFrame for easy downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "774ef502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pii(text):\n",
    "    tlm = TLMChatCompletion(quality_preset=\"medium\", options={\"log\": [\"per_field_score\"]})\n",
    "    client = OpenAI()\n",
    "    client.chat.completions.parse = add_trust_scoring(tlm)(client.chat.completions.parse)\n",
    "\n",
    "\n",
    "    completion = client.chat.completions.parse(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "                {\"role\": \"user\", \"content\": f\"Extract PII information from the following text, return null if the entity is not found: {text}\"}  \n",
    "            ],\n",
    "        response_format=PII,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"raw_completion\": completion,\n",
    "        # the columns below extract the PII information and scores from the raw OpenAI response\n",
    "        \"extracted_pii\": completion.choices[0].message.parsed,\n",
    "        \"trustworthiness_score\": completion.tlm_metadata[\"trustworthiness_score\"],\n",
    "        \"per_field_score\": completion.tlm_metadata[\"log\"][\"per_field_score\"],\n",
    "    }\n",
    "\n",
    "def extract_pii_batch(texts, batch_size=15, max_threads=8, sleep_time=2):\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        \n",
    "        with ThreadPoolExecutor(max_threads) as executor:\n",
    "            futures = [executor.submit(extract_pii, text) for text in batch]\n",
    "            batch_results = [f.result() for f in futures]\n",
    "        \n",
    "        results.extend(batch_results)\n",
    "\n",
    "        # sleep to prevent hitting rate limits\n",
    "        if i + batch_size < len(texts):\n",
    "            time.sleep(sleep_time)\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "118e4250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:32<00:00, 16.39s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_completion</th>\n",
       "      <th>extracted_pii</th>\n",
       "      <th>trustworthiness_score</th>\n",
       "      <th>per_field_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ParsedChatCompletion[PII](id='chatcmpl-CJSmu5J...</td>\n",
       "      <td>FIRSTNAME='Sierra' LASTNAME='Green' DATE='Augu...</td>\n",
       "      <td>0.98902</td>\n",
       "      <td>{'ACCOUNTNUMBER': {'explanation': 'There is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ParsedChatCompletion[PII](id='chatcmpl-CJSmulq...</td>\n",
       "      <td>FIRSTNAME='Melvin' LASTNAME=None DATE=None ACC...</td>\n",
       "      <td>0.96906</td>\n",
       "      <td>{'ACCOUNTNUMBER': {'explanation': 'The text do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      raw_completion  \\\n",
       "0  ParsedChatCompletion[PII](id='chatcmpl-CJSmu5J...   \n",
       "1  ParsedChatCompletion[PII](id='chatcmpl-CJSmulq...   \n",
       "\n",
       "                                       extracted_pii  trustworthiness_score  \\\n",
       "0  FIRSTNAME='Sierra' LASTNAME='Green' DATE='Augu...                0.98902   \n",
       "1  FIRSTNAME='Melvin' LASTNAME=None DATE=None ACC...                0.96906   \n",
       "\n",
       "                                     per_field_score  \n",
       "0  {'ACCOUNTNUMBER': {'explanation': 'There is no...  \n",
       "1  {'ACCOUNTNUMBER': {'explanation': 'The text do...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = extract_pii_batch(data[\"source_text\"])\n",
    "results.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae1a1fb",
   "metadata": {},
   "source": [
    "## Examine Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d6e6a6",
   "metadata": {},
   "source": [
    "We've now generated structured ouputs (i.e. extracted data) for each text sample in the dataset and scored the trustworthiness of each output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c517d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63e078ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results = pd.concat([data, results], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8743f202",
   "metadata": {},
   "source": [
    "### High Trustworthiness Scores\n",
    " \n",
    "The responses with the highest trustworthiness scores represent texts where TLM is most confident in the accuracy of your LLM's structured outputs.\n",
    " \n",
    "Looking at the examples below with high trustworthiness scores, we can see that your OpenAI model successfully extracted the correct PII elements in these text samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3237454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_text</th>\n",
       "      <th>extracted_pii</th>\n",
       "      <th>trustworthiness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We would like to do a follow-up meeting with Sierra Green regarding her recent surgery. The proposed date is August 13, 2013 at our clinic in West Nash.</td>\n",
       "      <td>FIRSTNAME='Sierra' LASTNAME='Green' DATE='August 13, 2013' ACCOUNTNUMBER=None</td>\n",
       "      <td>0.98902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pinkie, our Customer Brand Engineer noticed unusual traffic from 197.30.116.133 on our site https://tattered-past.org. Please investigate.</td>\n",
       "      <td>FIRSTNAME='Pinkie' LASTNAME=None DATE=None ACCOUNTNUMBER=None</td>\n",
       "      <td>0.98902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Patient Fredrick with insurance account 22661006 and SSN 756.9719.4002 is scheduled for general cleaning on 12/05/1973. Please send a confirmation text message to his mobile number +736 435 268.6135 today.</td>\n",
       "      <td>FIRSTNAME='Fredrick' LASTNAME=None DATE='12/05/1973' ACCOUNTNUMBER='22661006'</td>\n",
       "      <td>0.98902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      source_text  \\\n",
       "0                                                        We would like to do a follow-up meeting with Sierra Green regarding her recent surgery. The proposed date is August 13, 2013 at our clinic in West Nash.   \n",
       "9                                                                      Pinkie, our Customer Brand Engineer noticed unusual traffic from 197.30.116.133 on our site https://tattered-past.org. Please investigate.   \n",
       "27  Patient Fredrick with insurance account 22661006 and SSN 756.9719.4002 is scheduled for general cleaning on 12/05/1973. Please send a confirmation text message to his mobile number +736 435 268.6135 today.   \n",
       "\n",
       "                                                                    extracted_pii  \\\n",
       "0   FIRSTNAME='Sierra' LASTNAME='Green' DATE='August 13, 2013' ACCOUNTNUMBER=None   \n",
       "9                   FIRSTNAME='Pinkie' LASTNAME=None DATE=None ACCOUNTNUMBER=None   \n",
       "27  FIRSTNAME='Fredrick' LASTNAME=None DATE='12/05/1973' ACCOUNTNUMBER='22661006'   \n",
       "\n",
       "    trustworthiness_score  \n",
       "0                 0.98902  \n",
       "9                 0.98902  \n",
       "27                0.98902  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results.sort_values(\"trustworthiness_score\", ascending=False).head(3)[[\"source_text\", \"extracted_pii\", \"trustworthiness_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eae17bb",
   "metadata": {},
   "source": [
    "### Low Trustworthiness Scores\n",
    "\n",
    "The lowest trustworthiness scores reveal the LLM outputs that TLM is least confident are accurate.\n",
    "Documents/results with low trustworthiness scores would benefit most from manual review, especially if we need almost all outputs across the dataset to be correct and want to save human review costs.\n",
    "\n",
    "The LLM outputs with the lowest trustworthiness scores in this dataset are shown below, and these extractions are often incorrect or ambiguous warranting further review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e7d9778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_text</th>\n",
       "      <th>extracted_pii</th>\n",
       "      <th>trustworthiness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>To: Maximillian Noah Moore, we forgot to update your record with phone IMEI: 30-265288-033265-8. Could you please provide it in your earliest convenience to keep your records updated.</td>\n",
       "      <td>FIRSTNAME='Maximillian' LASTNAME='Moah' DATE=None ACCOUNTNUMBER=None</td>\n",
       "      <td>0.242112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Loma, your son's eye color, Eye color: Brown, is quite unique. It's beautiful!</td>\n",
       "      <td>FIRSTNAME=None LASTNAME='Loma' DATE=None ACCOUNTNUMBER=None</td>\n",
       "      <td>0.320759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Is your business tax-ready? Our team in Novato is here to help you navigate through Martinique's complex tax rules. Contact us at 56544500.</td>\n",
       "      <td>FIRSTNAME=None LASTNAME=None DATE=None ACCOUNTNUMBER='56544500'</td>\n",
       "      <td>0.595425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                source_text  \\\n",
       "16  To: Maximillian Noah Moore, we forgot to update your record with phone IMEI: 30-265288-033265-8. Could you please provide it in your earliest convenience to keep your records updated.   \n",
       "24                                                                                                           Loma, your son's eye color, Eye color: Brown, is quite unique. It's beautiful!   \n",
       "12                                              Is your business tax-ready? Our team in Novato is here to help you navigate through Martinique's complex tax rules. Contact us at 56544500.   \n",
       "\n",
       "                                                           extracted_pii  \\\n",
       "16  FIRSTNAME='Maximillian' LASTNAME='Moah' DATE=None ACCOUNTNUMBER=None   \n",
       "24           FIRSTNAME=None LASTNAME='Loma' DATE=None ACCOUNTNUMBER=None   \n",
       "12       FIRSTNAME=None LASTNAME=None DATE=None ACCOUNTNUMBER='56544500'   \n",
       "\n",
       "    trustworthiness_score  \n",
       "16               0.242112  \n",
       "24               0.320759  \n",
       "12               0.595425  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results.sort_values(\"trustworthiness_score\").head(3)[[\"source_text\", \"extracted_pii\", \"trustworthiness_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d689019a",
   "metadata": {},
   "source": [
    "## Obtaining Trust Scores for Individual Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f789b46",
   "metadata": {},
   "source": [
    "Beyond TLM's overall trustworthiness score, you can obtain granular confidence scores for each individual field in the structured output from your LLM. These field-level scores help you pinpoint which specific values may be incorrect or warrant focused review. \n",
    "\n",
    "Let's look at the text sample receiving the lowest trustworthiness score in this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52babdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_scoring_text = combined_results.loc[combined_results['trustworthiness_score'].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "417f9760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: To: Maximillian Noah Moore, we forgot to update your record with phone IMEI: 30-265288-033265-8. Could you please provide it in your earliest convenience to keep your records updated.\n",
      "Extracted PII Information: FIRSTNAME='Maximillian' LASTNAME='Moah' DATE=None ACCOUNTNUMBER=None\n",
      "Trustworthiness Score: 0.242112028685259\n",
      "Per-field Trustworthiness Scores: {'ACCOUNTNUMBER': {'explanation': 'No account number is mentioned in the input text, so null is appropriate and correct.', 'score': 1.0}, 'DATE': {'explanation': 'No date is mentioned in the input text, so null is appropriate and correct.', 'score': 1.0}, 'FIRSTNAME': {'explanation': \"The first name 'Maximillian' matches exactly with the name in the input text, so it is correct.\", 'score': 1.0}, 'LASTNAME': {'explanation': \"The last name in the response is 'Moah', but the input text shows 'Moore'. This is a clear misspelling, so the value is incorrect.\", 'score': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Text: {lowest_scoring_text['source_text']}\")\n",
    "print(f\"Extracted PII Information: {lowest_scoring_text['extracted_pii']}\")\n",
    "print(f\"Trustworthiness Score: {lowest_scoring_text['trustworthiness_score']}\")\n",
    "print(f\"Per-field Trustworthiness Scores: {lowest_scoring_text['per_field_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250ed222",
   "metadata": {},
   "source": [
    "The `per_field_score` dictionary contains a granular confidence score and explanation for each extracted field.\n",
    "Since this dictionary can be overwhelming, we provide a `get_untrustworthy_fields()` method that:\n",
    "\n",
    "- Prints detailed information about low-confidence fields\n",
    "- Returns a list of fields that may need manual review due to low trust scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "400014d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrustworthy fields: ['LASTNAME']\n",
      "\n",
      "Field: LASTNAME\n",
      "Response: Moah\n",
      "Score: 0.0\n",
      "Explanation: The last name in the response is 'Moah', but the input text shows 'Moore'. This is a clear misspelling, so the value is incorrect.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "untrustworthy_fields = tlm.get_untrustworthy_fields(tlm_result=lowest_scoring_text['raw_completion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81657637",
   "metadata": {},
   "source": [
    "This method returns a list of fields whose confidence score is low, allowing you to focus manual review on the specific fields whose extracted value is untrustworthy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26356069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LASTNAME']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untrustworthy_fields"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}