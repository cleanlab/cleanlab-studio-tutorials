---
sidebar_position: 9
sidebar_label: Evals/Observability
---

# Automatically Find Inaccurate LLM Responses in Evaluation and Observability Platforms

Cleanlab's Trustworthy Language Model (TLM) enables evaluation and observability platform users to automatically identify low quality and hallucinated responses from any LLM trace.

With the increased usage of LLMs, there exists a growing need for observability, evaluation, and tracing platforms. These platforms enable users to trace and record the inputs and outputs of LLMs.

You can now automatically find the poor quality and incorrect LLM responses lurking within your production logs and traces. This provides better Evals, with significantly less manual review and annotation work from your team.

The following are some examples of how TLM can be used with 3rd party observability platforms.

## Arize

[Arize](https://arize.com/) is a platform built to help accelerate development of AI apps and agents.

- [Documentation](https://docs.arize.com/phoenix/integrations/cleanlab)
- [Github](https://github.com/Arize-ai/phoenix/blob/main/tutorials/integrations/evaluating_traces_cleanlabTLM.ipynb)
- [Colab](https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/integrations/evaluating_traces_cleanlabTLM.ipynb)