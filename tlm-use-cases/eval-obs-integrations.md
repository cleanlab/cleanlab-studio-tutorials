---
sidebar_position: 9
sidebar_label: Evals/Observability
---

# Automatically Find Inaccurate LLM Responses in Evaluation and Observability Platforms

Cleanlab's Trustworthy Language Model (TLM) enables evaluation and observability platform users to automatically identify low quality and hallucinated responses from any LLM trace.

With the increased usage of LLMs, there exists a growing need for observability, evaluation, and tracing platforms. These platforms enable users to trace and record the inputs and outputs of LLMs.

TLM enables you to automatically find the poor quality and incorrect LLM responses lurking within your production logs and traces. This provides better Evals, with significantly less manual review and annotation work from your team.

Here are integrations showing how TLM can be used with 3rd party observability platforms.

## Arize Phoenix

[Arize Phoenix](https://github.com/Arize-ai/phoenix) is an open-source AI observability platform designed for experimentation, evaluation, and troubleshooting.

- [Documentation for Cleanlab Integration](https://docs.arize.com/phoenix/integrations/cleanlab)
- [Github Example](https://github.com/Arize-ai/phoenix/blob/main/tutorials/integrations/evaluating_traces_cleanlabTLM.ipynb)
- [Colab Example](https://colab.research.google.com/github/Arize-ai/phoenix/blob/main/tutorials/integrations/evaluating_traces_cleanlabTLM.ipynb)
