{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the Trustworthiness of ChatBot Responses over Multi-Turn Conversations\n",
    "\n",
    "<head>\n",
    "  <meta name=\"title\" content=\"Automated trustworthiness scoring for any chatbot\"/>\n",
    "  <meta property=\"og:title\" content=\"Automated trustworthiness scoring for any chatbot\"/>\n",
    "  <meta name=\"twitter:title\" content=\"Automated trustworthiness scoring for any chatbot\" />\n",
    "  <meta name=\"image\" content=\"/img/tlm-conversation.png\" />\n",
    "  <meta property=\"og:image\" content=\"/img/tlm-conversation.png\" />\n",
    "  <meta name=\"description\" content=\"How to prevent incorrect responses in LLM chat applications.\"  />\n",
    "  <meta property=\"og:description\" content=\"How to prevent incorrect responses in LLM chat applications.\" />\n",
    "  <meta name=\"twitter:description\" content=\"How to prevent incorrect responses in LLM chat applications.\" />\n",
    "</head>\n",
    "\n",
    "Conversational chatbots generate LLM responses based on a running dialogue history with the user. This tutorial demonstrates how to **score the trustworthiness of chatbot responses in multi-turn conversational settings**. Cleanlab works with any chatbot framework (e.g. Claude, Gemini, LlamaIndex), memory mechanism (e.g., message trimming, summary memory), and LLM model.\n",
    "\n",
    "If you are using LangChain or any API compatible with OpenAI's Chat Completions, we have dedicated tutorials you can consider first:\n",
    "- [Trust scoring for LangChain](/tlm/use-cases/tlm_langchain/)\n",
    "- [Trust scoring for Chat Completions API](/tlm/tutorials/tlm_chat_completion/)\n",
    "\n",
    "![TLM adds a trustworthiness score to every chatbot response](./assets/tlm-conversation-tutorial/tlm-conversation.png)\n",
    "\n",
    "## Setup\n",
    "\n",
    "This tutorial requires a TLM API key. Get one [here](https://tlm.cleanlab.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -U openai cleanlab-tlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "import os\n",
    "os.environ[\"CLEANLAB_TLM_API_KEY\"] = \"<YOUR_CLEANLAB_API_KEY>\"  # Get your free API key from: https://tlm.cleanlab.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import openai\n",
    "from cleanlab_tlm import TLM\n",
    "from cleanlab_tlm.utils.chat import form_prompt_string\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn Conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your chatbot system should already have logic to manage conversation history and generate LLM responses. For this tutorial, we standardize the format of `chat_history` to be a list of dictionaries, each with `\"role\"` and `\"content\"` keys \u2014 identical to [OpenAI\u2019s message format](https://platform.openai.com/docs/guides/text?api-mode=chat).\n",
    "\n",
    "To follow this tutorial, your `generate_llm_response()` function should take in this `chat_history` and return a response from your LLM provider (e.g. LangChain, Claude, Gemini, etc.). Here we use OpenAI as an example LLM provider, but provide `generate_llm_response()` implementations for other LLM providers so you can easily swap in your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=\"<YOUR_OPENAI_API_KEY>\")\n",
    "\n",
    "def generate_llm_response(messages: List[Dict[str, str]]) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we rely on a simple function to update `chat_history`, but you can customize it to control how history is managed (e.g. trimming older messages, summarizing earlier context, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae7f86-75bf-4ca5-a0d4-ea57d6f86353",
   "metadata": {},
   "source": [
    "**Optional: Define update_chat_history() method for managing chat history**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_chat_history(chat_history: List[Dict[str, str]], role: str, content: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Append a new message to the chat history.\n",
    "\n",
    "    This function updates the chat history by adding a new dictionary entry with\n",
    "    the specified role ('user', 'assistant', 'system') and content (message text).\n",
    "\n",
    "    Args:\n",
    "        chat_history (List[Dict[str, str]]): The current list of messages in the chat history.\n",
    "        role (str): The role of the message sender (e.g., 'user', 'assistant').\n",
    "        content (str): The textual content of the message.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, str]]: The updated chat history including the new message.\n",
    "    \"\"\"\n",
    "    chat_history.append({\"role\": role, \"content\": content})\n",
    "    return chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f73c8ba-b83d-4129-a026-e1e8ac5f514c",
   "metadata": {},
   "source": [
    "**Optional: `generate_llm_response` implementation for Claude**\n",
    "\n",
    "Remember to pip install anthropic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic(api_key=\"<YOUR_CLAUDE_API_KEY>\")\n",
    "\n",
    "def generate_llm_response_claude(messages: List[Dict[str, str]]) -> str:\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=1000,\n",
    "        system=system_prompt,\n",
    "        messages=messages[1:]    # system prompt passed separately\n",
    "    )\n",
    "    return response.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55e5f0e-24a9-437f-a693-18f6f7e0e0a3",
   "metadata": {},
   "source": [
    "**Optional: `generate_llm_response` implementation  for Gemini**\n",
    "\n",
    "Remember to pip install google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "client = genai.Client(api_key=\"<YOUR_GEMINI_API_KEY>\")\n",
    "\n",
    "def generate_llm_response_gemini(messages: List[Dict[str, str]]) -> str:\n",
    "\n",
    "    config = types.GenerateContentConfig(system_instruction=system_prompt)\n",
    "\n",
    "    messages = messages[1:]    # system prompt passed separately\n",
    "\n",
    "    gemini_messages = [\n",
    "        {\n",
    "            \"role\": \"model\" if msg[\"role\"] == \"assistant\" else \"user\",\n",
    "            \"parts\": [{\"text\": msg[\"content\"]}]\n",
    "        }\n",
    "        for msg in messages\n",
    "    ]\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-1.5-flash-8b\",\n",
    "        contents=gemini_messages,\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e00d465-eb02-40a3-8805-c9f52db7b6d9",
   "metadata": {},
   "source": [
    "**Optional: `generate_llm_response` implementation for LlamaIndex**\n",
    "\n",
    "Remember to pip install llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI    # or any other llama-index LLM wrapper\n",
    "from llama_index.core.base.llms.types import ChatMessage, MessageRole\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    api_key=\"<YOUR_OPENAI_API_KEY>\"\n",
    ")\n",
    "\n",
    "def generate_llm_response_llama(messages: List[Dict[str, str]]) -> str:\n",
    "\n",
    "    role_map = {\n",
    "        \"system\":    MessageRole.SYSTEM,\n",
    "        \"user\":      MessageRole.USER,\n",
    "        \"assistant\": MessageRole.ASSISTANT,\n",
    "    }\n",
    "\n",
    "    chat_msgs = [\n",
    "        ChatMessage(role=role_map[m[\"role\"]], content=m[\"content\"])\n",
    "        for m in messages\n",
    "    ]\n",
    "\n",
    "    response = llm.chat(chat_msgs)\n",
    "\n",
    "    return response.message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5dde22-0f97-485d-9e1f-1f2fb08ee5c3",
   "metadata": {},
   "source": [
    "**Optional: `generate_llm_response` implementation for LiteLLM**\n",
    "\n",
    "Remember to pip install litellm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "\n",
    "litellm.api_key = \"<YOUR_OPENAI_API_KEY>\"\n",
    "\n",
    "def generate_llm_response_litellm(messages: List[Dict[str, str]]) -> str:\n",
    "\n",
    "    response = litellm.completion(\n",
    "        model=\"openai/gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Use Case: Customer Support Chatbot\n",
    "\n",
    "Let's consider a customer support chatbot use case. Replace our example system prompt and conversations with your own, and Cleanlab will evaluate the trustworthiness of each response in real-time based on the full conversation history and system instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899392c-7d41-47c8-a91e-94305563422d",
   "metadata": {},
   "source": [
    "**Optional: Define system_prompt for our customer support chatbot**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"The following is the customer service policy of ACME Inc.\n",
    "# ACME Inc. Customer Service Policy\n",
    "\n",
    "## Table of Contents\n",
    "1. Free Shipping Policy\n",
    "2. Free Returns Policy\n",
    "3. Fraud Detection Guidelines\n",
    "4. Customer Interaction Tone\n",
    "\n",
    "## 1. Free Shipping Policy\n",
    "\n",
    "### 1.1 Eligibility Criteria\n",
    "- Free shipping is available on all orders over $50 within the continental United States.\n",
    "- For orders under $50, a flat rate shipping fee of $5.99 will be applied.\n",
    "- Free shipping is not available for expedited shipping methods (e.g., overnight or 2-day shipping).\n",
    "\n",
    "### 1.2 Exclusions\n",
    "- Free shipping does not apply to orders shipped to Alaska, Hawaii, or international destinations.\n",
    "- Oversized or heavy items may incur additional shipping charges, which will be clearly communicated to the customer before purchase.\n",
    "\n",
    "### 1.3 Handling Customer Inquiries\n",
    "- If a customer inquires about free shipping eligibility, verify the order total and shipping destination.\n",
    "- Inform customers of ways to qualify for free shipping (e.g., adding items to reach the $50 threshold).\n",
    "- For orders just below the threshold, you may offer a one-time courtesy free shipping if it's the customer's first purchase or if they have a history of large orders.\n",
    "\n",
    "### 1.4 Processing & Delivery Timeframes\n",
    "- Standard orders are processed within 1 business day; during peak periods (e.g., holidays) allow up to 3 business days.  \n",
    "- Delivery via ground service typically takes 3-7 business days depending on destination.\n",
    "\n",
    "### 1.5 Shipment Tracking & Notifications\n",
    "- A tracking link must be emailed automatically once the carrier scans the package.  \n",
    "- Agents may resend tracking links on request and walk customers through carrier websites if needed.\n",
    "\n",
    "### 1.6 Lost-Package Resolution\n",
    "1. File a tracer with the carrier if a package shows no movement for 7 calendar days.\n",
    "2. Offer either a replacement shipment or a full refund once the carrier confirms loss.  \n",
    "3. Document the outcome in the order record for analytics.\n",
    "\n",
    "### 1.7 Sustainability & Packaging Standards\n",
    "- Use recyclable or recycled-content packaging whenever available.  \n",
    "- Consolidate items into a single box to minimize waste unless it risks damage.\n",
    "\n",
    "## 2. Free Returns Policy\n",
    "\n",
    "### 2.1 Eligibility Criteria\n",
    "- Free returns are available for all items within 30 days of the delivery date.\n",
    "- Items must be unused, unworn, and in their original packaging with all tags attached.\n",
    "- Free returns are limited to standard shipping methods within the continental United States.\n",
    "\n",
    "### 2.2 Exclusions\n",
    "- Final sale items, as marked on the product page, are not eligible for free returns.\n",
    "- Customized or personalized items are not eligible for free returns unless there is a manufacturing defect.\n",
    "- Undergarments, swimwear, and earrings are not eligible for free returns due to hygiene reasons.\n",
    "\n",
    "### 2.3 Process for Handling Returns\n",
    "1. Verify the order date and ensure it falls within the 30-day return window.\n",
    "2. Ask the customer about the reason for the return and document it in the system.\n",
    "3. Provide the customer with a prepaid return label if they qualify for free returns.\n",
    "4. Inform the customer of the expected refund processing time (5-7 business days after receiving the return).\n",
    "\n",
    "### 2.4 Exceptions\n",
    "- For items damaged during shipping or with manufacturing defects, offer an immediate replacement or refund without requiring a return.\n",
    "- For returns outside the 30-day window, use discretion based on the customer's history and the reason for the late return. You may offer store credit as a compromise.\n",
    "\n",
    "### 2.5 Return Package Preparation Guidelines\n",
    "- Instruct customers to reuse the original box when possible and to cushion fragile items.  \n",
    "- Advise removing or obscuring any prior shipping labels.\n",
    "\n",
    "### 2.6 Inspection & Restocking Procedures\n",
    "- Returns are inspected within 48 hours of arrival.  \n",
    "- Items passing inspection are restocked; those failing inspection follow the disposal flow in \u00a7 2.8.\n",
    "\n",
    "### 2.7 Refund & Exchange Timeframes\n",
    "- Refunds to the original payment method post within 5-7 business days after inspection.  \n",
    "- Exchanges ship out within 1 business day of successful inspection.\n",
    "\n",
    "### 2.8 Disposal of Non-Restockable Goods\n",
    "- Defective items are sent to certified recyclers; lightly used goods may be donated to charities approved by the CSR team.\n",
    "\n",
    "## 3. Fraud Detection Guidelines\n",
    "\n",
    "### 3.1 Red Flags for Potential Fraud\n",
    "- Multiple orders from the same IP address with different customer names or shipping addresses.\n",
    "- Orders with unusually high quantities of the same item.\n",
    "- Shipping address different from the billing address, especially if in different countries.\n",
    "- Multiple failed payment attempts followed by a successful one.\n",
    "- Customers pressuring for immediate shipping or threatening to cancel the order.\n",
    "\n",
    "### 3.2 Verification Process\n",
    "1. For orders flagging as potentially fraudulent, place them on hold for review.\n",
    "2. Verify the customer's identity by calling the phone number on file.\n",
    "3. Request additional documentation (e.g., photo ID, credit card statement) if necessary.\n",
    "4. Cross-reference the shipping address with known fraud databases.\n",
    "\n",
    "### 3.3 Actions for Confirmed Fraud\n",
    "- Cancel the order immediately and refund any charges.\n",
    "- Document the incident in the customer's account and flag it for future reference.\n",
    "- Report confirmed fraud cases to the appropriate authorities and credit card companies.\n",
    "\n",
    "### 3.4 False Positives\n",
    "- If a legitimate customer is flagged, apologize for the inconvenience and offer a small discount or free shipping on their next order.\n",
    "- Document the incident to improve our fraud detection algorithms.\n",
    "\n",
    "### 3.5 Chargeback Response Procedure\n",
    "1. Gather all order evidence (invoice, shipment tracking, customer communications).  \n",
    "2. Submit documentation to the processor within 3 calendar days of chargeback notice.  \n",
    "3. Follow up weekly until the dispute is closed.\n",
    "\n",
    "### 3.6 Data Security & Privacy Compliance\n",
    "- Store verification documents in an encrypted, access-controlled folder.  \n",
    "- Purge personally identifiable information after 180 days unless required for ongoing legal action.\n",
    "\n",
    "### 3.7 Continuous Improvement & Training\n",
    "- Run quarterly reviews of fraud rules with data analytics.  \n",
    "- Provide annual anti-fraud training to all front-line staff.\n",
    "\n",
    "### 3.8 Record-Keeping Requirements\n",
    "- Maintain a log of all fraud reviews\u2014including false positives\u2014for 3 years to support audits.\n",
    "\n",
    "## 4. Customer Interaction Tone\n",
    "\n",
    "### 4.1 General Guidelines\n",
    "- Always maintain a professional, friendly, and empathetic tone.\n",
    "- Use the customer's name when addressing them.\n",
    "- Listen actively and paraphrase the customer's concerns to ensure understanding.\n",
    "- Avoid negative language; focus on what can be done rather than what can't.\n",
    "\n",
    "### 4.2 Specific Scenarios\n",
    "\n",
    "#### Angry or Frustrated Customers\n",
    "- Remain calm and do not take comments personally.\n",
    "- Acknowledge the customer's feelings and apologize for their negative experience.\n",
    "- Focus on finding a solution and clearly explain the steps you'll take to resolve the issue.\n",
    "- If necessary, offer to escalate the issue to a supervisor.\n",
    "\n",
    "#### Confused or Indecisive Customers\n",
    "- Be patient and offer clear, concise explanations.\n",
    "- Ask probing questions to better understand their needs.\n",
    "- Provide options and explain the pros and cons of each.\n",
    "- Offer to send follow-up information via email if the customer needs time to decide.\n",
    "\n",
    "#### VIP or Loyal Customers\n",
    "- Acknowledge their status and thank them for their continued business.\n",
    "- Be familiar with their purchase history and preferences.\n",
    "- Offer exclusive deals or early access to new products when appropriate.\n",
    "- Go above and beyond to exceed their expectations.\n",
    "\n",
    "### 4.3 Language and Phrasing\n",
    "- Use positive language: \"I'd be happy to help you with that\" instead of \"I can't do that.\"\n",
    "- Avoid technical jargon or abbreviations that customers may not understand.\n",
    "- Use \"we\" statements to show unity with the company: \"We value your feedback\" instead of \"The company values your feedback.\"\n",
    "- End conversations on a positive note: \"Is there anything else I can assist you with today?\"\n",
    "\n",
    "### 4.4 Written Communication\n",
    "- Use proper grammar, spelling, and punctuation in all written communications.\n",
    "- Keep emails and chat responses concise and to the point.\n",
    "- Use bullet points or numbered lists for clarity when providing multiple pieces of information.\n",
    "- Include a clear call-to-action or next steps at the end of each communication.\n",
    "\n",
    "### 4.5 Response-Time Targets\n",
    "- Live chat: respond within 30 seconds.  \n",
    "- Email: first reply within 4 business hours (max 24 hours during peak).  \n",
    "- Social media mentions: acknowledge within 1 hour during staffed hours.\n",
    "\n",
    "### 4.6 Accessibility & Inclusivity\n",
    "- Offer alternate text for images and use plain-language summaries.  \n",
    "- Provide TTY phone support and ensure web chat is screen-reader compatible.\n",
    "\n",
    "### 4.7 Multichannel Etiquette (Phone, Chat, Social)\n",
    "- Use consistent greetings and closings across channels.  \n",
    "- Avoid emojis in formal email; limited, brand-approved emojis allowed in chat or social when matching customer tone.\n",
    "\n",
    "### 4.8 Proactive Outreach & Follow-Up\n",
    "- After resolving a complex issue, send a 24-hour satisfaction check-in.  \n",
    "- Tag VIP accounts for quarterly \u201cthank-you\u201d notes highlighting new offerings.\n",
    "\n",
    "### 4.9 Documentation of Customer Interactions\n",
    "- Log every interaction in the CRM within 15 minutes of completion, including sentiment and resolution code.  \n",
    "- Use standardized tags to support trend analysis and training.\n",
    "\n",
    "You are a customer service assistant for ACME Inc. Answer customer questions accurately, concisely, and in line with the company's service policy. Do not suggest contacting customer service.\n",
    "Remember, as a representative of ACME Inc., you are often the first point of contact for our customers. Your interactions should always reflect our commitment to exceptional customer service and satisfaction.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [{\"role\": \"system\", \"content\": system_prompt}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring trustworthiness of LLM responses\n",
    "\n",
    "To score the trustworthiness of each LLM response in the chat, let's instantiate a TLM client and log TLM explanations to understand *why* certain LLM responses were considered untrustworthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlm = TLM(options={'log':['explanation']})  # See Advanced Tutorial for optional TLM configurations to get better/faster results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456dbc75-e8a5-483f-af56-da5bba497d0f",
   "metadata": {},
   "source": [
    "**Optional: Define display_tlm_feedback() helper function to print TLM results**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def display_tlm_feedback(response_text: str, resp: dict, threshold: float = 0.8, explanation: bool = True):\n",
    "    print(\"=\" * 30 + \" AI Message \" + \"=\" * 30)\n",
    "\n",
    "    # Wrap and print the AI response across multiple lines\n",
    "    wrapped_response = textwrap.fill(response_text.strip(), width=100)\n",
    "    print(wrapped_response + \"\\n\")\n",
    "\n",
    "    score = resp.get(\"trustworthiness_score\")\n",
    "    if score is None:\n",
    "        print(\"[TLM Error]: No trustworthiness score found in response.\")\n",
    "        return\n",
    "\n",
    "    label = \"Trustworthy\" if score >= threshold else \"Untrustworthy\"\n",
    "    print(f\"[TLM Score]: {score} ({label})\")\n",
    "\n",
    "    if explanation:\n",
    "        explanation_text = resp.get(\"log\", {}).get(\"explanation\")\n",
    "        if explanation_text:\n",
    "            print(f\"[TLM Score Explanation]: {explanation_text}\")\n",
    "        else:\n",
    "            print(\"[TLM Warning]: Enable the 'explanation' option in the TLM client to receive detailed reasoning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TLM.get_trustworthiness()` requires two parameters: `prompt` and `response`. For a multi-turn chat: the `prompt` should include the conversation history up to (but not including) the last assistant response, plus any system instructions or retrieved context that was also provided to your LLM when it generated a response.\n",
    "Simply convert your chat history into a `prompt` string using TLM's `form_prompt_string()` method.\n",
    "\n",
    "Let\u2019s run our chatbot with trustworthiness scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== AI Message ==============================\n",
      "Hello! Unfortunately, to be eligible for a free return, the jeans need to be unused, unworn, and in\n",
      "their original packaging with all tags attached. If the jeans have been worn, they would not qualify\n",
      "for a free return. Please let me know if you need assistance with a different item or further\n",
      "questions!\n",
      "\n",
      "[TLM Score]: 0.982129737222567 (Trustworthy)\n",
      "[TLM Score Explanation]: Did not find a reason to doubt trustworthiness.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Can I return my jeans even if I've worn them?\"\n",
    "\n",
    "# Your existing LLM chat code\n",
    "chat_history = update_chat_history(chat_history, \"user\", user_input)\n",
    "response = generate_llm_response(chat_history)\n",
    "\n",
    "# Extra code for trustworthiness scoring\n",
    "tlm_results = tlm.get_trustworthiness_score(\n",
    "    prompt = form_prompt_string(chat_history), response=response\n",
    ")\n",
    "\n",
    "# Your existing LLM chat code\n",
    "chat_history = update_chat_history(chat_history, \"assistant\", response)\n",
    "\n",
    "# Code just for this tutorial, to display results\n",
    "display_tlm_feedback(response_text=response, resp=tlm_results, threshold=0.85, explanation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the chatbot response, we find that it clearly and accurately follows the refund policy. The trustworthiness score automatically confirmed this in real time. Next, we\u2019ll evaluate the chatbot\u2019s response to a follow-up question \u2014 one that depends on the context established in the first exchange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== AI Message ==============================\n",
      "If the jeans have been worn once and do not have any defects, they typically wouldn't be eligible\n",
      "for a free return. However, you can still return the item by paying the standard $5.99 shipping fee\n",
      "for a return. Please make sure the item is unused, unworn, and in its original packaging to proceed\n",
      "with the return.\n",
      "\n",
      "[TLM Score]: 0.4784828550368547 (Untrustworthy)\n",
      "[TLM Score Explanation]: The policy states worn items are not eligible for free returns except for defects. It does not mention paid returns for worn items. The assistant incorrectly suggests paying a $5.99 fee for a return of worn jeans, which contradicts the policy.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I've only worn it once. Can I just pay the shipping fee?\"\n",
    "\n",
    "# Your existing LLM chat code\n",
    "chat_history = update_chat_history(chat_history, \"user\", user_input)\n",
    "response = generate_llm_response(chat_history)\n",
    "\n",
    "# Extra code for trustworthiness scoring\n",
    "tlm_results = tlm.get_trustworthiness_score(\n",
    "    prompt = form_prompt_string(chat_history), response=response\n",
    ")\n",
    "\n",
    "# Your existing LLM chat code\n",
    "chat_history = update_chat_history(chat_history, \"assistant\", response)\n",
    "\n",
    "# Code just for this tutorial, to display results\n",
    "display_tlm_feedback(response_text=response, resp=tlm_results, threshold=0.85, explanation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chatbot successfully relied on the earlier conversation history to answer. However, TLM assigned the response a low trustworthiness score.\n",
    "\n",
    "Referring to the policy in our LLM's system prompt:\n",
    "\n",
    "> *Free returns are available for all items within 30 days of the delivery date.*\n",
    "\n",
    "We see the policy does not clarify whether items can still be returned if the customer were to cover return shipping, leading to ambiguity regarding what is a correct response. TLM automatically detected this issue in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> Handling open-ended / non-propositional responses and other custom evaluations <b>(click to expand)</b></summary>\n",
    "\n",
    "You can also specify custom TLM evaluations to assess specific criteria. For example, you may not want to rely on TLM's trustworthiness score for every chatbot response, but rather only for verifiable statements that convey information (these are called propositional responses).\n",
    "You can run TLM with custom evaluation criteria that scores how non-propositional each response is, and only consider TLM's trustworthiness score for those responses whose custom evaluation score is low.\n",
    "\n",
    "Here's an example implmentation of this strategy:\n",
    "\n",
    "\n",
    "```python\n",
    "# Run TLM with custom eval assessing how non-propositional each response is\n",
    "custom_eval_criteria_option = {\"custom_eval_criteria\": [\n",
    "    {\"name\": \"Non-Propositionality\", \"criteria\": \"Determine whether the response is non-propositional, in which case it is great. Otherwise it is a bad response if it conveys any specific information or facts, or otherwise seems like an answer whose accuracy could matter.\"}\n",
    "]}\n",
    "\n",
    "tlm_custom_eval = TLM(options=custom_eval_criteria_option)\n",
    "\n",
    "\n",
    "# Helper method to handle propostional responses\n",
    "def update_trust_score(tlm_results, custom_score_threshold=0.8, high_trust_score = 0.99):\n",
    "    \"\"\"\n",
    "    Assumes `tlm_results` are the output of TLM run with a custom evaluation criteria.\n",
    "    Whenever the custom evaluation score is higher than `custom_score_threshold`,\n",
    "    this method overrides the TLM trustworthiness score to be high.\n",
    "    Returns: updated `tlm_results` (this object is mutated in place).\n",
    "    \"\"\"\n",
    "    if not 'log' in tlm_results:\n",
    "        raise ValueError(\"tlm_results must be output of TLM run with a custom evaluation criteria\")\n",
    "    if not 'custom_eval_criteria' in tlm_results['log']:\n",
    "        raise ValueError(\"tlm_results must be output of TLM run with a custom evaluation criteria\")\n",
    "    if len(tlm_results['log']['custom_eval_criteria']) != 1:\n",
    "        raise ValueError(\"tlm_results must be output of TLM run with a single custom evaluation criteria\")\n",
    "    if not 'score' in tlm_results[\"log\"][\"custom_eval_criteria\"][0]:\n",
    "        raise ValueError(\"custom evaluation criteria score is missing in tlm_results\")\n",
    "\n",
    "    custom_score = tlm_results[\"log\"][\"custom_eval_criteria\"][0][\"score\"]\n",
    "    if custom_score > custom_score_threshold:\n",
    "        tlm_results[\"trustworthiness_score\"] = high_trust_score\n",
    "```\n",
    "\n",
    "\n",
    "Here's how to run this implementation on an open-ended LLM response whose trustworthiness doesn't really matter:\n",
    "\n",
    "```python\n",
    "user_input = \"Hi!\"\n",
    "\n",
    "# Your existing LLM chat code\n",
    "chat_history = update_chat_history(chat_history, \"user\", user_input)\n",
    "response = generate_llm_response(chat_history)\n",
    "\n",
    "# Extra code for trustworthiness scoring\n",
    "tlm_results = tlm_custom_eval.get_trustworthiness_score(\n",
    "    prompt = form_prompt_string(chat_history), response=response\n",
    ")\n",
    "update_trust_score(tlm_results)  # possibly override trust scores\n",
    "\n",
    "# Your existing LLM chat code\n",
    "chat_history = update_chat_history(chat_history, \"assistant\", response)\n",
    "\n",
    "# Code just for this tutorial, to display results\n",
    "display_tlm_feedback(response_text=response, resp=tlm_results, threshold=0.85, explanation=False)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial relied on `form_prompt_string(messages)` to convert chat `messages` into a string `prompt` for TLM.\n",
    "Alternatively, you can apply TLM directly to `messages` in OpenAI's Chat Completions format as shown here: [TLM for Chat Completions API](/tlm/tutorials/tlm_chat_completion/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}