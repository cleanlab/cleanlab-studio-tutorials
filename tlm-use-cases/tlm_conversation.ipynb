{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the Trustworthiness of ChatBot Responses over Multi-Turn Conversations\n",
    "\n",
    "<head>\n",
    "  <meta name=\"title\" content=\"Automated trustworthiness scoring for any chatbot\"/>\n",
    "  <meta property=\"og:title\" content=\"Automated trustworthiness scoring for any chatbot\"/>\n",
    "  <meta name=\"twitter:title\" content=\"Automated trustworthiness scoring for any chatbot\" />\n",
    "  <meta name=\"image\" content=\"/img/tlm-conversation.png\" />\n",
    "  <meta property=\"og:image\" content=\"/img/tlm-conversation.png\" />\n",
    "  <meta name=\"description\" content=\"How to prevent incorrect responses in LLM chat applications.\"  />\n",
    "  <meta property=\"og:description\" content=\"How to prevent incorrect responses in LLM chat applications.\" />\n",
    "  <meta name=\"twitter:description\" content=\"How to prevent incorrect responses in LLM chat applications.\" />\n",
    "</head>\n",
    "\n",
    "Conversational chatbots generate LLM responses based on a running dialogue history with the user. This tutorial demonstrates how to score the trustworthiness of every chatbot response in real-time, such that you can automatically prevent incorrect reponses from being served to the user. Cleanlab works with any chatbot framework (e.g. Claude, Gemini, LlamaIndex), memory mechanism (e.g., message trimming, summary memory), and LLM model.\n",
    "\n",
    "If you want to apply TLM in multi-turn conversational settings, this is the tutorial for you!\n",
    "If you are using LangChain or OpenAI, we also have additional dedicated tutorials: \n",
    "[Trustworthiness scoring for LangChain](/tlm/use-cases/tlm_langchain/) and\n",
    "[Using TLM via the OpenAI API](/tlm/tutorials/tlm_structured_outputs/).\n",
    "\n",
    "![TLM adds a trustworthiness score to every chatbot response](./assets/tlm-conversation-tutorial/tlm-conversation.png)\n",
    "\n",
    "## Setup\n",
    "\n",
    "This tutorial requires a TLM API key. Get one [here](https://tlm.cleanlab.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "%pip install -U openai cleanlab-tlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "import os\n",
    "os.environ[\"CLEANLAB_TLM_API_KEY\"] = \"<YOUR_CLEANLAB_API_KEY>\"  # Get your free API key from: https://tlm.cleanlab.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import openai\n",
    "from cleanlab_tlm import TLM\n",
    "from cleanlab_tlm.utils.chat import form_prompt_string\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn Conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your chatbot system should already include logic to manage conversation history and generate responses. For this tutorial, we standardize the format of `chat_history` to be a list of dictionaries, each with `\"role\"` and `\"content\"` keys \u2014 identical to [OpenAI\u2019s message format](https://platform.openai.com/docs/guides/text?api-mode=chat).\n",
    "\n",
    "As such to follow this tutorial, your `generate_llm_response` function should take this standardized chat history as input and internally convert it into the format required by your specific LLM provider (e.g., LangChain, Claude, Gemini, etc.). We'll use OpenAI as the default example, but provide plug-and-play `generate_llm_response` implementations for other frameworks so you can easily swap in your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(api_key=\"<YOUR_OPENAI_API_KEY>\")\n",
    "\n",
    "def generate_llm_response(messages: List[Dict[str, str]]) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "chat_history = [{\"role\": \"system\", \"content\": system_prompt}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While your `chat_history` remains in this standardized format, our provided `update_chat_history` helper function \u2014 which simply appends the latest message \u2014 will work out of the box, but you can customize it to control how history is managed, such as trimming older messages, summarizing earlier context, or enforcing token limits.\n",
    "\n",
    "`TLM.get_trustworthiness()` requires two parameters: `prompt` and `response`. For a multi-turn chat, the `prompt` should include the conversation history up to (but not including) the last assistant response. This means we must convert the structured chat history into a string format.  We provide a `form_prompt_string()` helper function for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d39129-c0de-4e65-bafc-31517b0eaf7f",
   "metadata": {},
   "source": [
    "**Optional: helper functions for managing chat history**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_chat_history(chat_history: List[Dict[str, str]], role: str, content: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Append a new message to the chat history.\n",
    "\n",
    "    This function updates the chat history by adding a new dictionary entry with\n",
    "    the specified role ('user', 'assistant', 'system') and content (message text).\n",
    "\n",
    "    Args:\n",
    "        chat_history (List[Dict[str, str]]): The current list of messages in the chat history.\n",
    "        role (str): The role of the message sender (e.g., 'user', 'assistant').\n",
    "        content (str): The textual content of the message.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, str]]: The updated chat history including the new message.\n",
    "    \"\"\"\n",
    "    chat_history.append({\"role\": role, \"content\": content})\n",
    "    return chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab519c0-6372-4a94-bd51-73cd84f47db7",
   "metadata": {},
   "source": [
    "**Optional: `generate_llm_response` implementation for Claude**\n",
    "\n",
    "Remember to pip install anthropic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic(api_key=\"<YOUR_CLAUDE_API_KEY>\")\n",
    "\n",
    "def generate_llm_response_claude(messages: List[Dict[str, str]]) -> str:\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=1000,\n",
    "        system=system_prompt,\n",
    "        messages=messages[1:]    # system prompt passed separately\n",
    "    )\n",
    "    return response.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749f27a7-624a-44cb-8e6d-b00ae3d873c3",
   "metadata": {},
   "source": [
    "**Optional: `generate_llm_response` implementation  for Gemini**\n",
    "\n",
    "Remember to pip install google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "client = genai.Client(api_key=\"<YOUR_GEMINI_API_KEY>\")\n",
    "\n",
    "def generate_llm_response_gemini(messages: List[Dict[str, str]]) -> str:\n",
    "\n",
    "    config = types.GenerateContentConfig(system_instruction=system_prompt)\n",
    "\n",
    "    messages = messages[1:]    # system prompt passed separately\n",
    "\n",
    "    gemini_messages = [\n",
    "        {\n",
    "            \"role\": \"model\" if msg[\"role\"] == \"assistant\" else \"user\",\n",
    "            \"parts\": [{\"text\": msg[\"content\"]}]\n",
    "        }\n",
    "        for msg in messages\n",
    "    ]\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-1.5-flash-8b\",\n",
    "        contents=gemini_messages,\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4a28dd-e73b-4887-a640-ee2ad208ad15",
   "metadata": {},
   "source": [
    "**Optional: `generate_llm_response` implementation for LlamaIndex**\n",
    "\n",
    "Remember to pip install llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI    # or any other llama-index LLM wrapper\n",
    "from llama_index.core.base.llms.types import ChatMessage, MessageRole\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    api_key=\"<YOUR_OPENAI_API_KEY>\"\n",
    ")\n",
    "\n",
    "def generate_llm_response_llama(messages: List[Dict[str, str]]) -> str:\n",
    "\n",
    "    role_map = {\n",
    "        \"system\":    MessageRole.SYSTEM,\n",
    "        \"user\":      MessageRole.USER,\n",
    "        \"assistant\": MessageRole.ASSISTANT,\n",
    "    }\n",
    "\n",
    "    chat_msgs = [\n",
    "        ChatMessage(role=role_map[m[\"role\"]], content=m[\"content\"])\n",
    "        for m in messages\n",
    "    ]\n",
    "\n",
    "    response = llm.chat(chat_msgs)\n",
    "\n",
    "    return response.message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd28c90a-bc7a-445c-96bb-f331cfcfc476",
   "metadata": {},
   "source": [
    "**Optional: `generate_llm_response` implementation for LiteLLM**\n",
    "\n",
    "Remember to pip install litellm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "\n",
    "litellm.api_key = \"<YOUR_OPENAI_API_KEY>\"\n",
    "\n",
    "def generate_llm_response_litellm(messages: List[Dict[str, str]]) -> str:\n",
    "\n",
    "    response = litellm.completion(\n",
    "        model=\"openai/gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Use Case: Customer Support Chatbot\n",
    "\n",
    "For this tutorial, we'll consider a customer support chatbot use case, where the assistant follows a fixed company policy document embedded directly into the system prompt. The customer service policy \u2014 which outlines rules for shipping, returns, fraud detection, and tone \u2014 is provided in full as part of the initial prompt and remains consistent across all turns. Replace our example conversations with your own, and Cleanlab will evaluate the trustworthiness of each response in real-time based on the full conversation history and system instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca41dc-47ad-4289-8beb-1cc4c820aa80",
   "metadata": {},
   "source": [
    "**Optional: Customer Support System Prompt**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"The following is the customer service policy of ACME Inc.\n",
    "# ACME Inc. Customer Service Policy\n",
    "\n",
    "## Table of Contents\n",
    "1. Free Shipping Policy\n",
    "2. Free Returns Policy\n",
    "3. Fraud Detection Guidelines\n",
    "4. Customer Interaction Tone\n",
    "\n",
    "## 1. Free Shipping Policy\n",
    "\n",
    "### 1.1 Eligibility Criteria\n",
    "- Free shipping is available on all orders over $50 within the continental United States.\n",
    "- For orders under $50, a flat rate shipping fee of $5.99 will be applied.\n",
    "- Free shipping is not available for expedited shipping methods (e.g., overnight or 2-day shipping).\n",
    "\n",
    "### 1.2 Exclusions\n",
    "- Free shipping does not apply to orders shipped to Alaska, Hawaii, or international destinations.\n",
    "- Oversized or heavy items may incur additional shipping charges, which will be clearly communicated to the customer before purchase.\n",
    "\n",
    "### 1.3 Handling Customer Inquiries\n",
    "- If a customer inquires about free shipping eligibility, verify the order total and shipping destination.\n",
    "- Inform customers of ways to qualify for free shipping (e.g., adding items to reach the $50 threshold).\n",
    "- For orders just below the threshold, you may offer a one-time courtesy free shipping if it's the customer's first purchase or if they have a history of large orders.\n",
    "\n",
    "### 1.4 Processing & Delivery Timeframes\n",
    "- Standard orders are processed within 1 business day; during peak periods (e.g., holidays) allow up to 3 business days.  \n",
    "- Delivery via ground service typically takes 3-7 business days depending on destination.\n",
    "\n",
    "### 1.5 Shipment Tracking & Notifications\n",
    "- A tracking link must be emailed automatically once the carrier scans the package.  \n",
    "- Agents may resend tracking links on request and walk customers through carrier websites if needed.\n",
    "\n",
    "### 1.6 Lost-Package Resolution\n",
    "1. File a tracer with the carrier if a package shows no movement for 7 calendar days.\n",
    "2. Offer either a replacement shipment or a full refund once the carrier confirms loss.  \n",
    "3. Document the outcome in the order record for analytics.\n",
    "\n",
    "### 1.7 Sustainability & Packaging Standards\n",
    "- Use recyclable or recycled-content packaging whenever available.  \n",
    "- Consolidate items into a single box to minimize waste unless it risks damage.\n",
    "\n",
    "## 2. Free Returns Policy\n",
    "\n",
    "### 2.1 Eligibility Criteria\n",
    "- Free returns are available for all items within 30 days of the delivery date.\n",
    "- Items must be unused, unworn, and in their original packaging with all tags attached.\n",
    "- Free returns are limited to standard shipping methods within the continental United States.\n",
    "\n",
    "### 2.2 Exclusions\n",
    "- Final sale items, as marked on the product page, are not eligible for free returns.\n",
    "- Customized or personalized items are not eligible for free returns unless there is a manufacturing defect.\n",
    "- Undergarments, swimwear, and earrings are not eligible for free returns due to hygiene reasons.\n",
    "\n",
    "### 2.3 Process for Handling Returns\n",
    "1. Verify the order date and ensure it falls within the 30-day return window.\n",
    "2. Ask the customer about the reason for the return and document it in the system.\n",
    "3. Provide the customer with a prepaid return label if they qualify for free returns.\n",
    "4. Inform the customer of the expected refund processing time (5-7 business days after receiving the return).\n",
    "\n",
    "### 2.4 Exceptions\n",
    "- For items damaged during shipping or with manufacturing defects, offer an immediate replacement or refund without requiring a return.\n",
    "- For returns outside the 30-day window, use discretion based on the customer's history and the reason for the late return. You may offer store credit as a compromise.\n",
    "\n",
    "### 2.5 Return Package Preparation Guidelines\n",
    "- Instruct customers to reuse the original box when possible and to cushion fragile items.  \n",
    "- Advise removing or obscuring any prior shipping labels.\n",
    "\n",
    "### 2.6 Inspection & Restocking Procedures\n",
    "- Returns are inspected within 48 hours of arrival.  \n",
    "- Items passing inspection are restocked; those failing inspection follow the disposal flow in \u00a7 2.8.\n",
    "\n",
    "### 2.7 Refund & Exchange Timeframes\n",
    "- Refunds to the original payment method post within 5-7 business days after inspection.  \n",
    "- Exchanges ship out within 1 business day of successful inspection.\n",
    "\n",
    "### 2.8 Disposal of Non-Restockable Goods\n",
    "- Defective items are sent to certified recyclers; lightly used goods may be donated to charities approved by the CSR team.\n",
    "\n",
    "## 3. Fraud Detection Guidelines\n",
    "\n",
    "### 3.1 Red Flags for Potential Fraud\n",
    "- Multiple orders from the same IP address with different customer names or shipping addresses.\n",
    "- Orders with unusually high quantities of the same item.\n",
    "- Shipping address different from the billing address, especially if in different countries.\n",
    "- Multiple failed payment attempts followed by a successful one.\n",
    "- Customers pressuring for immediate shipping or threatening to cancel the order.\n",
    "\n",
    "### 3.2 Verification Process\n",
    "1. For orders flagging as potentially fraudulent, place them on hold for review.\n",
    "2. Verify the customer's identity by calling the phone number on file.\n",
    "3. Request additional documentation (e.g., photo ID, credit card statement) if necessary.\n",
    "4. Cross-reference the shipping address with known fraud databases.\n",
    "\n",
    "### 3.3 Actions for Confirmed Fraud\n",
    "- Cancel the order immediately and refund any charges.\n",
    "- Document the incident in the customer's account and flag it for future reference.\n",
    "- Report confirmed fraud cases to the appropriate authorities and credit card companies.\n",
    "\n",
    "### 3.4 False Positives\n",
    "- If a legitimate customer is flagged, apologize for the inconvenience and offer a small discount or free shipping on their next order.\n",
    "- Document the incident to improve our fraud detection algorithms.\n",
    "\n",
    "### 3.5 Chargeback Response Procedure\n",
    "1. Gather all order evidence (invoice, shipment tracking, customer communications).  \n",
    "2. Submit documentation to the processor within 3 calendar days of chargeback notice.  \n",
    "3. Follow up weekly until the dispute is closed.\n",
    "\n",
    "### 3.6 Data Security & Privacy Compliance\n",
    "- Store verification documents in an encrypted, access-controlled folder.  \n",
    "- Purge personally identifiable information after 180 days unless required for ongoing legal action.\n",
    "\n",
    "### 3.7 Continuous Improvement & Training\n",
    "- Run quarterly reviews of fraud rules with data analytics.  \n",
    "- Provide annual anti-fraud training to all front-line staff.\n",
    "\n",
    "### 3.8 Record-Keeping Requirements\n",
    "- Maintain a log of all fraud reviews\u2014including false positives\u2014for 3 years to support audits.\n",
    "\n",
    "## 4. Customer Interaction Tone\n",
    "\n",
    "### 4.1 General Guidelines\n",
    "- Always maintain a professional, friendly, and empathetic tone.\n",
    "- Use the customer's name when addressing them.\n",
    "- Listen actively and paraphrase the customer's concerns to ensure understanding.\n",
    "- Avoid negative language; focus on what can be done rather than what can't.\n",
    "\n",
    "### 4.2 Specific Scenarios\n",
    "\n",
    "#### Angry or Frustrated Customers\n",
    "- Remain calm and do not take comments personally.\n",
    "- Acknowledge the customer's feelings and apologize for their negative experience.\n",
    "- Focus on finding a solution and clearly explain the steps you'll take to resolve the issue.\n",
    "- If necessary, offer to escalate the issue to a supervisor.\n",
    "\n",
    "#### Confused or Indecisive Customers\n",
    "- Be patient and offer clear, concise explanations.\n",
    "- Ask probing questions to better understand their needs.\n",
    "- Provide options and explain the pros and cons of each.\n",
    "- Offer to send follow-up information via email if the customer needs time to decide.\n",
    "\n",
    "#### VIP or Loyal Customers\n",
    "- Acknowledge their status and thank them for their continued business.\n",
    "- Be familiar with their purchase history and preferences.\n",
    "- Offer exclusive deals or early access to new products when appropriate.\n",
    "- Go above and beyond to exceed their expectations.\n",
    "\n",
    "### 4.3 Language and Phrasing\n",
    "- Use positive language: \"I'd be happy to help you with that\" instead of \"I can't do that.\"\n",
    "- Avoid technical jargon or abbreviations that customers may not understand.\n",
    "- Use \"we\" statements to show unity with the company: \"We value your feedback\" instead of \"The company values your feedback.\"\n",
    "- End conversations on a positive note: \"Is there anything else I can assist you with today?\"\n",
    "\n",
    "### 4.4 Written Communication\n",
    "- Use proper grammar, spelling, and punctuation in all written communications.\n",
    "- Keep emails and chat responses concise and to the point.\n",
    "- Use bullet points or numbered lists for clarity when providing multiple pieces of information.\n",
    "- Include a clear call-to-action or next steps at the end of each communication.\n",
    "\n",
    "### 4.5 Response-Time Targets\n",
    "- Live chat: respond within 30 seconds.  \n",
    "- Email: first reply within 4 business hours (max 24 hours during peak).  \n",
    "- Social media mentions: acknowledge within 1 hour during staffed hours.\n",
    "\n",
    "### 4.6 Accessibility & Inclusivity\n",
    "- Offer alternate text for images and use plain-language summaries.  \n",
    "- Provide TTY phone support and ensure web chat is screen-reader compatible.\n",
    "\n",
    "### 4.7 Multichannel Etiquette (Phone, Chat, Social)\n",
    "- Use consistent greetings and closings across channels.  \n",
    "- Avoid emojis in formal email; limited, brand-approved emojis allowed in chat or social when matching customer tone.\n",
    "\n",
    "### 4.8 Proactive Outreach & Follow-Up\n",
    "- After resolving a complex issue, send a 24-hour satisfaction check-in.  \n",
    "- Tag VIP accounts for quarterly \u201cthank-you\u201d notes highlighting new offerings.\n",
    "\n",
    "### 4.9 Documentation of Customer Interactions\n",
    "- Log every interaction in the CRM within 15 minutes of completion, including sentiment and resolution code.  \n",
    "- Use standardized tags to support trend analysis and training.\n",
    "\n",
    "You are a customer service assistant for ACME Inc. Answer customer questions accurately, concisely, and in line with the company's service policy. Do not suggest contacting customer service.\n",
    "Remember, as a representative of ACME Inc., you are often the first point of contact for our customers. Your interactions should always reflect our commitment to exceptional customer service and satisfaction.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [{\"role\": \"system\", \"content\": system_prompt}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time Evaluation using Trustworthy Language Model\n",
    "\n",
    "Cleanlab evaluates each response in your conversational AI system using the Trustworthy Language Model \u2014 a state-of-the-art LLM uncertainty estimator. It provides a trustworthiness score that reflects how likely a given chatbot response is to be accurate and aligned with its instructions. Cleanlab runs in real time and can be used to monitor individual responses or analyze patterns of failure across conversations.\n",
    "\n",
    "Here, we instantiate the TLM client using low-latency settings: `quality_preset=\"low\"` and `model=\"gpt-4.1-mini\"` (specified in the options dictionary). We also set `log=[\"explanation\"]` to receive rationales for why each LLM response is judged as trustworthy or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlm = TLM(quality_preset=\"low\", options={'model':'gpt-4.1-mini', 'log':['explanation']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b539b-d81f-41bb-88ba-b231a67f03cd",
   "metadata": {},
   "source": [
    "**Optional: Helper function to pretty print TLM results**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def display_tlm_feedback(response_text: str, resp: dict, threshold: float = 0.8, explanation: bool = True):\n",
    "    print(\"=\" * 30 + \" AI Message \" + \"=\" * 30)\n",
    "\n",
    "    # Wrap and print the AI response across multiple lines\n",
    "    wrapped_response = textwrap.fill(response_text.strip(), width=100)\n",
    "    print(wrapped_response + \"\\n\")\n",
    "\n",
    "    score = resp.get(\"trustworthiness_score\")\n",
    "    if score is None:\n",
    "        print(\"[TLM Error]: No trustworthiness score found in response.\")\n",
    "        return\n",
    "\n",
    "    label = \"Trustworthy\" if score >= threshold else \"Untrustworthy\"\n",
    "    print(f\"[TLM Score]: {score} ({label})\")\n",
    "\n",
    "    if explanation:\n",
    "        explanation_text = resp.get(\"log\", {}).get(\"explanation\")\n",
    "        if explanation_text:\n",
    "            print(f\"[TLM Score Explanation]: {explanation_text}\")\n",
    "        else:\n",
    "            print(\"[TLM Warning]: Enable the 'explanation' option in the TLM client to receive detailed reasoning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring is done by converting your chat history into a prompt string using `form_prompt_string`, then passing it along with the chatbot's latest response into the TLM client. Let\u2019s evaluate the chatbot response to our first example query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== AI Message ==============================\n",
      "Hello! Unfortunately, to be eligible for a free return, the jeans need to be unused, unworn, and in\n",
      "their original packaging with all tags attached. If the jeans have been worn, they would not qualify\n",
      "for a free return. Please let me know if you need assistance with a different item or further\n",
      "questions!\n",
      "\n",
      "[TLM Score]: 0.982129737222567 (Trustworthy)\n",
      "[TLM Score Explanation]: Did not find a reason to doubt trustworthiness.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Can I return my jeans even if I've worn them?\"\n",
    "\n",
    "# Your existing LLM chat code\n",
    "chat_history = update_chat_history(chat_history, \"user\", user_input)\n",
    "response = generate_llm_response(chat_history)\n",
    "\n",
    "# Extra code for trustworthiness scoring\n",
    "tlm_results = tlm.get_trustworthiness_score(\n",
    "    prompt = form_prompt_string(chat_history), response=response\n",
    ")\n",
    "\n",
    "# Your existing LLM chat code\n",
    "chat_history = update_chat_history(chat_history, \"assistant\", response)\n",
    "\n",
    "display_tlm_feedback(response_text=response, resp=tlm_results, threshold=0.85, explanation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the chatbot response, we find that it clearly and accurately follows the refund policy. Cleanlab\u2019s TLM score automatically confirmed this in real time. Next, we\u2019ll evaluate the chatbot\u2019s response to a follow-up question \u2014 one that depends on the context established in the first exchange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== AI Message ==============================\n",
      "If the jeans have been worn once and do not have any defects, they typically wouldn't be eligible\n",
      "for a free return. However, you can still return the item by paying the standard $5.99 shipping fee\n",
      "for a return. Please make sure the item is unused, unworn, and in its original packaging to proceed\n",
      "with the return.\n",
      "\n",
      "[TLM Score]: 0.4784828550368547 (Untrustworthy)\n",
      "[TLM Score Explanation]: The policy states worn items are not eligible for free returns except for defects. It does not mention paid returns for worn items. The assistant incorrectly suggests paying a $5.99 fee for a return of worn jeans, which contradicts the policy.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I've only worn it once. Can I just pay the shipping fee?\"\n",
    "\n",
    "# Your existing LLM chat code\n",
    "chat_history = update_chat_history(chat_history, \"user\", user_input)\n",
    "response = generate_llm_response(chat_history)\n",
    "\n",
    "# Extra code for trustworthiness scoring\n",
    "tlm_results = tlm.get_trustworthiness_score(\n",
    "    prompt = form_prompt_string(chat_history), response=response\n",
    ")\n",
    "\n",
    "# Your existing LLM chat code\n",
    "chat_history = update_chat_history(chat_history, \"assistant\", response)\n",
    "\n",
    "display_tlm_feedback(response_text=response, resp=tlm_results, threshold=0.85, explanation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chatbot correctly interpreted the user\u2019s question as asking about return eligibility for jeans, showing it successfully incorporated context from earlier in the conversation. However, Cleanlab\u2019s TLM flagged the response as untrustworthy, assigning it a lower trustworthiness score.\n",
    "\n",
    "Referring to the return policy in the system prompt:\n",
    "\n",
    "> *Free returns are available for all items within 30 days of the delivery date.*\n",
    "\n",
    "However, it does not clarify whether items can still be returned if the customer were to cover return shipping. This ambiguity was successfully identified by TLM.\n",
    "\n",
    "### Custom Evals\n",
    "\n",
    "You can also specify custom evaluations to assess specific criteria. For example, you may not want to rely on TLM's trustworthiness score for every chatbot response, but rather only for verifiable statements that convey information. You can run TLM with a [custom evaluation criterion](/tlm/tutorials/tlm_custom_eval/) like the following:\n",
    "\n",
    "*Determine whether the response is non-propositional, in which case it is great. Otherwise it is a bad response if it conveys any specific information or facts, or otherwise seems like an answer whose accuracy could matter.*\n",
    "\n",
    "Then, you could only consider TLM's trustworthiness score for those responses whose custom evaluation score is low.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}