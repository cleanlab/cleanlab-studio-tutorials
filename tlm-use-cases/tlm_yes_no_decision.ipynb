{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trustworthy Yes/No Decision Automation with TLM (Binary Classification)\n",
    "\n",
    "<head>\n",
    "  <meta name=\"title\" content=\"Trustworthy Yes/No Decision Automation with TLM\"/>\n",
    "  <meta property=\"og:title\" content=\"Trustworthy Yes/No Decision Automation with TLM\"/>\n",
    "  <meta name=\"twitter:title\" content=\"Trustworthy Yes/No Decision Automation with TLM\" />\n",
    "  <meta name=\"image\" content=\"/img/tlm_yes_no_decision.png\" />\n",
    "  <meta property=\"og:image\" content=\"/img/tlm_yes_no_decision.png\" />\n",
    "  <meta name=\"description\" content=\"Automating yes/no decisions (binary classification) with the Trustworthy Language Model.\"  />\n",
    "  <meta property=\"og:description\" content=\"Automating yes/no decisions (binary classification) with the Trustworthy Language Model.\" />\n",
    "  <meta name=\"twitter:description\" content=\"Automating yes/no decisions (binary classification) with the Trustworthy Language Model.\" />\n",
    "</head>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to use the Trustworthy Language Model (TLM) to automate Yes/No decisions, or more generally, for **any binary classification** task where you want an LLM to pick between two options (e.g. *True* or *False*, *A* or *B*, etc).\n",
    "\n",
    "To use TLM for *multi-class classification* tasks where your LLM picks from more than two options, refer to our [Zero-Shot Classification Tutorial](/tlm/use-cases/zero_shot_classification/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "This tutorial requires a TLM API key. Get one [here](https://tlm.cleanlab.ai/).\n",
    "\n",
    "Cleanlab\u2019s Python client can be installed using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade cleanlab-tlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "import os\n",
    "os.environ[\"CLEANLAB_TLM_API_KEY\"] = \"<API key>\" # Get your free API key from: https://tlm.cleanlab.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab_tlm import TLM\n",
    "\n",
    "tlm = TLM(quality_preset=\"low\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification dataset\n",
    "\n",
    "Let's consider a dataset composed of customer service messages received by a bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://cleanlab-public.s3.us-east-1.amazonaws.com/Datasets/tlm-annotation-tutorial/customer-service-text.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i need to cancel my recent transfer as soon as possible. i made an error there. please help before it goes through.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is there a fee when i thought there would be no fees?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do i replace my card before it expires next month?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what should i do if someone stole my phone?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>please help me get a visa card.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  text\n",
       "0  i need to cancel my recent transfer as soon as possible. i made an error there. please help before it goes through.\n",
       "1                                                            why is there a fee when i thought there would be no fees?\n",
       "2                                                               how do i replace my card before it expires next month?\n",
       "3                                                                          what should i do if someone stole my phone?\n",
       "4                                                                                      please help me get a visa card."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"customer-service-text.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, let's suppose the **goal** is to determine: whether each customer is asking for help changing their card's PIN, or about something else.\n",
    "\n",
    "This is a *decision making* task, which we we want to automate using an LLM that takes in a customer message and outputs:\n",
    "- \"Yes\" if the request is about changing their card PIN\n",
    "- \"No\" otherwise\n",
    "\n",
    "\n",
    "## Apply TLM for Yes/No decision making\n",
    "\n",
    "In binary decision-making, LLM errors (false positives/negatives) may have asymmetric impact. For example, incorrectly predicting *Yes* may be 3x worse than incorrectly predicting *No*.\n",
    "\n",
    "If we just have an LLM output either *Yes* or *No*, it will be difficult to control the false positive/negative error rates. Instead you can use TLM to produce a score reflecting the LLM's confidence that *Yes* is the right decision. You can subsequently translate these scores into Yes/No predictions by choosing the score-threshold which achieves the best false positive/negative error rates for your use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trustworthiness Score: 0.999830669558766\n"
     ]
    }
   ],
   "source": [
    "customer_message = \"I need to change my card's PIN\"\n",
    "\n",
    "prompt_template = '''Given the following customer message, determine if it is about the customer needing help changing their card's PIN. Please respond with only \"Yes\" or \"No\" with no leading or trailing text.\n",
    "Here is the customer message: {}'''\n",
    "prompt = prompt_template.format(customer_message)\n",
    "\n",
    "# Note how we specify the only outputs to consider are: Yes or No\n",
    "response = tlm.get_trustworthiness_score(prompt, \"Yes\", constrain_outputs=[\"Yes\", \"No\"])\n",
    "\n",
    "print(\"Trustworthiness Score:\", response[\"trustworthiness_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the above example, the trustworthiness score indicates the LLM's confidence that *Yes* is the right decision. You can confidently decide *Yes* for examples where this score is high, and *No* for examples where this score is low.\n",
    "\n",
    "## Run TLM for automated decision-making over the dataset\n",
    "\n",
    "Let's now apply TLM to predict decisions for every customer message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following customer message, determine if it is about the customer needing help changing their card's PIN. Please respond with only \"Yes\" or \"No\" with no leading or trailing text.\n",
      "Here is the customer message: i need to cancel my recent transfer as soon as possible. i made an error there. please help before it goes through.\n"
     ]
    }
   ],
   "source": [
    "# Construct prompt for each message.\n",
    "all_prompts = [prompt_template.format(text) for text in df.text]\n",
    "print(all_prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying TLM... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>trustworthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i need to cancel my recent transfer as soon as possible. i made an error there. please help before it goes through.</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is there a fee when i thought there would be no fees?</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do i replace my card before it expires next month?</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  text  \\\n",
       "0  i need to cancel my recent transfer as soon as possible. i made an error there. please help before it goes through.   \n",
       "1                                                            why is there a fee when i thought there would be no fees?   \n",
       "2                                                               how do i replace my card before it expires next month?   \n",
       "\n",
       "   trustworthiness  \n",
       "0         0.000469  \n",
       "1         0.000469  \n",
       "2         0.000469  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score the entire dataset in one batch.\n",
    "responses = tlm.get_trustworthiness_score(all_prompts, [\"Yes\"] * len(all_prompts), constrain_outputs=[\"Yes\", \"No\"])\n",
    "\n",
    "# Extract the scores from each response\n",
    "scores = [response[\"trustworthiness_score\"] for response in responses]\n",
    "df[\"trustworthiness\"] = scores\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Prediction Performance\u00a0(Optional) \n",
    "\n",
    "In this section, we introduce ground-truth labels solely in order to evaluate the performance of TLM. These ground-truth labels are never provided to TLM, and this section can be skipped if you don't have ground-truth labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://cleanlab-public.s3.us-east-1.amazonaws.com/Datasets/tlm-annotation-tutorial/customer-service-categories.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>trustworthiness</th>\n",
       "      <th>ground_truth_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i need to cancel my recent transfer as soon as possible. i made an error there. please help before it goes through.</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is there a fee when i thought there would be no fees?</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do i replace my card before it expires next month?</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  text  \\\n",
       "0  i need to cancel my recent transfer as soon as possible. i made an error there. please help before it goes through.   \n",
       "1                                                            why is there a fee when i thought there would be no fees?   \n",
       "2                                                               how do i replace my card before it expires next month?   \n",
       "\n",
       "   trustworthiness ground_truth_label  \n",
       "0         0.000469                 No  \n",
       "1         0.000469                 No  \n",
       "2         0.000469                 No  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_labels = pd.read_csv(\"customer-service-categories.csv\")\n",
    "df['ground_truth_label'] = np.where(ground_truth_labels['label'] == \"change pin\", \"Yes\", \"No\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowest confidence examples\n",
    "\n",
    "Let's sort the messages by TLM's confidence score\u00a0for *Yes*, and look at a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>trustworthiness</th>\n",
       "      <th>ground_truth_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i need to cancel my recent transfer as soon as possible. i made an error there. please help before it goes through.</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>my google pay top up isn't working. help.</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>how do i top up using my apple watch?</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    text  \\\n",
       "0    i need to cancel my recent transfer as soon as possible. i made an error there. please help before it goes through.   \n",
       "630                                                                            my google pay top up isn't working. help.   \n",
       "633                                                                                how do i top up using my apple watch?   \n",
       "\n",
       "     trustworthiness ground_truth_label  \n",
       "0           0.000469                 No  \n",
       "630         0.000469                 No  \n",
       "633         0.000469                 No  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"trustworthiness\", ascending=True).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the lowest scores were given to messages that are not related to changing card PIN (these are obvious cases where *No* is the right decision)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest confidence examples\n",
    "\n",
    "We can also view messages where TLM estimated highest confidence that *Yes* is the right decision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>trustworthiness</th>\n",
       "      <th>ground_truth_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>which atm's am i able to change my pin?</td>\n",
       "      <td>0.999831</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>how do i change my pin while traveling?</td>\n",
       "      <td>0.999831</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>how can i reset my pin?</td>\n",
       "      <td>0.999831</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text  trustworthiness  \\\n",
       "104  which atm's am i able to change my pin?         0.999831   \n",
       "28   how do i change my pin while traveling?         0.999831   \n",
       "664                  how can i reset my pin?         0.999831   \n",
       "\n",
       "    ground_truth_label  \n",
       "104                Yes  \n",
       "28                 Yes  \n",
       "664                Yes  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"trustworthiness\", ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the highest trustworthiness scores are given to examples that are related to changing card PIN (cases where *Yes* is clearly the right decision)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate results\n",
    "\n",
    "Let's plot the distribution of these confidence scores, grouping the messages by their ground-truth label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab3d999-93a3-482b-a997-70e80c48fdb0",
   "metadata": {},
   "source": [
    "**Optional: Plotting code**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_results(train_df, score_col):\n",
    "    \"\"\"\n",
    "    Analyze results and find best threshold from training data\n",
    "    Returns best threshold and mismatches dataframe\n",
    "    \"\"\"\n",
    "    # Plot distribution of trustworthiness scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=train_df, x=score_col, hue='ground_truth_label', bins=20)\n",
    "    plt.title('Distribution of Trustworthiness Scores by Label')\n",
    "    plt.xlabel('Trustworthiness Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "analyze_results(df, \"trustworthiness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TLM performance on Yes/No decisions](./assets/tlm-yes-no-decisions/tlm_yes_no_decision.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the TLM score is consistently lower for \"No\" ground-truth examples (messages that are unrelated to changing PIN), while \"Yes\" ground truth examples (messages that are actually requesting a PIN change) received consistently higher scores from TLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yes/No Decision with Unsure option\n",
    "\n",
    "Sometimes, it may be useful to include an \"Unsure\" option for your LLM to consider. This can be done by setting TLM's `constrain_outputs` parameter to: `[\"Yes\", \"No\", \"Unsure\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the following customer message, determine if it is about the customer needing help changing their card's PIN. Please respond with only \"Yes\", \"No\", or \"Unsure\" with no leading or trailing text.\n",
      "Here is the customer message: i need to cancel my recent transfer as soon as possible. i made an error there. please help before it goes through.\n"
     ]
    }
   ],
   "source": [
    "prompt_template_with_unsure = '''Given the following customer message, determine if it is about the customer needing help changing their card's PIN. Please respond with only \"Yes\", \"No\", or \"Unsure\" with no leading or trailing text.\n",
    "Here is the customer message: {}'''\n",
    "\n",
    "# Construct prompt for each message to label.\n",
    "all_prompts_with_unsure = [prompt_template_with_unsure.format(text) for text in df.text]\n",
    "print(all_prompts_with_unsure[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the entire dataset in one batch.\n",
    "responses_with_unsure = tlm.get_trustworthiness_score(all_prompts_with_unsure, [\"Yes\"] * len(all_prompts_with_unsure), constrain_outputs=[\"Yes\", \"No\", \"Unsure\"])\n",
    "\n",
    "# Extract the scores from each response\n",
    "scores = [response[\"trustworthiness_score\"] for response in responses_with_unsure]\n",
    "df[\"trustworthiness_with_unsure\"] = scores\n",
    "\n",
    "analyze_results(df, \"trustworthiness_with_unsure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TLM performance on Yes/No decisions with Unsure option](./assets/tlm-yes-no-decisions/tlm_yes_no_decision_with_unsure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that TLM's confidence score is again consistently higher for \"Yes\" ground truth examples (messages that are actually requesting a PIN change)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}