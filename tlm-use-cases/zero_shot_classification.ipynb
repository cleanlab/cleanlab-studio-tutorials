{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reliable Zero-Shot Classification with the Trustworthy Language Model\n",
    "\n",
    "<head>\n",
    "  <meta name=\"title\" content=\"Reliable zero-shot classification with the Trustworthy Language Model\"/>\n",
    "  <meta property=\"og:title\" content=\"Reliable zero-shot classification with the Trustworthy Language Model\"/>\n",
    "  <meta name=\"twitter:title\" content=\"Reliable zero-shot classification with the Trustworthy Language Model\" />\n",
    "  <meta name=\"image\" content=\"/img/tlm_zero_shot_classification.png\" />\n",
    "  <meta property=\"og:image\" content=\"/img/tlm_zero_shot_classification.png\" />\n",
    "  <meta name=\"description\" content=\"Determine which documents/text can be reliably auto-labeled and which cannot.\"  />\n",
    "  <meta property=\"og:description\" content=\"Determine which documents/text can be reliably auto-labeled and which cannot.\" />\n",
    "  <meta name=\"twitter:description\" content=\"Determine which documents/text can be reliably auto-labeled and which cannot.\" />\n",
    "</head>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In zero-shot (or *few*-shot) classification, we use a Foundation model to classify input data into predefined categories (aka. *classes*), without having to train this model on a manually annotated dataset. This requires much less work than training/deploying classical machine learning models (no data preparation/labeling required either) and can generalize better across evolving environments. The problem with classification with pretrained LLMs is **we don't know which LLM classifications we can trust**. LLMs are prone to *hallucination* and will often predict a category even when their world knowledge does not suffice to justify this prediction.\n",
    "\n",
    "This tutorial demonstrates how you can easily replace *any* LLM with Cleanlab's [Trustworthy Language Model (TLM)](/tlm/tutorials/tlm/) to:\n",
    "\n",
    "1. **Score the trustworthiness of each classification**\n",
    "2. **Automatically boost classification accuracy**\n",
    "\n",
    "Use TLM to ensure **reliable classification** where you know which model predictions cannot be trusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This tutorial requires a TLM API key. Get one [here](https://tlm.cleanlab.ai/).\n",
    "\n",
    "The Python client package can be installed using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install cleanlab-tlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "import os\n",
    "os.environ[\"CLEANLAB_TLM_API_KEY\"] = \"<API key>\" # Get your free API key from: https://tlm.cleanlab.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cleanlab_tlm import TLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load an example classification dataset. Here we consider legal documents from the \"US\" Jurisdiction of the [Multi_Legal_Pile](https://arxiv.org/abs/2306.02069). We aim to classify each document into one of three categories: `[caselaw, contracts, legislation]`.\n",
    "We'll prompt our TLM to categorize each document and record its response and associated trustworthiness score. You can use the ideas from this tutorial to improve LLMs for *any* other classification task! \n",
    "\n",
    "First download our dataset and load it into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc 'https://cleanlab-public.s3.amazonaws.com/Datasets/zero_shot_classification.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Probl2B\\n0/NV Form\\nRev. June 2014\\n\\n\\n\\n    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>UNITED STATES DI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      0  Probl2B\\n0/NV Form\\nRev. June 2014\\n\\n\\n\\n    ...\n",
       "1      1                                UNITED STATES DI..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('zero_shot_classification.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Zero Shot Classification with TLM\n",
    "\n",
    "Let's initalize a `TLM` object using `gpt-4o` as the underlying base model. [Advanced configuration options](/tlm/tutorials/tlm_advanced/#quality-presets) exist that can produce improved classification accuracy or trustworthiness scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o\"  # which base LLM should TLM utilize\n",
    "tlm = TLM(options={\"model\": MODEL})  # to boost accuracy, consider adding: quality_preset = 'best'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a prompt template to instruct TLM on how to classify each document. Write your prompt just as you would with any other LLM when adapting it for zero-shot classification. A good prompt template might contain all the possible categories a document can be classified as, as well as formatting instructions for the LLM response. Of course the text of the document is crucial.\n",
    "\n",
    "```python\n",
    "'You are an expert Legal Document Auditor. Classify the following document into a single category that best represents it. The categories are: {categories}. In your response, first provide a brief explanation as to why the document belongs to a specific category and then on a new line write \"Category: <category document belongs to>\". \\nDocument: {document}'\n",
    "\n",
    "```\n",
    "\n",
    "If you have a couple labeled examples from different classes, you may be able to get better LLM predictions via *few-shot* prompting (where these examples + their classes are embedded within the prompt). Here we'll stick with zero-shot classification for simplicity, but note that TLM can also be used for few-shot classification just like any other LLM.\n",
    "\n",
    "Let's apply the above prompt template to all documents in our dataset and form the list of prompts we want to run. For one arbitrary document, we print the actual corresponding prompt fed into TLM below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert Legal Document Auditor. Classify the following document into a single category that best represents it. The categories are: [caselaw, contracts, legislation]. In your response, first provide a brief explanation as to why the document belongs to a specific category and then on a new line write \"Cateogry: <category document belongs to>\". \n",
      "Document: UNITED STATES DISTRICT COURT\n",
      "SOUTHERN DISTRICT OF NEW YORK\n",
      "\n",
      "UNITED STATES OF AMERICA,\n",
      "\n",
      "                 v.                                                ORDER\n",
      "\n",
      "JOSE DELEON,                                                    14 Cr. 28 (PGG)\n",
      "\n",
      "                         Defendant.\n",
      "\n",
      "\n",
      "PAUL G. GARDEPHE, U.S.D.J.:\n",
      "\n",
      "              It is hereby ORDERED that the violation of supervised release hearing currently\n",
      "\n",
      "scheduled for January 8, 2020 is adjourned to January 15, 2020 at 3:30 p.m. in Courtroom 705\n",
      "\n",
      "of the Thurgood Marshall United States Courthouse, 40 Foley Square, New York, New York.\n",
      "\n",
      "Dated: New York, New York\n",
      "       January 8, 2020\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "zero_shot_prompt_template = 'You are an expert Legal Document Auditor. Classify the following document into a single category that best represents it. The categories are: {categories}. In your response, first provide a brief explanation as to why the document belongs to a specific category and then on a new line write \"Cateogry: <category document belongs to>\". \\nDocument: {document}'\n",
    "categories = ['caselaw', 'contracts', 'legislation']\n",
    "string_categories = str(categories).replace('\\'', '')\n",
    "\n",
    "# Create a DataFrame to store results and apply the prompt template to all examples\n",
    "results_df = df.copy()\n",
    "results_df['prompt'] = results_df['text'].apply(lambda x: zero_shot_prompt_template.format(categories=string_categories, document=x))\n",
    "\n",
    "print(f\"{results_df.at[7, 'prompt']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prompt TLM and save the output responses and their associated trustworthiness scores for all examples. We recommend the `try_prompt()` method to run TLM over datasets with many examples. We also use the `constrain_outputs` parameter to ensure that TLM always outputs one of the valid categories. The *last entry* in the `constrain_outputs` list is treated as the category to fall back to whenever the LLM fails to choose one of the categories (so optionally order your categories such that the last one is what you would choose in cases of high uncertainty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying TLM... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588|\n"
     ]
    }
   ],
   "source": [
    "outputs = tlm.try_prompt(results_df['prompt'].to_list(), constrain_outputs=categories + [\"other\"])\n",
    "\n",
    "results_df[[\"predicted_category\",\"trustworthiness_score\"]] = pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf9a43-dc10-496e-ac97-c5046c304943",
   "metadata": {},
   "source": [
    "**Optional: Define helper methods to better display results.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_result(results_df: pd.DataFrame, index: int):\n",
    "    \"\"\"Displays TLM result for the example from the dataset whose `index` is provided.\"\"\"\n",
    "    \n",
    "    print(f\"TLM predicted category: {results_df.iloc[index].predicted_category}\")\n",
    "    print(f\"TLM trustworthiness score: {results_df.iloc[index].trustworthiness_score}\\n\")\n",
    "    print(results_df.iloc[index].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Classification Results\n",
    "\n",
    "Let's first inspect the most trustworthy predictions from our model. We sort the TLM outputs over our documents to see which predictions received the highest trustworthiness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLM predicted category: contracts\n",
      "TLM trustworthiness score: 0.966594896528417\n",
      "\n",
      "EXHIBIT 10\n",
      "\n",
      "WIRELESS RONIN TECHNOLOGIES, INC.\n",
      "\n",
      "SENIOR MANAGEMENT BONUS PLAN\n",
      "\n",
      "Effective January\u00a01, 2012\n",
      "\n",
      "The Senior Management Bonus Plan (the \u201cPlan\u201d) provides bonuses to certain\n",
      "members of the Company\u2019s senior management team. Such bonuses are based 50\n",
      "percent upon the Company\u2019s annual gross revenue dollars and 50 percent upon the\n",
      "Company\u2019s adjusted EBITDA, which is calculated based upon the Company\u2019s\n",
      "accounting practices, consistently applied and upon GAAP standards applicable to\n",
      "the Company.\n",
      "\n",
      "The Company\u2019s Compensation Committee has identified eligible members of senior\n",
      "management and established annual gross revenue dollar and adjusted EBITDA goals\n",
      "for the upcoming plan year. The Company\u2019s Board of Directors and the\n",
      "Compensation Committee of the Board reserve the right to modify, terminate or\n",
      "suspend this Plan at any time in the Board or Committee\u2019s sole discretion.\n",
      "\n",
      "\u00a0\n",
      "\n",
      "September 30,\n",
      "\n",
      "Percentage of Goal Annual\n",
      "\n",
      "Gross Revenue Dollar\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 Percentage\u00a0of\u00a0Goal\u00a0Annual\u00a0Gross\u00a0Revenue\n",
      "Dollar portion of Target Bonus \u00a0\n",
      "\n",
      "Less than 85%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 0 %\u00a0\n",
      "\n",
      "85% to < 100%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 12.5 %\u00a0\n",
      "\n",
      "100% to < 110%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 50 %\u00a0\n",
      "\n",
      "110% to\u00a0< 120%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 55 %\u00a0\n",
      "\n",
      "120% to < 130%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 60 %\u00a0\n",
      "\n",
      "130% to < 140%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 65 %\u00a0\n",
      "\n",
      "140% to < 150%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 70 %\u00a0\n",
      "\n",
      "150% to < 160%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 75 %\u00a0\n",
      "\n",
      "160% to < 170%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 80 %\u00a0\n",
      "\n",
      "170% to < 180%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 85 %\u00a0\n",
      "\n",
      "180% to < 190%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 90 %\u00a0\n",
      "\n",
      "190% to < 200%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 95 %\u00a0\n",
      "\n",
      "Over 200%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 100 %\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "September 30,\n",
      "\n",
      "Percentage of Goal Annual\n",
      "\n",
      "Adjusted EBITDA\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 Percentage\u00a0of\u00a0Goal\u00a0Annual\u00a0Adjusted\n",
      "EBITDA portion of Target Bonus \u00a0\n",
      "\n",
      "Less than 85%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 0 %\u00a0\n",
      "\n",
      "85% to < 100%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 12.5 %\u00a0\n",
      "\n",
      "100% to < 110%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 50 %\u00a0\n",
      "\n",
      "110% to\u00a0< 120%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 55 %\u00a0\n",
      "\n",
      "120% to < 130%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 60 %\u00a0\n",
      "\n",
      "130% to < 140%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 65 %\u00a0\n",
      "\n",
      "140% to < 150%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 70 %\u00a0\n",
      "\n",
      "150% to < 160%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 75 %\u00a0\n",
      "\n",
      "160% to < 170%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 80 %\u00a0\n",
      "\n",
      "170% to < 180%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 85 %\u00a0\n",
      "\n",
      "180% to < 190%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 90 %\u00a0\n",
      "\n",
      "190% to < 200%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 95 %\u00a0\n",
      "\n",
      "Over 200%\n",
      "\n",
      "\u00a0\u00a0\u00a0\u00a0 \u00a0 100 %\u00a0\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "The following process documents how bonus payouts are to be calculated:\n",
      "(1)\u00a0actual gross revenue dollar performance for 2012 is compared to targeted\n",
      "gross revenue dollar performance for 2012, (2)\u00a0the percentage payout associated\n",
      "with that gross revenue dollar performance is multiplied by the named\n",
      "executive\u2019s target bonus amount, then multiplied by the portion of the payout\n",
      "associated with gross revenue dollars (50%), (3)\u00a0actual adjusted EBITDA\n",
      "performance for 2012 is compared to targeted adjusted EBITDA performance for\n",
      "2012, (4)\u00a0the percentage payout associated with that adjusted EBITDA performance\n",
      "is multiplied by the named executive\u2019s target bonus amount, then multiplied by\n",
      "the portion of the payout associated with adjusted EBITDA (50%), then (5)\u00a0the\n",
      "numbers generated in steps (2)\u00a0and (4)\u00a0are added together to generate the total\n",
      "bonus payout.\n",
      "\n",
      "\u201cAdjusted EBITDA\u201d as used by the Compensation Committee equals the Company\u2019s\n",
      "earnings before all interest, tax, depreciation, amortization and stock-based\n",
      "expenses but after payment of non-equity based employee bonuses.\n"
     ]
    }
   ],
   "source": [
    "results_df = results_df.sort_values(by='trustworthiness_score', ascending=False)\n",
    "display_result(results_df, index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A document about \"SENIOR MANAGEMENT BONUS PLAN, Effective January 1, 2012\" is clearly a contract, so it makes sense that TLM classifies it into the \"contracts\" category with high trustworthiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLM predicted category: contracts\n",
      "TLM trustworthiness score: 0.9608771429046686\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AMENDMENT No. 4 TO EMPLOYMENT AGREEMENT\n",
      "\n",
      "\n",
      "THIS AMENDMENT No. 4 TO EMPLOYMENT AGREEMENT (\u201cAmendment No. 3\u201d), is entered\n",
      "into as of August 3, 2017 (the \u201cEffective Date\u201d), by and between Third Point\n",
      "Reinsurance Ltd., a Bermuda company (the \u201cCompany\u201d), and Manoj K. Gupta (the\n",
      "\u201cExecutive\u201d).\n",
      "\n",
      "\n",
      "WHEREAS, the Company and the Executive entered into a certain Employment\n",
      "Agreement dated as of March 27, 2012, an Amendment No. 1 to Employment Agreement\n",
      "dated as of February 26, 2015, an Amendment No. 2 to Employment Agreement dated\n",
      "as of April 1, 2016, and an Amendment No. 3 to Employment Agreement dated as of\n",
      "March 1, 2017 (collectively, the \u201cEmployment Agreement\u201d); and\n",
      "\n",
      "\n",
      "WHEREAS, in consideration of the mutual agreements set forth below and for other\n",
      "good and valuable consideration given, by each party to this Amendment No. 4 to\n",
      "the other, the receipt and sufficiency of which are hereby acknowledged, the\n",
      "Company and Executive agree to amend the Employment Agreement on the terms set\n",
      "forth below.\n",
      "\n",
      "\n",
      "NOW, THEREFORE, the parties hereto, intending to be legally bound, hereby agree\n",
      "as follows:\n",
      "1.\n",
      "Section 2 (a) Duties of the Employment Agreement shall be amended to read as\n",
      "follows:\n",
      "\n",
      "\u201c2. Extent of Employment.\n",
      "(a) Duties. During the Employment Term and from and after the Effective Date,\n",
      "the Executive shall serve as President of TPRe USA. In addition, the Executive\n",
      "shall continue to serve as the Company\u2019s Head of Investor Relations and Business\n",
      "Development, in such capacity reporting to the Chief Executive Officer of the\n",
      "Company. In each function, the Executive shall perform such duties, services,\n",
      "and responsibilities on behalf of TPRe USA and the Company, respectively,\n",
      "consistent with such positions as may be reasonably assigned to the Executive\n",
      "from time to time.\n",
      "2.\n",
      "The parties hereto agree that except as specifically set forth in this Amendment\n",
      "No. 4, each and every provision of the Employment Agreement shall remain in full\n",
      "force and effect as set forth therein.\n",
      "\n",
      "\n",
      "\n",
      "[Signature Page Follows]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "IN WITNESS WHEREOF, the Company has caused this Amendment No. 4 to be executed,\n",
      "and the Executive has hereunto set his hand, in each case to be effective as of\n",
      "the day and year first above written.\n",
      "THIRD POINT REINSURANCE LTD.\n",
      "\n",
      "\n",
      "By: /s/ J. Robert Bredahl ______________________________\n",
      "Name: Title: \u00a0\u00a0\u00a0\u00a0J. Robert Bredahl\n",
      "President & Chief Executive Officer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "By: /s/ Janice R. Weidenborner\n",
      "_____________________________\n",
      "Name: Title: \u00a0\u00a0\u00a0\u00a0Janice R. Weidenborner\n",
      "EVP, Group General Counsel\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EXECUTIVE\n",
      "By: \u00a0\u00a0\u00a0\u00a0/s/ Manoj K. Gupta\n",
      "______________________________\n",
      "Manoj K. Gupta\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_result(results_df, index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another document titled as \"AMENDMENT No. 4 TO EMPLOYMENT AGREEMENT\" is clearly a contract, so it makes sense that TLM classifies it into the \"contracts\" category with high trustworthiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLM predicted category: legislation\n",
      "TLM trustworthiness score: 0.9484836135698226\n",
      "\n",
      "\n",
      "      \n",
      "        DEPARTMENT OF DEFENSE\n",
      "        GENERAL SERVICES ADMINISTRATION\n",
      "        NATIONAL AERONAUTICS AND SPACE ADMINISTRATION \n",
      "        48 CFR Parts 2, 4, 12, 14, 15, 16, 19, 27, 30, 31, 32, 42, 44, 49, and 52\n",
      "        [FAR Case 2005-036; Docket 2007-001, Sequence 7]\n",
      "        RIN 9000-AK74\n",
      "        Federal Acquisition Regulation; FAR Case 2005-036, Definition of Cost or Pricing Data\n",
      "        \n",
      "          AGENCIES:\n",
      "          Department of Defense (DoD), General Services Administration (GSA), and National Aeronautics and Space Administration (NASA).\n",
      "        \n",
      "        \n",
      "          ACTION:\n",
      "          Notice of public meeting; extension of comment period.\n",
      "        \n",
      "        \n",
      "          SUMMARY:\n",
      "          The Civilian Agency Acquisition Council and the Defense Acquisition Regulations Council (Councils) are cosponsoring a public meeting to discuss the proposed Federal Acquisition Regulation (FAR) rule 2005-036 on cost or pricing data.  The rule would revise the definition of \u201ccost or pricing data\u201d; change the term \u201cinformation other than cost or pricing data\u201d to \u201cdata other than certified cost or pricing data\u201d; add a definition of \u201ccertified cost or pricing data\u201d to make the terms and definitions consistent with 10 U.S.C. 2306(a) and 41 U.S.C. 254(b) and more understandable to the general reader; change terminology throughout the FAR; and clarify the need to obtain data other than certified cost or pricing data when there is no other means to determine fair and reasonable pricing during price analysis.\n",
      "          The proposed rule was published in the Federal Register at 72 FR 20092 on April 23, 2007.  The Councils are now seeking additional views before finalizing the proposed rule.\n",
      "\n",
      "          A public meeting will be held on November 15, 2007, from 9:00 a.m. to 1:00 p.m. EST, in the General Services Administration Building Auditorium, 1800 F Street, NW, Washington, DC, 20405.  Interested parties may register electronically at: http://www.corpcomm-inc.com/dpap/dars/far_case_2005-036_meeting_registration.php.  Attendees are encouraged but not required to register for the public meeting, to ensure adequate room accommodations.\n",
      "        \n",
      "        \n",
      "          DATES:\n",
      "\n",
      "          The comment period has been extended.  Interested parties should submit written comments to the FAR Secretariat on or before November 22, 2007, to be considered in the formulation of the final rule.  Please do not resubmit comments already made.  If you wish your views at the public meeting to be considered as a public comment you must submit a public comment.  Copies of the public comments already submitted are available at http://www.regulations.gov.\n",
      "        \n",
      "        \n",
      "          ADDRESSES:\n",
      "          Submit comments identified by FAR Case 2005-036 by any of the following methods:\n",
      "        \n",
      "        Federal eRulemaking Portal: http://www.regulations.gov.\n",
      "        \u2022 To search for any document, first select under \u201cStep 1,\u201d \u201cDocuments with an Open Comment Period\u201d and select under \u201cOptional Step 2,\u201d \u201cFederal Acquisition Regulation\u201d as the agency of choice. Under \u201cOptional Step 3,\u201d select \u201cProposed Rules\u201d. Under \u201cOptional Step 4,\u201d from the drop down list, select \u201cDocument Title\u201d and type the FAR case number \u201c2005-036\u201d. Click the \u201cSubmit\u201d button. Please include your name and company name (if any) inside the document.\n",
      "        You may also search for any document by clicking on the \u201cSearch for Documents\u201d tab at the top of the screen. Select from the agency field \u201cFederal Acquisition Regulation\u201d, and type \u201c2005-036\u201d in the \u201cDocument Title\u201d field.  Select the \u201cSubmit\u201d button.\n",
      "        \u2022 Fax:  202-501-4067.\n",
      "        \u2022 Mail:  General Services Administration, Regulatory Secretariat (VIR), 1800 F Street, NW, Room 4035, ATTN:  Laurieann Duarte, Washington, DC  20405.\n",
      "        \n",
      "          Instructions: Please submit comments only and cite FAR case 2005-036 in all correspondence related to this case.  All comments received will be posted without change to http://www.regulations.gov, including any personal and/or business confidential information provided.\n",
      "        \n",
      "          FOR FURTHER INFORMATION CONTACT\n",
      "          Edward N. Chambers, Deputy Chair, FAR Finance Team, by telephone at (202) 501-3221, or by e-mail at edward.chambers@gsa.gov, for clarification of content.  Please cite FAR Case 2005-036. For information pertaining to status or publication schedules, contact the FAR Secretariat, Room 4035, GS Building, Washington, DC, 20405, at (202) 501-4755.\n",
      "        \n",
      "      \n",
      "      \n",
      "        \n",
      "        \n",
      "          Dated:  October 24, 2007.\n",
      "          Al Matera,\n",
      "          Director, Office of Acquisition Policy.\n",
      "        \n",
      "      \n",
      "      [FR Doc. 07-5404 Filed 10-31-07; 8:45 am]\n",
      "      BILLING CODE 6820-EP-S\n",
      "    \n",
      "  \n"
     ]
    }
   ],
   "source": [
    "display_result(results_df, index=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document about \"DEPARTMENT OF DEFENSE, GENERAL SERVICES ADMINISTRATION, NATIONAL AERONAUTICS AND SPACE ADMINISTRATION\" clearly belongs to some legislation measure, so it makes sense that TLM classifies it into the \"legislation\" category with high trustworthiness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Trustworthy Predictions\n",
    "\n",
    "Now let's see which classifications predicted by the model are least trustworthy. We sort the data by trustworthiness scores in the opposite order to see which predictions received the lowest scores. Observe how model classifications with the lowest trustworthiness scores are often incorrect, corresponding to examples with vague/irrelevant text or documents possibly belonging to more than one category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLM predicted category: legislation\n",
      "TLM trustworthiness score: 0.227975262181385\n",
      "\n",
      "\u00a0\n",
      "\n",
      "[exaa_001.jpg]\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_002.jpg]\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_003.jpg]\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_004.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_005.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_006.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_007.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_008.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_009.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_010.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_011.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_012.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_013.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_014.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_015.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_016.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_017.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0[exaa_018.jpg]\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\u00a0\n",
      "\n",
      "\n",
      "\n",
      "\u00a0\n"
     ]
    }
   ],
   "source": [
    "results_df = results_df.sort_values(by='trustworthiness_score')\n",
    "display_result(results_df, index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is clearly not legislation nor any other category since the document is just a list of JPG file names. TLM's low trust score alerts us that this example cannot be confidently classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use Trustworthiness Scores?\n",
    "\n",
    "If you have time, your team can manually review/correct the least trustworthy LLM classifications.\n",
    "Inspecting the least trustworthy examples also helps you discover how to improve your prompt (e.g. how to handle edge-cases, which few-shot examples to provide, etc).\n",
    "\n",
    "Alternatively, you can determine a trustworthiness threshold below which LLM predictions seem too unreliable, and abstain from classifying such cases. The overall magnitude/range of the trustworthiness scores may differ between datasets, so we recommend selecting any thresholds to be **application-specific**. First consider the *relative* trustworthiness levels between different data points before considering the overall magnitude of these scores for individual data points.\n",
    "\n",
    "## Measuring Classification Accuracy with Ground Truth Labels\n",
    "\n",
    "Our example dataset happens to have labels for each document, so we can load them in to assess the accuracy of our model predictions. We'll study the impact on accuracy as we abstain from making predictions for examples receiving lower trustworthiness scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc 'https://cleanlab-public.s3.amazonaws.com/Datasets/zero_shot_classification_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>prompt</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>trustworthiness_score</th>\n",
       "      <th>type</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Probl2B\\n0/NV Form\\nRev. June 2014\\n\\n\\n\\n    ...</td>\n",
       "      <td>You are an expert Legal Document Auditor. Clas...</td>\n",
       "      <td>caselaw</td>\n",
       "      <td>0.778880</td>\n",
       "      <td>caselaw</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>UNITED STATES DI...</td>\n",
       "      <td>You are an expert Legal Document Auditor. Clas...</td>\n",
       "      <td>caselaw</td>\n",
       "      <td>0.809627</td>\n",
       "      <td>caselaw</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n      \\n        FEDERAL COMMUNICATIONS COMMI...</td>\n",
       "      <td>You are an expert Legal Document Auditor. Clas...</td>\n",
       "      <td>legislation</td>\n",
       "      <td>0.923114</td>\n",
       "      <td>legislation</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\\n      \\n        DEPARTMENT OF COMMERCE\\n    ...</td>\n",
       "      <td>You are an expert Legal Document Auditor. Clas...</td>\n",
       "      <td>legislation</td>\n",
       "      <td>0.767369</td>\n",
       "      <td>legislation</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>EXHIBIT 10.14\\n\\nAMENDMENT NO. 1 TO\\n\\nCHANGE ...</td>\n",
       "      <td>You are an expert Legal Document Auditor. Clas...</td>\n",
       "      <td>contracts</td>\n",
       "      <td>0.843782</td>\n",
       "      <td>contracts</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  \\\n",
       "0      0  Probl2B\\n0/NV Form\\nRev. June 2014\\n\\n\\n\\n    ...   \n",
       "1      1                                UNITED STATES DI...   \n",
       "2      2  \\n      \\n        FEDERAL COMMUNICATIONS COMMI...   \n",
       "3      3  \\n      \\n        DEPARTMENT OF COMMERCE\\n    ...   \n",
       "4      4  EXHIBIT 10.14\\n\\nAMENDMENT NO. 1 TO\\n\\nCHANGE ...   \n",
       "\n",
       "                                              prompt predicted_category  \\\n",
       "0  You are an expert Legal Document Auditor. Clas...            caselaw   \n",
       "1  You are an expert Legal Document Auditor. Clas...            caselaw   \n",
       "2  You are an expert Legal Document Auditor. Clas...        legislation   \n",
       "3  You are an expert Legal Document Auditor. Clas...        legislation   \n",
       "4  You are an expert Legal Document Auditor. Clas...          contracts   \n",
       "\n",
       "   trustworthiness_score         type  is_correct  \n",
       "0               0.778880      caselaw        True  \n",
       "1               0.809627      caselaw        True  \n",
       "2               0.923114  legislation        True  \n",
       "3               0.767369  legislation        True  \n",
       "4               0.843782    contracts        True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ground_truth = pd.read_csv('zero_shot_classification_labels.csv')\n",
    "df = pd.merge(results_df, df_ground_truth, on=['index'], how='outer')\n",
    "df['is_correct'] = df['type'] == df['predicted_category']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLM zero-shot classification accuracy over all documents:  0.9605263157894737\n"
     ]
    }
   ],
   "source": [
    "print('TLM zero-shot classification accuracy over all documents: ', df['is_correct'].sum() / df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot the accuracy of the TLM-predicted categories (computed with respect to ground-truth labels). Here we assume predictions from TLM are only considered for the subset of data where the trustworthiness score is sufficiently high, so accuracy is only computed over this data subset (the remaining data could be manually reviewed by humans). Our plot depicts the resulting accuracy across different choices of the trustworthiness score threshold, which determine how much of the data gets auto-labeled by the LLM (see X-axis below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4082a2-0577-470b-b3e0-2dcace5fed31",
   "metadata": {},
   "source": [
    "**Optional: Plotting code**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the number of examples, percentage of data, and accuracy of TLM's predictions for each threshold value\n",
    "threshold_analysis = pd.DataFrame([{\n",
    "    \"threshold\": t,\n",
    "    \"num_examples\": len(filtered := df[df[\"trustworthiness_score\"] > t]),\n",
    "    \"percent_data\": len(filtered) / len(df) * 100,\n",
    "    \"accuracy\": np.mean(filtered[\"predicted_category\"] == filtered[\"type\"]) * 100\n",
    "} for t in np.arange(0, 1.0, 0.01)]).round(2)\n",
    "\n",
    "# Plot the accuracy of TLM's predictions and percentage of data for each trustworthiness score threshold value\n",
    "def create_enhanced_line_plot(threshold_analysis):\n",
    "    plt.figure(figsize=(8.25, 6.6))\n",
    "    points = plt.scatter(threshold_analysis['percent_data'], threshold_analysis['accuracy'],\n",
    "                        c=threshold_analysis['threshold'], cmap='viridis', s=40)  # Increased marker size\n",
    "    plt.plot(threshold_analysis['percent_data'], threshold_analysis['accuracy'], \n",
    "            alpha=0.3, color='gray', zorder=1, linewidth=2)  # Increased line width\n",
    "    \n",
    "    plt.colorbar(points).set_label('trustworthiness Threshold', fontsize=14)  # Increased font size\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xlabel('Percentage of Data Included', fontsize=14)  # Increased font size\n",
    "    plt.ylabel('Classification Accuracy', fontsize=14)  # Increased font size\n",
    "    plt.title('Accuracy vs Auto Classification Threshold', fontsize=16)  # Increased font size\n",
    "    plt.xticks(fontsize=14)  # Increased tick label size\n",
    "    plt.yticks(fontsize=14)  # Increased tick label size\n",
    "    plt.xlim(85, 100)\n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "# Apply the function to your data\n",
    "fig = create_enhanced_line_plot(threshold_analysis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TLM performance on zero-shot classification](./assets/tlm-zero-shot-classification/tlm_zero_shot_classification.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows the accuracy of TLM predicted labels, if we only have the LLM handle the subset of the data where TLM's trustworthiness score exceeds a certain threshold. This shows how **TLM can ensure a target labeling accuracy for examples above a certain trustworthiness score**. You can escalate to humans who manually categorize the remaining data whose trustworthiness falls below a score threshold.\n",
    "\n",
    "For this task, we can achieve 100% accuracy in automated classification with TLM by setting the trustworthiness score threshold near 0.7, which allows us to automatically categorize 91% of the data. This means you only need to manually handle 9% of the data to achieve **perfect accuracy**. Use TLM trust scores to *guarantee* reliable LLM classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically Boost Accuracy\n",
    "\n",
    "Beyond scoring trustworthiness, TLM can\u00a0*automatically* boost the accuracy of LLM predictions, if you specify the \"best\" [`quality_preset`](/tlm/tutorials/tlm_advanced/#quality-presets). Additionally consider setting TLM's base `model` option to a more powerful LLM that works well in your domain. TLM can automatically improve the accuracy of *any* LLM model, no change to your prompts/code required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base accuracy: 96.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying TLM... 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosted accuracy: 97.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_accuracy = np.mean(df[\"predicted_category\"] == df[\"type\"])\n",
    "print(f\"Base accuracy: {base_accuracy:.1%}\")\n",
    "\n",
    "# Here we use the \"best\" quality preset to auto-boost accuracy\n",
    "tlm_best = TLM(quality_preset=\"best\", options={\"model\": MODEL})\n",
    "best_responses = tlm_best.try_prompt(df['prompt'].to_list(), constrain_outputs=categories + [\"other\"])\n",
    "df[[\"best_predicted_category\",\"best_trustworthiness_score\"]] = pd.DataFrame(best_responses)\n",
    "boosted_accuracy = np.mean(df['type'] == df['best_predicted_category'])\n",
    "print(f\"Boosted accuracy: {boosted_accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "If you are enforcing Structured Outputs on your LLM, learn how you can still apply TLM via our [OpenAI API](/tlm/tutorials/tlm_structured_outputs/). For classification tasks: structured outputs may degrade accuracy, so using TLM's `constrain_outputs` argument is generally recommended over using structured outputs.\n",
    "\n",
    "For binary classification tasks (i.e. Yes/No or True/False decisions), learn how you can control false positive/negative error rates with TLM via our tutorial: [Yes/No Decisions](/tlm/use-cases/tlm_yes_no_decision/).\n",
    "\n",
    "Learn how to auto-label data using TLM and save human data annotation costs via our tutorial on: [Data Annotation/Labeling](/tlm/use-cases/tlm_annotation/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}