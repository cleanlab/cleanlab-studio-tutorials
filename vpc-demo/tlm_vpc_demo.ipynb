{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f278ba-441a-470a-99c1-54cbd6f8cee5",
   "metadata": {},
   "source": [
    "# Integrating TLM into your RAG app via the OpenAI Python client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79715fec-e568-407b-b2f6-11aba262c9ed",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to integrate your VPC installation of Cleanlab's Trustworthy Language Model (TLM) into existing GenAI apps. You will learn how to assess the trustworthiness of OpenAI model responses, directly through the [OpenAI client library](https://github.com/openai/openai-python)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38dc41",
   "metadata": {},
   "source": [
    "In this tutorial, we perform multi-label classification (i.e. document tagging) with trustworthiness scores from TLM. The same method can be used to score the trustworthiness of any type of output from OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f87254-771e-4674-aad9-1a83f08a0343",
   "metadata": {},
   "source": [
    "## API access to the TLM backend service\n",
    "\n",
    "This demo assumes that you have access to the deployed TLM backend service at the URL `http://example.customer.com:8080/api`. You are welcome to expose the TLM service however you prefer, depending on the unique needs of your networking environment. Simply replace the base URL when instantiating the OpenAI Python client later in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987f7149-3539-4210-b2e9-8926f3ac3ea5",
   "metadata": {},
   "source": [
    "Please note that Google Colab does **_not_** have built-in support to access services on your local machine. This is because Colab [runs in a virtual machine](https://research.google.com/colaboratory/faq.html#executed-code), so `localhost` refers to that VM, rather than your computer. If you would like to access TLM by port-forwarding to your local machine, you may do so by downloading the `.ipynb` file and running Jupyter locally, or by using a tunneling service like [ngrok](https://ngrok.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce124e52-f9c4-4110-b844-3fe05a84adb8",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c07e776-adf9-4246-8a98-7d19d2fcb422",
   "metadata": {},
   "source": [
    "The Python packages required for this tutorial can be installed using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c356e4-6b02-4864-a5ff-926d991de162",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade openai tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9bc6a28-1873-4b02-8624-16faffca9108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from openai import OpenAI\n",
    "import ast\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e18a67a-8575-43bb-9e53-74385d6fbc6a",
   "metadata": {},
   "source": [
    "## Fetch example Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65018bf-464e-4c8c-abe2-7e72c517918d",
   "metadata": {},
   "source": [
    "This tutorial uses a modified version of the [Alexa intent detection dataset](https://huggingface.co/datasets/AmazonScience/massive). \n",
    "\n",
    "Each text sample contains several statements that could correspond to multiple intents (for example controlling devices, asking for information etc). The label corresponding to each example specifies what the intent of that statement is, where there could be more than one intent corresponding to each sample. Let's take a look at the dataset below.\n",
    "\n",
    "In this tutorial, we will only run the LLM inference on 50 randomly sampled examples of this dataset as a demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43273fc-c518-46fe-b6dd-f34215552fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://cleanlab-public.s3.us-east-1.amazonaws.com/Datasets/massive_multilabel_classification.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a73bec43-dee1-473a-a926-318b1a9c11d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lets have a chat</td>\n",
       "      <td>[general_quirky]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are meeting scheduled for today</td>\n",
       "      <td>[calendar_query]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>erase all the events. resume my audio book from karl pilkington. tell me the profession of celebrity</td>\n",
       "      <td>[calendar_remove, play_audiobook, qa_factoid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thirty minute reminder on meeting for tuesday</td>\n",
       "      <td>[calendar_set]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have a nine am meeting on wednesday send me a reminder</td>\n",
       "      <td>[calendar_set]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   text  \\\n",
       "0                                                                                      lets have a chat   \n",
       "1                                                                  what are meeting scheduled for today   \n",
       "2  erase all the events. resume my audio book from karl pilkington. tell me the profession of celebrity   \n",
       "3                                                         thirty minute reminder on meeting for tuesday   \n",
       "4                                              i have a nine am meeting on wednesday send me a reminder   \n",
       "\n",
       "                                          labels  \n",
       "0                               [general_quirky]  \n",
       "1                               [calendar_query]  \n",
       "2  [calendar_remove, play_audiobook, qa_factoid]  \n",
       "3                                 [calendar_set]  \n",
       "4                                 [calendar_set]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"massive_multilabel_classification.csv\")\n",
    "data[\"labels\"] = data[\"labels\"].apply(ast.literal_eval)\n",
    "data = data.sample(50, random_state=123).reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba57c0-ea98-4d35-9b6e-41b8313a3f8c",
   "metadata": {},
   "source": [
    "## Obtain LLM Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94989f63-ade7-4a01-95bd-bea936f6cfce",
   "metadata": {},
   "source": [
    "First, we need to get a list of all possible classes from the given dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "763c6dcd-6a18-4833-bf94-898f1a000836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['general_quirky', 'calendar_query', 'calendar_remove',\n",
       "       'play_audiobook', 'qa_factoid'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_classes = data[\"labels\"].explode().unique()\n",
    "multilabel_classes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf4eadf-13de-44fb-8128-b51d5e575991",
   "metadata": {},
   "source": [
    "### Prompt OpenAI "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38fc4d5-f768-430e-94f4-8eba529591ef",
   "metadata": {},
   "source": [
    "Then, we can instantiate the OpenAI client, pointing the `base_url` to TLM, which allows us to also get the trustworthiness score associated with each response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "549220e5-0530-4342-af89-538a7965e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the VPC installation of TLM does not authenticate requests by default, but the OpenAI client requires an API key, so we pass a fake value here\n",
    "client = OpenAI(\n",
    "    api_key=\"test\",\n",
    "    base_url=\"http://example.customer.com:8080/api\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1bbaa6-691c-4192-94ce-64c465abfb00",
   "metadata": {},
   "source": [
    "Here is an example of how we can prompt OpenAI with one sample text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5efa2ff4-1b9b-4562-b74d-c431d8db4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = data['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e8792d0-fa34-4824-8dc8-27bda83d9258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Classify the following text, using these labels for guidance: {multilabel_classes}. The text is: {sample_text}\"}  \n",
    "        ],\n",
    "    extra_body={\n",
    "        \"tlm\": {\n",
    "            \"quality_preset\": \"low\"\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007eeb76-9324-44a4-b08c-a2994d6e9e53",
   "metadata": {},
   "source": [
    "The returned object matches what OpenAI would ordinarily return, except it has an additional `tlm` field from TLM with extra information like the trustworthiness `score` and other `metadata`. This way you can use TLM as a drop-in replacement for OpenAI in any application (and will still get back the same responses you'd get directly from OpenAI).  Let's parse the predictions and trustworthiness score from the returned response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d555f0-a01e-4e9f-9628-3a7d093fca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: The appropriate label for the text \"what are meeting scheduled for today\" is **'calendar_query'**.\n",
      "TLM Score: 0.6187163760956422\n"
     ]
    }
   ],
   "source": [
    "response = completion.choices[0].message.content\n",
    "tlm_score = completion.choices[0].tlm[\"score\"]\n",
    "\n",
    "print(f\"LLM Response: {response}\")\n",
    "print(f\"TLM Score: {tlm_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb4ff8-2982-4542-9693-9960583e5c8e",
   "metadata": {},
   "source": [
    "### Batch Prompt on a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453680cb-1bc0-4381-8b43-f405de8366af",
   "metadata": {},
   "source": [
    "Here, we define a quick helper function that allows us to process multiple texts in parallel, which will speed up prompting the LLM on an entire dataset. The helper function also parses and collects the predictions and trustworthiness score in a DataFrame for easy downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4433f2d-a4db-4909-b523-731ac6227b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Classify the following text, using these labels for guidance: {multilabel_classes}. The text is: {text}\"}],\n",
    "        extra_body={\n",
    "            \"tlm\": {\n",
    "                \"quality_preset\": \"low\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"response\": completion.choices[0].message.content,\n",
    "        \"tlm_score\": completion.choices[0].tlm[\"score\"],\n",
    "    }\n",
    "\n",
    "def classify_texts_batch(texts, batch_size=5, max_threads=3, sleep_time=10):\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        \n",
    "        with ThreadPoolExecutor(max_threads) as executor:\n",
    "            futures = [executor.submit(classify_text, text) for text in batch]\n",
    "            batch_results = [f.result() for f in futures]\n",
    "        \n",
    "        results.extend(batch_results)\n",
    "\n",
    "        # sleep to prevent hitting rate limits\n",
    "        if i + batch_size < len(texts):\n",
    "            time.sleep(sleep_time)\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "786fe8b7-dada-4ec6-81cd-5e1643c12b59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [13:47<00:00, 82.79s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>tlm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The text \"lets have a chat\" is best classified as **general_quirky**.</td>\n",
       "      <td>0.570052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The text \"what are meeting scheduled for today\" can be classified as **'calendar_query'**.</td>\n",
       "      <td>0.588551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The text can be classified into multiple categories based on its content. Here are the appropriate labels:\\n\\n1. \"calendar_remove\" - related to \"erase all the events.\"\\n2. \"play_audiobook\" - related to \"resume my audio book from karl pilkington.\"\\n3. \"qa_factoid\" - related to \"tell me the profession of celebrity.\"\\n\\nTherefore, the classification would be:\\n\\n- calendar_remove\\n- play_audiobook\\n- qa_factoid</td>\n",
       "      <td>0.485598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The appropriate classification for the text \"thirty minute reminder on meeting for tuesday\" is **calendar_query**.</td>\n",
       "      <td>0.597910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The appropriate label for the text \"i have a nine am meeting on wednesday send me a reminder\" is **calendar_set**.</td>\n",
       "      <td>0.705016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                      response  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                        The text \"lets have a chat\" is best classified as **general_quirky**.   \n",
       "1                                                                                                                                                                                                                                                                                                                                   The text \"what are meeting scheduled for today\" can be classified as **'calendar_query'**.   \n",
       "2  The text can be classified into multiple categories based on its content. Here are the appropriate labels:\\n\\n1. \"calendar_remove\" - related to \"erase all the events.\"\\n2. \"play_audiobook\" - related to \"resume my audio book from karl pilkington.\"\\n3. \"qa_factoid\" - related to \"tell me the profession of celebrity.\"\\n\\nTherefore, the classification would be:\\n\\n- calendar_remove\\n- play_audiobook\\n- qa_factoid   \n",
       "3                                                                                                                                                                                                                                                                                                           The appropriate classification for the text \"thirty minute reminder on meeting for tuesday\" is **calendar_query**.   \n",
       "4                                                                                                                                                                                                                                                                                                           The appropriate label for the text \"i have a nine am meeting on wednesday send me a reminder\" is **calendar_set**.   \n",
       "\n",
       "   tlm_score  \n",
       "0   0.570052  \n",
       "1   0.588551  \n",
       "2   0.485598  \n",
       "3   0.597910  \n",
       "4   0.705016  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = classify_texts_batch(data[\"text\"], batch_size=5)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b6aacf-2768-45ca-bd10-4eaff37693d8",
   "metadata": {},
   "source": [
    "## Examine Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ce86f-3085-4c90-aca4-964b1a3fe867",
   "metadata": {},
   "source": [
    "We have now obtained the predictions and trustworthiness score for each given text. Let's examine the results in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0c9198d-d26c-422c-b11f-6adec3fed116",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results = pd.concat([data, results], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3732335f-9bb2-47f0-83da-936b2c66ca09",
   "metadata": {},
   "source": [
    "### High Trustworthiness Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb3a4f-2c56-427a-88c5-a8345830cfcd",
   "metadata": {},
   "source": [
    "The responses with the highest trustworthiness scores represent texts where TLM is the most confident that it has predicted the correct intents.\n",
    "\n",
    "We can see below that the predictions for the samples below match the ground truth labels and are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "946e78ca-980d-4078-8564-01496fdfdf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>response</th>\n",
       "      <th>tlm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>what movie can i watch tonight on the theater here in boston</td>\n",
       "      <td>[recommendation_events]</td>\n",
       "      <td>The text can be classified under the label: **recommendation_movies**.</td>\n",
       "      <td>0.818268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>features of google pixel. what is the deepest point on earth</td>\n",
       "      <td>[general_quirky, qa_factoid]</td>\n",
       "      <td>The text can be classified under the label: **qa_factoid**.</td>\n",
       "      <td>0.768271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>add a wrist watch to the shopping list. when is the next friday the thirteenth. olly clear the list</td>\n",
       "      <td>[lists_createoradd, datetime_query, lists_remove]</td>\n",
       "      <td>The text contains multiple requests, which can be classified into different categories:\\n\\n1. \"add a wrist watch to the shopping list.\" - This can be classified as **lists_createoradd**.\\n2. \"when is the next friday the thirteenth.\" - This can be classified as **datetime_query**.\\n3. \"olly clear the list\" - This can be classified as **lists_remove**.\\n\\nOverall, the classification labels applicable to the text are:\\n\\n- lists_createoradd\\n- datetime_query\\n- lists_remove</td>\n",
       "      <td>0.765526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   text  \\\n",
       "44                                         what movie can i watch tonight on the theater here in boston   \n",
       "41                                         features of google pixel. what is the deepest point on earth   \n",
       "23  add a wrist watch to the shopping list. when is the next friday the thirteenth. olly clear the list   \n",
       "\n",
       "                                               labels  \\\n",
       "44                            [recommendation_events]   \n",
       "41                       [general_quirky, qa_factoid]   \n",
       "23  [lists_createoradd, datetime_query, lists_remove]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       response  \\\n",
       "44                                                                                                                                                                                                                                                                                                                                                                                                                       The text can be classified under the label: **recommendation_movies**.   \n",
       "41                                                                                                                                                                                                                                                                                                                                                                                                                                  The text can be classified under the label: **qa_factoid**.   \n",
       "23  The text contains multiple requests, which can be classified into different categories:\\n\\n1. \"add a wrist watch to the shopping list.\" - This can be classified as **lists_createoradd**.\\n2. \"when is the next friday the thirteenth.\" - This can be classified as **datetime_query**.\\n3. \"olly clear the list\" - This can be classified as **lists_remove**.\\n\\nOverall, the classification labels applicable to the text are:\\n\\n- lists_createoradd\\n- datetime_query\\n- lists_remove   \n",
       "\n",
       "    tlm_score  \n",
       "44   0.818268  \n",
       "41   0.768271  \n",
       "23   0.765526  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results.sort_values(\"tlm_score\", ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639fa71-b7f2-480b-b00b-40fec010338f",
   "metadata": {},
   "source": [
    "### Low Trustworthiness Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25664160-d35f-421b-99b7-ec8e2bd4d200",
   "metadata": {},
   "source": [
    "The responses with the lowest trustworthiness scores indicate outputs we are least confident are good.\n",
    "\n",
    "Results with low trustworthiness scores would benefit most from manual review, especially if we need almost all outputs across the dataset to be correct.\n",
    "\n",
    "For examples with the lowest trustworthiness scores in our dataset shown below, you can see that the predictions tend to be incorrect or could use further review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5f546f4-c2a0-4501-b94f-109c0e0a237c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>response</th>\n",
       "      <th>tlm_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>delete alarm. when will the world end. can you please add an item to my grocery list</td>\n",
       "      <td>[alarm_remove, general_quirky, lists_createoradd]</td>\n",
       "      <td>The text contains multiple requests that can be classified into different categories. Here are the classifications for each part:\\n\\n1. \"delete alarm.\" - This corresponds to the label **'alarm_remove'**.\\n2. \"when will the world end.\" - This corresponds to the label **'qa_factoid'** (since it's a question seeking factual information).\\n3. \"can you please add an item to my grocery list\" - This corresponds to the label **'lists_createoradd'**.\\n\\nIf you are looking for a single label classification for the entire text, it would be more complex since it contains multiple different requests. However, if choosing one main label, you could consider it as **'calendar_remove'** because it may suggest removing or adjusting an alarm as a primary action. \\n\\nBut as the text stands, it covers three separate requests.</td>\n",
       "      <td>0.289426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>where do most celebrities hang out. please rate current song as five stars</td>\n",
       "      <td>[qa_factoid, music_likeness]</td>\n",
       "      <td>The text can be classified as: **general_quirky**.</td>\n",
       "      <td>0.301980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>yes i like to save opinion on song playing and which player support that song. what's the currency exchange rate for china</td>\n",
       "      <td>[music_likeness, qa_currency]</td>\n",
       "      <td>The text can be classified under the following labels:\\n\\n1. **music_likeness** - \"yes i like to save opinion on song playing...\"\\n2. **qa_currency** - \"...which player support that song. what's the currency exchange rate for china\"\\n\\nHowever, since it presents two different ideas, if only one label is to be chosen based on the primary focus, **qa_currency** would be more appropriate, given the clear question concerning the currency exchange rate. \\n\\nFinal classification: **qa_currency**</td>\n",
       "      <td>0.425064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                          text  \\\n",
       "37                                        delete alarm. when will the world end. can you please add an item to my grocery list   \n",
       "36                                                  where do most celebrities hang out. please rate current song as five stars   \n",
       "48  yes i like to save opinion on song playing and which player support that song. what's the currency exchange rate for china   \n",
       "\n",
       "                                               labels  \\\n",
       "37  [alarm_remove, general_quirky, lists_createoradd]   \n",
       "36                       [qa_factoid, music_likeness]   \n",
       "48                      [music_likeness, qa_currency]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            response  \\\n",
       "37  The text contains multiple requests that can be classified into different categories. Here are the classifications for each part:\\n\\n1. \"delete alarm.\" - This corresponds to the label **'alarm_remove'**.\\n2. \"when will the world end.\" - This corresponds to the label **'qa_factoid'** (since it's a question seeking factual information).\\n3. \"can you please add an item to my grocery list\" - This corresponds to the label **'lists_createoradd'**.\\n\\nIf you are looking for a single label classification for the entire text, it would be more complex since it contains multiple different requests. However, if choosing one main label, you could consider it as **'calendar_remove'** because it may suggest removing or adjusting an alarm as a primary action. \\n\\nBut as the text stands, it covers three separate requests.   \n",
       "36                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                The text can be classified as: **general_quirky**.   \n",
       "48                                                                                                                                                                                                                                                                                                                                    The text can be classified under the following labels:\\n\\n1. **music_likeness** - \"yes i like to save opinion on song playing...\"\\n2. **qa_currency** - \"...which player support that song. what's the currency exchange rate for china\"\\n\\nHowever, since it presents two different ideas, if only one label is to be chosen based on the primary focus, **qa_currency** would be more appropriate, given the clear question concerning the currency exchange rate. \\n\\nFinal classification: **qa_currency**   \n",
       "\n",
       "    tlm_score  \n",
       "37   0.289426  \n",
       "36   0.301980  \n",
       "48   0.425064  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results.sort_values(\"tlm_score\").head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922df4fa-409c-40f3-8b8a-73ba2f5ee313",
   "metadata": {},
   "source": [
    "## Using Different Quality Presets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396b996-da06-4102-9ef9-8a74f7cf24cb",
   "metadata": {},
   "source": [
    "You can use TLM with different [quality presets](/tlm/tutorials/tlm_advanced/#quality-presets) by specifying the preset after the model name. \n",
    "\n",
    "For example, in this example below we specify `model=\"gpt-4o-low\"` to use TLM on `low` quality preset (for lower cost/latency). If unspecified, the default quality preset used is `medium`.\n",
    "\n",
    "Currently, only `base`, `low`, and `medium` presets are supported when using TLM via the OpenAI library. Read more about quality presets [here](/tlm/api/python/tlm/#class-tlmoptions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "561a4cc9-e835-40e8-adc5-abcecb09db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = data['text'][0]\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-low\",\n",
    "    messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Classify the following text, using these labels for guidance: {multilabel_classes}. The text is: {sample_text}\"}  \n",
    "        ],\n",
    "    extra_body={\n",
    "        \"tlm\": {\n",
    "            \"quality_preset\": \"low\"\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a396b996-da06-4102-9ef9-8a74f7cf24cd",
   "metadata": {},
   "source": [
    "We re-emphasize that you can use TLM via the [OpenAI library](https://github.com/openai/openai-python) to score the trustworthiness of *any* type of OpenAI output.\n",
    "\n",
    "For questions about the OpenAI API, refer to the documentation linked from [their library](https://github.com/openai/openai-python)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}